[{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhistudio_meeting_nodes/","tags":null,"title":""},{"categories":null,"contents":"Separated qubits don\u0026rsquo;t really like to interact. Instead, then, we just make them bigger and control them at the same time. We can implement gates via a sequence of pulses. If you work with interacting qubits a lot, you will end up with the APR Paradox.\nIf you take two qubits, and move them though two gates, you essentially will get entangled results.\nTo make this works, you will need to take some probability. Know correlation, expectation, etc.\n","permalink":"https://www.jemoka.com/posts/kbhmaking_qubits_interact/","tags":null,"title":""},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhpoint_estimate/","tags":null,"title":""},{"categories":null,"contents":" \\(A\\) does all the asking, \\(B\\) has all the decision making power Population \\(A\\)\u0026rsquo;s match never goes up at best, they stay the same Population \\(B\\)\u0026rsquo;s match can never go down. At worse, they stay the same. Population \\(A\\) always ends up with the highest-preferred person in their realm of possibility Population \\(B\\) always ends up with the lowest-preferred person in their realm of possibility ","permalink":"https://www.jemoka.com/posts/kbhproperties_of_the_stable_matching_algorithm/","tags":null,"title":""},{"categories":null,"contents":" \u0026ldquo;Are the nodes system independent of the class system?\u0026rdquo; Does the model require a set of L2 class? Can we build the model to take advantage of as many 10* things as possible? A preso Demo of a kid moving through MVP vis a vis advantage over just taking all classes Naming skills that would go on the graph Figuring: comparability with flattening like in a L1 system ","permalink":"https://www.jemoka.com/posts/kbhrnn_notes/","tags":null,"title":""},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhrural_hospitals_problem/","tags":null,"title":""},{"categories":null,"contents":"The Stable Matching Problem is Wes Chao\u0026rsquo;s favourite algorithm.\nConsider two populations, \\(A\\) and \\(B\\), who want to form paired relationships between a person \\(A\\) and \\(B\\). \\(A_i\\) has a list of their ranked order matches (I want to be paired with \\(B_1\\) most, \\(B_4\\) second, etc.), and so does \\(B_i\\) (I want to be paired with \\(A_4\\) most \\(A_9\\) second, etc.)\nWe want to discover a stable matching, where pairs are most unwilling to move. We can solve it using the stable matching algorithm.\nNueva Invention Studio speed-dating noises?\napplications of the stable matching problem Dating Applying to college Both of these are high-stress situations, especially if you are doing asking You can mathematically prove that person doing the asking gets the best result Hence, it shows us that the best possible outcomes go to the people who are willing to ask and get rejected.\nextensions to the stable matching problem the stable matching problem can be extended to the rural hospitals problem, which is slightly better.\n","permalink":"https://www.jemoka.com/posts/kbhstable_matching_problem/","tags":null,"title":""},{"categories":null,"contents":"thermoregulation is the brain\u0026rsquo;s regulation of body temperature to respond to heat, cold events.\nStudies indicate that cold exposure cold exposure can activate AgRP (stimulate food intake) as a means for the brain leveraging CNS regulation to which would lower the glucose level and maintain glucose homeostatis.\nHowever, cold exposure also trigger energy expenditure, and seems contradictory but not really why?.\n","permalink":"https://www.jemoka.com/posts/kbhthermoregulation/","tags":null,"title":""},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhz_score/","tags":null,"title":""},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhq/","tags":null,"title":":q"},{"categories":null,"contents":" New Deal ","permalink":"https://www.jemoka.com/posts/kbh1980s_political_alignment/","tags":null,"title":"1980s Political Alignment"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbh1a/","tags":null,"title":"1a"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhaaa/","tags":null,"title":"AAA"},{"categories":null,"contents":"Welcome to the personal site of Houjun \u0026ldquo;Jack\u0026rdquo; Liu.\nI\u0026rsquo;m on the blaggosphere as @jemokajack and, far more frequently, u/jemoka and @jemoka.\nWho\u0026rsquo;s this guy? I am a human interested in linguistic analysis, L2 learning, and user interfaces. AGI \u0026amp; Emacs are cool. I run Condution, Shabang, and MODAP, do research in NLP and education pedagogy, direct Science Friday streams, captain an entrepreneurship studio, and recently began working for Brian MacWhinney on projects in linguistics.\nNeed to catch me? Email me at houjun at the current domain. Please do email me, I actually check.\nRecent Projects Take a look at my GitHub profile for programming projects. For larger scale things, take a look at the Projects Index on this site.\nNotes This site also contains the vast majority of my course notes. It is a organized in a zettlekasten format. To begin exploring, why don\u0026rsquo;t you check out Nueva Courses Index. Accompanying this index is the collection of assignments found here which a few friends has collected together.\njklsnt Some friends and I started a small collection of fun internets that we made. Check it out!.\nHow do I know you are you? Good question! gpg --keyserver pgp.mit.edu --recv-keys 1807A0C6 and verify with my work email. Note that GPG don\u0026rsquo;t actually check fingerprints you received so do that yourself.\nBugga Bugga Bontehu? Sometimes I use this domain as a downlink to fastcalculator to friends and coworkers. To achieve this, here are two links you could click on that I don\u0026rsquo;t always promise do anything: oliver and socks.\n","permalink":"https://www.jemoka.com/posts/kbhindex/","tags":null,"title":"About"},{"categories":null,"contents":"Capecitabmine =\u0026gt; 5-Fluoropyrimidine =\u0026gt; Cancer cell death.\n","permalink":"https://www.jemoka.com/posts/kbhaction_of_capecitabmine/","tags":null,"title":"action of Capecitabmine"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhaction_research/","tags":null,"title":"action research"},{"categories":null,"contents":"Comes from doi.org/10.3389/fcomp.2020.00001\nADR is a vectorization/encoding technique whereby time-series data is segmented, clustered via solf-organizing maps, and the centroids of the clusters are used as the encoding\n","permalink":"https://www.jemoka.com/posts/kbhactive_data_representation/","tags":null,"title":"Active Data Representation"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhactive_recall/","tags":null,"title":"active recall"},{"categories":null,"contents":"Adding!\n","permalink":"https://www.jemoka.com/posts/kbhadding/","tags":null,"title":"adding"},{"categories":null,"contents":"The additive identity allows another number to retain its identity after adding. Its \\(0\\) [for fields?]\n","permalink":"https://www.jemoka.com/posts/kbhadditive_identity/","tags":null,"title":"additive identity"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhadhd/","tags":null,"title":"ADHD"},{"categories":null,"contents":"adMe: absorbtion, distribution, metabolism, excretion.\nPharmacology treatment of diseases. The microbiome regulates metabolism.\n","permalink":"https://www.jemoka.com/posts/kbhadme/","tags":null,"title":"adMe"},{"categories":null,"contents":"ADReSS Challenge is a Alzheimer\u0026rsquo;s Dementia Recognition challenge from the data available on DementiaBank.\n","permalink":"https://www.jemoka.com/posts/kbhadress_challenge/","tags":null,"title":"ADReSS Challenge"},{"categories":null,"contents":"The ADReSS Literature Survey is a literature survey for the results published during the ADReSS Challenge.\nAntonsson 2021: disfluency + SVF features trained on SVM: lexical \u0026gt; narrative qual. Chlasta 2021: features extracted from VGGish on SVM; also trained new CNN from .wav. Sadeghian 2021: Used GA for feature sel., achieved 94% w/ MMSE alone; dev\u0026rsquo;d ASR tool. Martinc 2021: CBOW (text) + ADR (sound) late fusion\u0026rsquo;d to a BERT, ablated for features. Meghanani 2021: spontaneous speech transcripts with fastText and CNN; 83.33% acc. Yuan 2021: ERNIE on transcripts with pause encoding; 89.6% acc. Jonell 2021: Developed a kitchen sink of diag. tools and correlated it with biomarkers. Laguarta 2021: multimodel (OVBM) to embed auditory info + biomarkers for clsf. Shah 2021: late fusion of n-gram and OpenSMILE on std. classifiers. Lindsay 2021: Cross-linguistic markers shared for AD patients between English and French. Zhu 2021: late fusion of CTP task for AD clsf. w/ transf., mobilenet, yamnet, mockingjay. Guo 2021: WLS data to augment CTP from ADReSS Challenge and trained it on a BERT. Balagopalan 2021: lexo. and synt. features trained on a BERT and other models. Mahajan 2021: a bimodal model on speech/text with GRU on speech and CNN-LSTM on text. Parvin 2020: excercize scheme effects on theta/alpha ratio and Brain wave frequency. Luz 2021: review paper presenting the ADReSSo challenge and current baselines. From Meghanani 2021, a review:\n","permalink":"https://www.jemoka.com/posts/kbhadress_literature_survey/","tags":["index"],"title":"ADReSS Literature Survey Index"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhadvertising/","tags":null,"title":"advertising"},{"categories":null,"contents":"Agricultural Adjustment Administration is a part of the New Deal programs to support the agricultural sector and maintain supply. They regulated production of seven different crops to group increase farming income. It is very far-reaching of other parts of the economy.\nIt was ruled unconstitutional in 1936.\n","permalink":"https://www.jemoka.com/posts/kbhagricultural_adjustment_administration/","tags":null,"title":"Agricultural Adjustment Administration"},{"categories":null,"contents":"AgRP is a type of neurons that stimulates food intake.\nInhibit metacortin Activate NPY Release GABA Diet-induced obesity blunts AgRP response, and so, because AgRP plays a part in thermoregulation, diet-inducsed obesity responds less to temperature changes.\n","permalink":"https://www.jemoka.com/posts/kbhagrp/","tags":null,"title":"AgRP"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhai/","tags":null,"title":"AI"},{"categories":null,"contents":"AI Ethics is the Ethics of training AI models.\n","permalink":"https://www.jemoka.com/posts/kbhai_ethics/","tags":null,"title":"AI Ethics"},{"categories":null,"contents":"AIBridge is an introductory AI bootcamp developed and taught by Prof. Xin Liu, yours truly, and Samuel Ren in collaboration with AIFS.\nCourse website: AIBridge Course Website\nAIBridge Lecture Codealongs AIBridgeLab D1Aft AIBridgeLab D2Aft AIBridgeLab D3/D4 AIBridgeLab D4Aft oeansut\\n \\n aosntegu\\n \\n\n","permalink":"https://www.jemoka.com/posts/kbhaibridge/","tags":null,"title":"AIBridge"},{"categories":null,"contents":" Welcome to the AIBridge Course homepage.\nThe purpose of AIBridge is to bridge the gap between computer science and other disciplines. To many, working with AI might seem like an unreachable objective. However, in reality, one week is enough to get started. AIBridge will provide basic programming capability in Python and knowledge of object-oriented programming as well as the concepts behind machine learning and how to implement it using a popular toolbox, Scikit-Learn. Students work to complete a personally-defined project using techniques in AI, with data from their own research or with problems supplied by the Course. This one week course will be hosted in-person at UC Davis and will target mainly undergraduate and non-technical graduate students.\nThe course is taught by Prof. Xin Liu in collaboration with Houjun \u0026ldquo;Jack\u0026rdquo; Liu, Samuel Ren, and Albara Ah Ramli.\nEvergreen Resources Python Tutorial: W3 Schools Python Documentation: Python.org SciKit Documentation: scikit-learn.org Iris Dataset: UCI DB, or, for better user experience, scikit Wine Dataset: UCI DB Class Discord: Invite Data-Loading Cheat-Sheet: Colab When in doubt\u0026hellip;\nGoogle it! Try it! Andrew Ng\u0026rsquo;s Machine Learning Suite of Courses DONE Day 1: Python Basics On Monday, 06/27/2022, we covered the basics of Python so that we are all up to speed to perform basic ML with the Scikit Learn toolkit.\nIntroductory Remarks: Slides Lecture on Python Basics: Slides Lab Exercises: Morning Lab Notes, Afternoon Lab Notes Colab Notebooks: Morning Lecture Notebook, Morning Lab Notebook, Afternoon Lecture Notebook, Afternoon Lab Notebook Day 1 feedback survey: Link\nDONE Day 2: OOP + Linear Models Today, we are going to cover the basic intuition and terminology behind Object Oriented Programming, as well as introduce two simple, linear approaches to Machine Learning tasks: linear regression and logistic regression.\nLecture on OOP and more on functions (morning): Slides Lecture on Linear and Logistic Regression (afternoon): Slides Lab Exercises: Morning Lab Notes, Afternoon Lab Notes Colab Notebooks: Morning Lecture Notebook, Morning Lab Notebook, Afternoon Lab Notebook Day 2 feedback survey: Link\nDONE Day 3: Data + Classifier Today, we are going to cover data cleaning, and three more classifiers!\nLecture on data cleaning and pandas (morning): Slides Lecture on three classification algorithms (afternoon): Slides Lab Exercises: Morning Lab Notes, Afternoon Lab Notes Colab Notebooks: Morning Lab Notebook, Afternoon Lab Notebook Day 3 feedback survey: Link\nDONE Day 4: Operations and Clustering Today, we are going to work on the validation operations tools, and talk about clustering\nLecture on training and data operations (morning): Slides Lecture on clustering and feature operations (afternoon): Slides Lab Exercises: Morning Lab Notes, Afternoon Lab Notes Colab Notebooks: Afternoon Notebook Day 4 feedback survey: Link\nDay 5: Closing Thoughts Today, we are going to tie some loose ends with missing data, error analysis, semi supervised learning, cross validation, and ethics.\nClosing thoughts lecture (morning): Slides Final Project: AIBridge Final Project\nDay 5/Bootcamp feedback survey: Link\nOther Links and Resources Tools we use: AIBridge Packages and Tools Cleaned Wine Dataset (try cleaning it yourself before using!): Google Drive Iris Data with Temperature (don\u0026rsquo;t use without instructions, though!): Google Drive ","permalink":"https://www.jemoka.com/posts/kbhaibridge_course_website/","tags":null,"title":"AIBridge Course Website"},{"categories":null,"contents":"Part 1: ML Training Practice One of the things that makes a very good Sommelier is their ability to figure out as much details about a wine as possible with very little information.\nYou are tasked with making a Sommelier program that is able to figure both the type and quality of wine from available chemical information. Also, you have a \u0026ldquo;flavor-ater\u0026rdquo; machine that makes a linear combination of multiple chemical features together (similar to PCA), which is counted as one chemical feature after combination.\nA good Sommelier uses as little information as possible to deduce the quality and type. So, what is the best model(s) you can build for predicting quality and type of wine based on the least amount of features? What features should you choose?\nGood luck!\nPart 2: ML Project Walk-through Create your own machine learning experiement! Begin with a problem in your field; go through the available/your own data, determine what type of problem it is, and discuss why machine learning could be a good solution for the problem. Research/quantify the baselines in the field for the task (remembering our discussion on ML validation methods), and determine a list of possible features of your data.\nIf we were to help collect data together, how can we best collect a representative sample? How expensive (resources, monetary, or temporal) would it be? What are some ethical issues?\nSelect the features in the data available to you that would be most relavent (this time you are not trying to minimize the features, but select the most appropriate ones), and the model/training mechanism you think would be most appropriate.\nFinally, present your thinking! Share with us a few (1-3) slides on Friday afternoon. If you have additional time, possibly train the model on baseline data!\n","permalink":"https://www.jemoka.com/posts/kbhaibridge_final_project/","tags":null,"title":"AIBridge Final Project"},{"categories":null,"contents":"SPOILER ALERT for future labs!! Don\u0026rsquo;t scroll down!\nWe are going to create a copy of the iris dataset with a random variance.\nimport sklearn from sklearn.datasets import load_iris Let\u0026rsquo;s load the iris dataset:\nx,y = load_iris(return_X_y=True) Because we need to generate a lot of random data, let\u0026rsquo;s import random\nimport random Put this in a df\nimport pandas as pd df = pd.DataFrame(x) df 0 1 2 3 0 5.1 3.5 1.4 0.2 1 4.9 3.0 1.4 0.2 2 4.7 3.2 1.3 0.2 3 4.6 3.1 1.5 0.2 4 5.0 3.6 1.4 0.2 .. ... ... ... ... 145 6.7 3.0 5.2 2.3 146 6.3 2.5 5.0 1.9 147 6.5 3.0 5.2 2.0 148 6.2 3.4 5.4 2.3 149 5.9 3.0 5.1 1.8 [150 rows x 4 columns] Let\u0026rsquo;s make 150 random numbers with pretty low variance:\nrandom_ns = [random.uniform(65,65.2) for _ in range(0, 150)] random_series = pd.Series(random_ns) random_series 0 65.127515 1 65.034572 2 65.123271 3 65.043985 4 65.145743 ... 145 65.036410 146 65.157172 147 65.034925 148 65.037373 149 65.042466 Length: 150, dtype: float64 Excellent. Now let\u0026rsquo;s put the two things together!\ndf[\u0026#34;temp\u0026#34;] = random_series df 0 1 2 3 temp 0 5.1 3.5 1.4 0.2 65.127515 1 4.9 3.0 1.4 0.2 65.034572 2 4.7 3.2 1.3 0.2 65.123271 3 4.6 3.1 1.5 0.2 65.043985 4 5.0 3.6 1.4 0.2 65.145743 .. ... ... ... ... ... 145 6.7 3.0 5.2 2.3 65.036410 146 6.3 2.5 5.0 1.9 65.157172 147 6.5 3.0 5.2 2.0 65.034925 148 6.2 3.4 5.4 2.3 65.037373 149 5.9 3.0 5.1 1.8 65.042466 [150 rows x 5 columns] And, while we are at it, let\u0026rsquo;s make new labels\nnames = pd.Series([\u0026#34;sepal length\u0026#34;, \u0026#34;sepal width\u0026#34;, \u0026#34;pedal length\u0026#34;, \u0026#34;pedal width\u0026#34;, \u0026#34;temp\u0026#34;]) df.columns = names df sepal length sepal width pedal length pedal width temp 0 5.1 3.5 1.4 0.2 65.127515 1 4.9 3.0 1.4 0.2 65.034572 2 4.7 3.2 1.3 0.2 65.123271 3 4.6 3.1 1.5 0.2 65.043985 4 5.0 3.6 1.4 0.2 65.145743 .. ... ... ... ... ... 145 6.7 3.0 5.2 2.3 65.036410 146 6.3 2.5 5.0 1.9 65.157172 147 6.5 3.0 5.2 2.0 65.034925 148 6.2 3.4 5.4 2.3 65.037373 149 5.9 3.0 5.1 1.8 65.042466 [150 rows x 5 columns] Excellent. Let\u0026rsquo;s finally get the flower results.\ndf[\u0026#34;species\u0026#34;] = y df sepal length sepal width pedal length pedal width temp species 0 5.1 3.5 1.4 0.2 65.127515 0 1 4.9 3.0 1.4 0.2 65.034572 0 2 4.7 3.2 1.3 0.2 65.123271 0 3 4.6 3.1 1.5 0.2 65.043985 0 4 5.0 3.6 1.4 0.2 65.145743 0 .. ... ... ... ... ... ... 145 6.7 3.0 5.2 2.3 65.036410 2 146 6.3 2.5 5.0 1.9 65.157172 2 147 6.5 3.0 5.2 2.0 65.034925 2 148 6.2 3.4 5.4 2.3 65.037373 2 149 5.9 3.0 5.1 1.8 65.042466 2 [150 rows x 6 columns] And dump it to a CSV.\ndf.to_csv(\u0026#34;./iris_variance.csv\u0026#34;, index=False) Let\u0026rsquo;s select for the input data again:\nX = df.iloc[:,0:5] y = df.iloc[:,5] X sepal length sepal width pedal length pedal width temp 0 5.1 3.5 1.4 0.2 65.127515 1 4.9 3.0 1.4 0.2 65.034572 2 4.7 3.2 1.3 0.2 65.123271 3 4.6 3.1 1.5 0.2 65.043985 4 5.0 3.6 1.4 0.2 65.145743 .. ... ... ... ... ... 145 6.7 3.0 5.2 2.3 65.036410 146 6.3 2.5 5.0 1.9 65.157172 147 6.5 3.0 5.2 2.0 65.034925 148 6.2 3.4 5.4 2.3 65.037373 149 5.9 3.0 5.1 1.8 65.042466 [150 rows x 5 columns] And use the variance threshold tool:\nfrom sklearn.feature_selection import VarianceThreshold sel = VarianceThreshold(0.1) sel.fit_transform(X) 5.1 3.5 1.4 0.2 4.9 3 1.4 0.2 4.7 3.2 1.3 0.2 4.6 3.1 1.5 0.2 5 3.6 1.4 0.2 5.4 3.9 1.7 0.4 4.6 3.4 1.4 0.3 \u0026hellip;\nAs we expected.\nAnd let\u0026rsquo;s use the select k best tool:\nfrom sklearn.feature_selection import SelectKBest, chi2 sel = SelectKBest(chi2, k=4) res = sel.fit_transform(X, y) res 5.1 3.5 1.4 0.2 4.9 3 1.4 0.2 4.7 3.2 1.3 0.2 4.6 3.1 1.5 0.2 5 3.6 1.4 0.2 5.4 3.9 1.7 0.4 4.6 3.4 1.4 0.3 5 3.4 1.5 0.2 \u0026hellip;\nAlso, as we expected. Got rid of temp.\n","permalink":"https://www.jemoka.com/posts/kbhaibridge_iris_variance_worksheet/","tags":null,"title":"AIBridge Iris Variance Worksheet"},{"categories":null,"contents":"This is usually not needed if you are using Google Colab. If you are following the instructions provided during our lecture series, please disregard this page.\nHowever, students have expressed interest in working with their own system\u0026rsquo;s copy of Jupyter or local installation. We therefore provide a set of very tenuous instructions for installing the tools used in our session using vanilla C-Python (i.e. not anaconda/conda/miniconda.)\nPython Our tools target Python 3.8+. Use your system\u0026rsquo;s package manager to install Python at least version 3.8, or use Python Foundation\u0026rsquo;s universal installers.\nPackages Python sometimes ships pip, its packaging utility separately. Refer to your own distribution\u0026rsquo;s installation instructions if none of pip or pip3 or python -m pip or python -m pip.\nOnce your copy of pip has been identified, let\u0026rsquo;s move on to\u0026hellip;\nInstalling Packages Here are the packages we will need for our sessions:\nscikit-learn pandas numpy Along with its respective dependencies. Here\u0026rsquo;s a one-liner:\npython3 -m pip install scikit-learn pandas numpy Good luck!\n","permalink":"https://www.jemoka.com/posts/kbhaibridge_packages/","tags":null,"title":"AIBridge Packages and Tools"},{"categories":null,"contents":"Rewa Rai Nitin Lab, Dept. of Food Sci + Tech - Davis\nWine Classification Task Whole data:\nDecision Tree: 98.46% Random Forest: 99.84% Gaussian NB: 97.08% Regression Task Feature selection with 2 best features actually improved.\nTalkthrough Detecting berry infection by leaf classification. Use FTIR spectroscopy as a means of infection classification.\nTana Hernandez PHD Student, Nitin Lab, Dept. of Food Sci + Tech - Davis\nTalkthrough Given input for reaction, predict resulting gell strength from protein+carbo+lactic acid.\nGoal to figure out what features are o predict gell formation. Use feature extraction to reduce the need of doing.\nWet lab task: use high-throughput 96 hole plates to measuring kinetics of absorborance and kinetics. In a single hour, 96 data points can be acquired.\nThen, droplet elements are added to the plates.\nModel: take feature inputs which was selected, classification on gell formation and regression for time for gell.\nJimmy Nguyen PHD Student, Nitin Lab, Dept. of Food Sci + Tech - Davis\nTalk through Need: creating plant-based products which just feels and tastes like actual meet based food.\nTask: given molecular information, classify taste based on like-product and unlike\nLuyao Ma Postdoc Researcher, Nitin Lab, Dept. of Food Sci + Tech - Davis\nTalk thought Problem: lots of antimicrobian resistance in food: on track for 10 million deaths due to antimicrobial resistance. This is caused by antibiotics given to animals, which then is given indirectly to humans. Humans gut bactorials became more more resistant to antibiotics due to antimicrobial bacterial deveolping in animal guts.\nCurrent surveilance systems for antibiotic bacteria: require centralized lab for analysis, data collection is slow, and data integration is very slow (2ish years to publish final results), protocol also changes.\nGoal: rapid in field automatic detection scheme\nExpose wells of bacterial to detect color intensity\n? PHD Student, USDA\nWine Naive bayes (6 RFE features); XE Boost Random Forest + Search with 9 features\nTalkthrough Dietary data Random calls Interested in gut miocrobiome influences. Goal: which factors to predict CAZyme dyvirsetiy?\nRandom forest regression Need for prediction for which features: use Shapley Addadtive for result intepretation.\nYue Wine OH WOWO\nReg:\n99.98 train, 59.788 test.\nBalanced dataset Sequential feature selection PCA -\u0026gt; 3 features Random Forest Something else: ExhaustiveFeatureSelector\nClsf:\nstill 4 features.\nTalkthrough Deep learning, CV applications.\nNutrition product validation so far is entirely manual; current work in bias are mostly political, so finding a ground truth is difficult.\nSupervised is probability difficult; getting the data and cluster.\nSriya Sunil PhD Food Science, Cornell\nWine Decision tree classifier; resulted in 7 features.\n99.97% train, 97.08% test.\nSupport Vector Regression; resulted in 7 features as well.\n39.25% train, 32.79% test.\nTalkthrough Microbial growth on baby spinach. Features: initial counts, prevalence of bacteria, growth of bacteria.\nOutput regression to time to spoilage\n","permalink":"https://www.jemoka.com/posts/kbhaibridge_student_presentations/","tags":null,"title":"AIBridge Student Presentations"},{"categories":null,"contents":"Welcome to the Day-2 Afternoon Lab! We are super excited to work through tasks in linear regression and logistic regression, as well as familiarize you with the Iris dataset.\nIris Dataset Let\u0026rsquo;s load the Iris dataset! Begin by importing the load_iris tool from sklearn. This is an easy loader scheme for the iris dataset.\nfrom sklearn.datasets import load_iris Then, we simply execute the following to load the data.\nx,y = load_iris(return_X_y=True) We use the return_X_y argument here so that, instead of dumping a large CSV, we get the neat-cleaned input and output values.\nLet\u0026rsquo;s inspect this data a little.\nx[0] 5.1 3.5 1.4 0.2 We can see that each sample of the data is a vector in \\(\\mathbb{R}^4\\). They correspond to four attributes:\nseptal length septal width pedal length pedal width What\u0026rsquo;s the output?\ny[0] 0 We can actually see all the possible values of the output by putting it into a set.\nset(y) 0 1 2 There are three different classes of outputs.\nIris Setosa Iris Versicolour Iris Virginica Excellent. So we can see that we have a dataset of four possible inputs and one possible output. Let\u0026rsquo;s see what we can do with it.\nLogistic Regression The simplest thing we can do is a logistic regression. We have a there categories for output and a lot of data for input. Let\u0026rsquo;s figure out if we can predict the output from the input!\nLet\u0026rsquo;s import logistic regression tool first, and instantiate it.\nfrom sklearn.linear_model import LogisticRegression reg = LogisticRegression() We will \u0026ldquo;fit\u0026rdquo; the data to the model: adjusting the model to best represent the data. Our data has 150 samples, so let\u0026rsquo;s fit the data on 140 of them.\ntesting_samples_x = x[-5:] testing_samples_y = y[-5:] x = x[:-5] y = y[:-5] Wonderful. Let\u0026rsquo;s fit the data onto the model.\nreg = reg.fit(x,y) Let\u0026rsquo;s go ahead and run the model on our 10 testing samples!\npredicted_y = reg.predict(testing_samples_x) predicted_y 2 2 2 2 2 And, let\u0026rsquo;s figure out what our actual results say:\ntesting_samples_y 2 2 2 2 2 Woah! That\u0026rsquo;s excellent.\nLinear Regression Instead of predicting the output classes, we can predict some values from the output. How about if we used septal length, width, and pedal length to predict petal width? The output now is a number, not some classes, which calls for linear regression!\nLet\u0026rsquo;s import linear regression tool first, and instantiate it.\nfrom sklearn.linear_model import LinearRegression reg = LinearRegression() We will \u0026ldquo;fit\u0026rdquo; the data to the model again. As we have cleaned out the testing_samples, we simply need to split out the fourth column for the new x and y:\nnew_x = x[:,:3] new_y = x[:,3] new_testing_samples_y = testing_samples_x[:,3] new_testing_samples_x = testing_samples_x[:,:3] Taking now our newly parsed data, let\u0026rsquo;s fit it to a linear model.\nreg = reg.fit(new_x,new_y) Let\u0026rsquo;s go ahead and run the model on our 10 testing samples!\nnew_predicted_y = reg.predict(new_testing_samples_x) new_predicted_y 1.7500734 1.61927061 1.79218767 2.04824364 1.86638164 And, let\u0026rsquo;s figure out what our actual results say:\nnew_testing_samples_y 2.3 1.9 2 2.3 1.8 Close on some samples, not quite there on others. How good does our model actually do? We can use .score() to figure out the \\(r^2\\) value of our line on some data.\nreg.score(new_x, new_y) 0.9405617534915884 Evidently, it seems like about \\(94\\%\\) of the variation in our output data can be explained by the input features. This means that the relationship between septals are not exactly a linear pattern!\nNow you try Download the wine quality dataset Predict the quality of wine given its chemical metrics Predict if its red or white wine given its chemical metrics Vary the amount of data used to .fit the model, how does that influence the results? Vary the amount in each \u0026ldquo;class\u0026rdquo; (red wine, white wine) to fit the model, how much does that influence the results. ","permalink":"https://www.jemoka.com/posts/kbhaibridgelab_d1aft/","tags":null,"title":"AIBridgeLab D2Aft"},{"categories":null,"contents":"Woah! We talked about a lot of different ways of doing classification today! Let\u0026rsquo;s see what we can do about this for the Iris dataset!\nIris Dataset Let\u0026rsquo;s load the Iris dataset! Begin by importing the load_iris tool from sklearn. This is an easy loader scheme for the iris dataset.\nfrom sklearn.datasets import load_iris Then, we simply execute the following to load the data.\nx,y = load_iris(return_X_y=True) We use the return_X_y argument here so that, instead of dumping a large CSV, we get the neat-cleaned input and output values.\nA reminder that there is three possible flowers that we can sort by.\nDecision Trees Scikit learn has great facilities for using decision trees for classification! Let\u0026rsquo;s use some of them by fitting to the Iris dataset.\nLet us begin by importing the SciKit learn tree system:\nfrom sklearn.tree import DecisionTreeClassifier We will fit and instantiate this classifier and fit it to the data exactly!\nclf = DecisionTreeClassifier() clf = clf.fit(x,y) One cool thing about decision trees is that we can actually see what its doing! by looking at the series of splits and decisions. This is a function provided by tree too.\n# We first import the plotting utility from matplotlib import matplotlib.pyplot as plt # as well as the tree plotting tool from sklearn.tree import plot_tree # We call the tree plot tool, which puts it on teh matplotlib graph for side effects plot_tree(clf) # And we save the figure plt.savefig(\u0026#34;tree.png\u0026#34;) Cool! As you can see, by the end of the entire graph, the gini impurity of each node has been sorted to 0.\nApparently, if the third feature (pedal length) is smaller that 2.45, it is definitely the first type of flower!\nCan you explain the rest of the divisions?\nThere are some arguments available in .fit of a DecisionTreeClassifier which controls for when splitting ends; for instance, max_depth controls the maximum depth by which the tree can go.\nExtra Addition! Random Forests. If you recall, we make the initial splitting decisions fairly randomly, and simply select the one with the lowest Ginni impurity. Of course, this makes the selection of the initial sets of splits very important.\nWhat if, instead of needing to make a decision about that now, we can just deal with it later? Well, that\u0026rsquo;s where the addition of Random Forests come in.\nAs the name suggests, instead of having one great tree that does a \u0026ldquo;pretty good\u0026rdquo; job, we can have a lot of trees acting in ensemble! We can randomly start a bunch of random trees, and pick the selection that most would correspond with.\nRandom forests come from the ensemble package from sklearn; we can use it fairly simply:\nfrom sklearn.ensemble import RandomForestClassifier clf = RandomForestClassifier() Wonderful! I bet you can guess what the syntax is. Instead of fitting on the whole dataset, though, we will fit on the first 145 items.\nclf = clf.fit(x[:-5],y[:-5]) We can go ahead and run predict on some samples, just to see how it does on data it has not already seen before!\nclf.score(x[-5:], y[-5:]) 1.0 As you can see, it still does pretty well!\nSVM Let\u0026rsquo;s put another classification technique we learned today to use! Support Vector Machines. The entire syntax to manipulate support vector machines is very simple; at this point, you can probably guess it in yours sleep :)\nLet\u0026rsquo;s import a SVM:\nfrom sklearn import svm Great. Now, we will instantiate it and fit it onto the data. SVC is the support-vector machine classifier.\nclf = svm.SVC() clf.fit(x,y) Excellent, now, let\u0026rsquo;s score our predictions:\nclf.score(x,y) 0.9733333333333334 As you can see, our data is not entirely linear! Fitting our entire dataset onto a linear SVM didn\u0026rsquo;t score perfectly, which means that the model is not complex enough to support our problem.\nScikit\u0026rsquo;s support vector machine supports lots of nonlinearity function; this is set by the argument kernel. For instance, if we wanted a nonlinear, exponential function kernel (where nonlinear function \\(f(x,x\u0026rsquo;)= e^{-\\gamma||\\big\u0026lt;x,x\u0026rsquo;\\big\u0026gt;||^2}\\)), we can say:\nclf = svm.SVC(kernel=\u0026#34;rbf\u0026#34;) clf.fit(x,y) clf.score(x,y) 0.9733333333333334 Looks like our results are fairly similar, though.\nNaive Bayes One last one! Its Bayes time. Let\u0026rsquo;s first take a look at how an Naive Bayes implementation can be done via Scikit learn.\nOne of the things that the Scikit Learn Naive Bayes estimator does differently than the one that we learned via probabilities is that it assumes that\u0026mdash;instead of a uniform distribution (and therefore \u0026ldquo;chance of occurrence\u0026rdquo; is just occurrence divided by count), our samples are normally distributed. Therefore, we have that\n\\begin{equation} P(x_i | y) = \\frac{1}{\\sqrt{2\\pi{\\sigma^2}_y}}e^{\\left(-\\frac{(x_i-\\mu_y)^2}{2{\\sigma^2}_y}\\right)} \\end{equation}\nWe can instantiate such a model with the same exact syntax.\nfrom sklearn.naive_bayes import GaussianNB clf = GaussianNB() clf = clf.fit(x,y) Let\u0026rsquo;s see how it does!\nclf.score(x,y) 0.96 Same thing as before, it seems simple probabilities can\u0026rsquo;t model our relationship super well. However, this is still a fairly accurate and powerful classifier.\nNow you try! Try all three classifiers on the Wine dataset for red-white divide! Which one does better on generalizing to data you haven\u0026rsquo;t seen before? Explain the results of the decision trees trained on the Wine data by plotting it. Is there anything interesting that the tree used as a heuristic that came up? The probabilistic, uniform Naive-Bayes is fairly simple to implement write if we are using the traditional version of the Bayes theorem. Can you use Pandas to implement one yourself? ","permalink":"https://www.jemoka.com/posts/kbhaibridgelab_d3_d4/","tags":null,"title":"AIBridgeLab D3/D4"},{"categories":null,"contents":"Welcome to the Day-3 Morning Lab! We are glad for you to join us. Today, we are learning about how Pandas, a data manipulation tool, works, and working on cleaning some data of your own!\nIris Dataset We are going to lead the Iris dataset from sklearn again. This time, however, we will load the full dataset and parse it ourselves (instead of using return_X_y.)\nLet\u0026rsquo;s begin by importing the Iris dataset, as we expect.\nfrom sklearn.datasets import load_iris And, load the dataset to see what it looks like.\niris = load_iris() iris.keys() dict_keys([\u0026#39;data\u0026#39;, \u0026#39;target\u0026#39;, \u0026#39;frame\u0026#39;, \u0026#39;target_names\u0026#39;, \u0026#39;DESCR\u0026#39;, \u0026#39;feature_names\u0026#39;, \u0026#39;filename\u0026#39;, \u0026#39;data_module\u0026#39;]) We have a pretty large dictionary full of information! Let\u0026rsquo;s pull out data (our input data), target (our output data), and feature_names, the names of our feature.\niris_in = iris[\u0026#34;data\u0026#34;] iris_out = iris[\u0026#34;target\u0026#34;] iris_names = iris[\u0026#34;feature_names\u0026#34;] Data Manipulation pandas is a very helpful utility that allow us to see into data more conveniently. The object that we are usually working with, when using pandas, is called a DataFrame. We can actually create a DataFrame pretty easily. Let\u0026rsquo;s first import pandas\nimport pandas as pd Loading Data We have aliased it as pd so that its easier to type. Awesome! Let\u0026rsquo;s make a DataFrame.\ndf = pd.DataFrame(iris_in) df 0 1 2 3 0 5.1 3.5 1.4 0.2 1 4.9 3.0 1.4 0.2 2 4.7 3.2 1.3 0.2 3 4.6 3.1 1.5 0.2 4 5.0 3.6 1.4 0.2 .. ... ... ... ... 145 6.7 3.0 5.2 2.3 146 6.3 2.5 5.0 1.9 147 6.5 3.0 5.2 2.0 148 6.2 3.4 5.4 2.3 149 5.9 3.0 5.1 1.8 [150 rows x 4 columns] Nice! We have our input data contained in a data frame and nicely printed in a table; cool! However, the column names 1, 2, 3, 4 aren\u0026rsquo;t exactly the most useful labels for us. Instead, then, let\u0026rsquo;s change the column headers to:\niris_names sepal length (cm) sepal width (cm) petal length (cm) petal width (cm) How? We can both get and set the columns via df.columns:\ndf.columns = iris_names Let\u0026rsquo;s look at the DataFrame again!\ndf sepal length (cm) sepal width (cm) petal length (cm) petal width (cm) 0 5.1 3.5 1.4 0.2 1 4.9 3.0 1.4 0.2 2 4.7 3.2 1.3 0.2 3 4.6 3.1 1.5 0.2 4 5.0 3.6 1.4 0.2 .. ... ... ... ... 145 6.7 3.0 5.2 2.3 146 6.3 2.5 5.0 1.9 147 6.5 3.0 5.2 2.0 148 6.2 3.4 5.4 2.3 149 5.9 3.0 5.1 1.8 [150 rows x 4 columns] Excellent! Now our data frame looks much more reasonable.\nWranging Data How do we manipulate the data around? Well, we can index this data by both columns and rows.\nIndexing by columns first is very easy. Pandas tables are, by default, \u0026ldquo;column-major\u0026rdquo;. This means that we can just index the columns just like a list!\ndf[\u0026#34;petal width (cm)\u0026#34;] 0 0.2 1 0.2 2 0.2 3 0.2 4 0.2 ... 145 2.3 146 1.9 147 2.0 148 2.3 149 1.8 Name: petal width (cm), Length: 150, dtype: float64 Nice! I want to know introduce the idea of a \u0026ldquo;cursor\u0026rdquo;. A \u0026ldquo;cursor\u0026rdquo; is used to index this high-dimensional data; think about it as the way to turn this table into something like an indexable 1-D list.\nThe simplest cursor is .loc (\u0026ldquo;locator.\u0026rdquo;)\nUnlike list indexing directly, .loc is \u0026ldquo;row-major:\u0026rdquo; the first index selects rows instead of columns.\ndf.loc[0] sepal length (cm) 5.1 sepal width (cm) 3.5 petal length (cm) 1.4 petal width (cm) 0.2 Name: 0, dtype: float64 Nice! You can see that .loc turned our table into a list, with each \u0026ldquo;sample\u0026rdquo; of the data more clearly represented by indexing it like a list.\nWhat if, then, we want to select the \u0026ldquo;pedal width\u0026rdquo; value inside this sample? We just select the first index, a comma, then select the second index.\ndf.loc[0, \u0026#34;petal width (cm)\u0026#34;] 0.2 Excellent! We can see, because we changed the header columns to be strings, we have to index them like strings.\nWhat if, instead of the first row, we want to get\u0026hellip; say, the first, fifth, and sixth rows? Unlike traditional lists, Pandas\u0026rsquo; cursors can be indexed by a list.\nSo this:\ndf.loc[0] sepal length (cm) 5.1 sepal width (cm) 3.5 petal length (cm) 1.4 petal width (cm) 0.2 Name: 0, dtype: float64 turns into\ndf.loc[[0,2,8,9]] sepal length (cm) sepal width (cm) petal length (cm) petal width (cm) 0 5.1 3.5 1.4 0.2 2 4.7 3.2 1.3 0.2 8 4.4 2.9 1.4 0.2 9 4.9 3.1 1.5 0.1 This would give us the 0th, 2nd, 8th, and 9th row!\nThis is all good, but, it\u0026rsquo;s kind of annoying to type the column names (like \u0026ldquo;petal width (cm)\u0026rdquo;) every time! No worries, we can address this.\niloc is a variant of loc which uses integer indexes. For row indexing, the syntax remains exactly the same; iloc, however, converts all column indexes to integers sequentially. Therefore:\ndf.loc[0, \u0026#34;petal width (cm)\u0026#34;] becomes\ndf.iloc[0, 3] 0.2 Nice! Isn\u0026rsquo;t that convenient.\nSome statistics The main gist of the lab here is to manipulate the input data a little. Pandas provides many helpful utilities to help us with that. For instance, let\u0026rsquo;s take a single feature in the data, say, the pedal with:\npwidth = df[\u0026#34;petal width (cm)\u0026#34;] # same pwidth = df.iloc[:,3], where : returns everything in the row dimention pwidth 0 0.2 1 0.2 2 0.2 3 0.2 4 0.2 ... 145 2.3 146 1.9 147 2.0 148 2.3 149 1.8 Name: petal width (cm), Length: 150, dtype: float64 We can now find out how distributed this data is, to glean some info about normalization! The most basic is for us to find the mean width of the petals:\npwidth.mean() 1.1993333333333336 Awesome! We can calculate the standard by applying this constant to that entire row. The syntax works just like how you expect\u0026mdash;subtracting a scalar from the whole column just subtracts that constant from every element\u0026mdash;without any fuss:\n(((pwidth-pwidth.mean())**2).sum()/len(pwidth))**0.5 0.7596926279021594 Cool! In the scheme of things, that\u0026rsquo;s actually a pretty good. However, if it was not, we could normalize the data!\nLet\u0026rsquo;s first get the norm of the vector\npwidth_norm = sum(pwidth**2)**0.5 pwidth_norm 17.38763928772391 And, let\u0026rsquo;s normalize our vector by this norm!\npwidth_normd = pwidth/pwidth_norm pwidth_normd 0 0.011502 1 0.011502 2 0.011502 3 0.011502 4 0.011502 ... 145 0.132278 146 0.109273 147 0.115024 148 0.132278 149 0.103522 Name: petal width (cm), Length: 150, dtype: float64 Excellent. Let\u0026rsquo;s find out its standard deviation again! This time we will use .std() instead.\npwidth_normd.std() 0.04383790440709825 Much better.\nNow you try Load the wine dataset into a DataFrame and manipulate it. Feed slices back into our functions yesterday! Can you make the subsets of the data you made yesterday via the .iloc notation to make slicing easier? Can you quantify the accuracy, precision, and recall on a shuffled version of the wine dataset and logistic regression? seed=0 Is there any columns that need normalisation? Any outliers (2 std. dev away)? Why/why not? Create a balanced version of the wine dataset between red and white classes. Does fitting this normalized version into our model makes training results better? ","permalink":"https://www.jemoka.com/posts/kbhaibridgelab_d2aft/","tags":null,"title":"AIBridgeLab D3Morning"},{"categories":null,"contents":"Let\u0026rsquo;s run some clustering algorithms! We are still going to use the Iris data, because we are super familiar with it already. Loading it works the exactly in the same way; I will not repeat the notes but just copy the code and description from before here for your reference\nIris Dataset Let\u0026rsquo;s load the Iris dataset! Begin by importing the load_iris tool from sklearn. This is an easy loader scheme for the iris dataset.\nfrom sklearn.datasets import load_iris Then, we simply execute the following to load the data.\nx,y = load_iris(return_X_y=True) We use the return_X_y argument here so that, instead of dumping a large CSV, we get the neat-cleaned input and output values.\nk-means clustering The basics of k-means clustering works exactly the same as before, except this time we have to specify and get a few more parameters. Let\u0026rsquo;s begin by importing k-means and getting some clusters together!\nfrom sklearn.cluster import KMeans Let\u0026rsquo;s instantiate the KMeans cluster with 3 clusters, which is the number of classes there is.\nkmeans = KMeans(n_clusters=3) kmeans = kmeans.fit(x) Great! Let\u0026rsquo;s take a look at how it sorted all of our samples\nkmeans.labels_ 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 2 2 2 2 0 2 2 2 2 2 2 0 0 2 2 2 2 0 2 0 2 0 2 2 0 0 2 2 2 2 2 0 2 2 2 2 0 2 2 2 0 2 2 2 0 2 2 0 Let\u0026rsquo;s plot our results.\nimport matplotlib.pyplot as plt We then need to define some colours.\ncolors=[\u0026#34;red\u0026#34;, \u0026#34;green\u0026#34;, \u0026#34;blue\u0026#34;] Recall from yesterday that we realized that inner Septal/Pedal differences are not as variable as intra Septal/Pedal differences. So, we will plot the first and third columns next to each other, and use labels_ for coloring.\n# for each element for indx, element in enumerate(x): # add a scatter point plt.scatter(element[0], element[1], color=colors[kmeans.labels_[indx]]) # save our figure plt.savefig(\u0026#34;scatter.png\u0026#34;) Nice. These look like the main groups are captured!\nLet\u0026rsquo;s compare that to intended classes\ny 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 There are obviously some clustering mistakes. Woah! Without prompting with answers, our model was able to figure out much of the general clusters at which our data exists. Nice.\nWe can also see the \u0026ldquo;average\u0026rdquo;/\u0026ldquo;center\u0026rdquo; for each of the clusters:\nkmeans.cluster_centers_ 5.9016129 2.7483871 4.39354839 1.43387097 5.006 3.428 1.462 0.246 6.85 3.07368421 5.74210526 2.07105263 Nice! These are what our model thinks are the centers of each group.\nPrinciple Component Analysis Let\u0026rsquo;s try reducing the dimentionality of our data by one, so that we only have three dimensions. We do this, by, again, begin importing PCA.\nfrom sklearn.decomposition import PCA When we are instantiating, we need to create a PCA instance with a keyword n_components, which is the number of dimensions (\u0026ldquo;component vectors\u0026rdquo;) we want to keep.\npca = PCA(n_components=3) Great, let\u0026rsquo;s fit our data to this PCA.\npca.fit(x) Wonderful. singular_values_ is how we can get out of the PCA\u0026rsquo;d change of basis results:\ncob = pca.components_ cob 0.36138659 -0.08452251 0.85667061 0.3582892 0.65658877 0.73016143 -0.17337266 -0.07548102 -0.58202985 0.59791083 0.07623608 0.54583143 So, we can then take a change of basis matrix and apply it to some samples!\ncob@(x[0]) 2.81823951 5.64634982 -0.65976754 What\u0026rsquo;s @? Well\u0026hellip; Unfortunately, Python has different operator for matrix-operations (\u0026ldquo;dot\u0026rdquo;); otherwise, it will perform element-wise operations.\nWe can actually also see the \\(R^2\\) values on each of the axis: the variance explained by each of the dimensions.\npca.explained_variance_ 4.22824171 0.24267075 0.0782095 Nice! As you can see, much of the variance is contained in our first dimension here.\n","permalink":"https://www.jemoka.com/posts/kbhaibridgelab_d4aft/","tags":null,"title":"AIBridgeLab D4Aft"},{"categories":null,"contents":"AIFS is a food systems institute at UC Davis.\n","permalink":"https://www.jemoka.com/posts/kbhaifs/","tags":null,"title":"AIFS"},{"categories":null,"contents":"I am honestly not entirely sure why or what state of mind I was in circa 2017 to write, edit, and act! in this video, but I did.\nThis is an adaption of a Greek-Style story which someone else wrote, I don\u0026rsquo;t know who.\nVideo produced mostly by myself in front of a green screen, with help from my lovely mother as well as a very nice teacher named Joseph O\u0026rsquo;Brian.\nhttps://youtu.be/b1YxOkcwtgw\nBe prepared. 前方高能\n","permalink":"https://www.jemoka.com/posts/kbhair_a_greek_style_myth/","tags":null,"title":"Air: A Greek Style Myth"},{"categories":null,"contents":"algebra is the study of\u0026hellip;\nsymbols/variables transformations/operations: \u0026ldquo;add\u0026rdquo;, \u0026ldquo;multiply\u0026rdquo; simple functions abstraction substitution ","permalink":"https://www.jemoka.com/posts/kbhalgebra/","tags":null,"title":"algebra"},{"categories":null,"contents":"Begin with a new installation of MFA, and head to the directory. First run validate with the original dictionary.\nmfa validate ~/Downloads/tb/my_corpus english_us_arpa english_us_arpa We see that there is in deed an section of corpus that is out-of-vocab.\nINFO - 11 OOV word types INFO - 18 total OOV tokens Therefore, we will generate a new dictionary based on the existing dictionary of english_us_arpa.\nFirst download the english_us_arpa model\nmfa model download g2p english_us_arpa Then, perform the actual dictionary generation:\nmfa g2p english_us_arpa ~/Downloads/tb/my_corpus ~/Downloads/tb/my_corpus/new_dict.txt There is a chance this command fails with\nThere was an issue importing Pynini, please ensure that it is installed. If you are on Windows, please use the Windows Subsystem for Linux to use g2p functionality. If so, install pynini\nconda add pynini Finally, run the mfa g2p command above to generate pronunciations.\nYou should end up with a file named new_dict.txt, which should include missing words.\nFinally, perform alignment with this new dictionary.\nmfa align ~/Downloads/tb/my_corpus ~/Downloads/tb/my_corpus/new_dict.txt english_us_arpa ~/Downloads/tb/my_corpus_output Notice here the second argument of mfa align is no longer english_us_arpa, our base dictionary. Instead, it is our custom dictionary.\n","permalink":"https://www.jemoka.com/posts/kbhalign_with_new_vocab/","tags":null,"title":"Align with New Vocab"},{"categories":null,"contents":" Want to interview more severe ashma Want to find someone younger Difference between marketing and purchaser.\nTaking to people Spoke with Matt. Talked with more details with prototyping and how they can build a unique product.\nHave not gotten back to him yet.\n","permalink":"https://www.jemoka.com/posts/kbhalivio_april_checkin/","tags":null,"title":"Alivio April Checkin"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhanatomy/","tags":null,"title":"anatomy"},{"categories":null,"contents":"anatomy learning is the learning of anatomy.\nAnatomy information acquired prior to medical school has a positive correlation in medical school outcomes. Also leveraging anatomy information.\n","permalink":"https://www.jemoka.com/posts/kbhanatomy_learning/","tags":null,"title":"anatomy learning"},{"categories":null,"contents":"Angelman Syndrome is a syndrome is ~1 in 15000, clinically recognizable, developmental delay syndrome.\ncause of Angelman Syndrome Angelman Syndrome is primarily caused by the UBE3A and the ubiquitin proteasome system. Poly-ubiquitin chain asks to discard cells.\n","permalink":"https://www.jemoka.com/posts/kbhangelman_syndrome/","tags":null,"title":"Angelman Syndrome"},{"categories":null,"contents":"Need-finding conversation Main idea: testing?\u0026mdash;pregnancy testing and COVID testing\ntalking to longer-scope challenges in visually impaired community Navigation; transportation Cannot see markers on smaller steps; trying to find an uber drive and cannot reorient ","permalink":"https://www.jemoka.com/posts/kbhanna_s_team_checkin/","tags":null,"title":"Anna's Team Checkin"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhanotehuaoeu/","tags":null,"title":"anotehuaoeu"},{"categories":null,"contents":"Anoushka is a student at Nueva, also the host of Project80, among other things.\n","permalink":"https://www.jemoka.com/posts/kbhanoushka_krishnan/","tags":null,"title":"Anoushka Krishnan"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhanthony_badger/","tags":null,"title":"Anthony Badger"},{"categories":null,"contents":"DOI: 10.3389/fnagi.2020.607449\nOne-Liner oral lexical retrieval works better than qualitative narrative analysis to classify dementia; and semantic fluency + Disfluency features chucked on an SVM returns pretty good results.\nNovelty Tried two different assays of measuring linguistic ability: oral lexical retrieval metrics, and qualitative discourse features analysis of speech.\nNotable Methods Subjects divided into three groups\nGreat cog. decline Impaired but stable Healthy controls Administered BNT and SVF tests as baseline\nKey Figs Table 3 This figure tells us that the percentages of unrelated utterances was a statistically significant metric to figure differences between the three experimental groups.\n(CD, CS, HC: cognitive decline, cognitively stable (but declining normally), healthy control)\n(no other items are bolded)\nTable 4 This figure tells us the disfluency features analyzed. None of them were independently statistically significant.\nTable 5 This figure tells us that analyzing Semantic Verbal Fluency, plus the information of disfluency, trained on an SVM, actually shows \u0026gt;90% recall value?\nNew Concepts Discourse-Completion Task oral lexical retrieval discourse features modalization Semantic Verbal Fluency Boston Naming Test ","permalink":"https://www.jemoka.com/posts/kbhantonsson_2021/","tags":["ntj"],"title":"Antonsson 2021"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhany_name_here/","tags":null,"title":"any name here"},{"categories":null,"contents":"AP Phys C Mech is an examination held by the CollegeBoard in mechanics.\nThings to Study Permittivity of free space Impulse Springs! In general. Perhaps review old notes. How to be faster? Kepler\u0026rsquo;s Laws of Planetary Motion\n","permalink":"https://www.jemoka.com/posts/kbhap_phys_c_mech_index/","tags":["index"],"title":"AP Phys C Mech Index"},{"categories":null,"contents":"AP Statistics is an examination by the CollegeBoard.\nSee also crap to remember for AP Stats\nNon-Focus Mistakes file:///Users/houliu/Documents/School Work/The Bible/APStats/APStats5Steps.pdf file:///Users/houliu/Documents/School Work/The Bible/APStats/APStats5Steps.pdf file:///Users/houliu/Documents/School Work/The Bible/APStats/APStats5Steps.pdf Interpretation of regression outputs Backlog Chi-square file:///Users/houliu/Documents/School Work/The Bible/APStats/APStats5Steps.pdf file:///Users/houliu/Documents/School Work/The Bible/APStats/APStats5Steps.pdf Notes confidence interval hypothesis testing t-statistics chi-square data inference binomial distribution ","permalink":"https://www.jemoka.com/posts/kbhapstats/","tags":["index"],"title":"AP Statistics Index"},{"categories":null,"contents":"If we take entangled qubits, and separate them real far away, their behavior would be the same even despite it will take longer for light to travel.\n","permalink":"https://www.jemoka.com/posts/kbhapr_paradox/","tags":null,"title":"APR Paradox"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhaps/","tags":null,"title":"APS"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbharthur_m_schlesinger/","tags":null,"title":"Arthur M. Schlesinger"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhasbmb/","tags":null,"title":"ASBMB"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhasee_prism/","tags":null,"title":"ASEE Prism"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhasip/","tags":null,"title":"ASIP"},{"categories":null,"contents":"ASR are tech that helps make transcripts from speech\n","permalink":"https://www.jemoka.com/posts/kbhasr/","tags":null,"title":"ASR"},{"categories":null,"contents":"associative means that operations can be grouped in any way as long as order is preserved.\nThat is:\n\\begin{equation} (AB)C = A(BC) \\end{equation}\n","permalink":"https://www.jemoka.com/posts/kbhassociative/","tags":null,"title":"associative"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhasymtotic_analysis/","tags":null,"title":"asymtotic analysis"},{"categories":null,"contents":"You can use atoms as many different types of qubits.\nmanipulating physical qubits To make physical qubits go to different states, we will again use something in the ancillary states. Rotating it to \\(z\\) \u0026mdash; leverage one lazer to make it fall; \\(rx\\), \\(ry\\), we leverage combinations of two light.\nvarious qubit implementations Implementations of physical qubits\nType Superconductor Ions Atoms Company Google, IBM, Rigetti IonQ, Honeywell Atom Computing, QuEra Nature Artifical Natural Natural Calibration Individual calibration Naturally calibrated Naturally calibrated Coherence Time Short Long Long Connectivity Adjacent connectivity All-to-all More than adjacent Scalability Compatible with existing tech Not easily scalable Potentially scalable Speed Fast gates Kinda fast Untested possible uses for qubits Here are some possible uses for physical qubits\nTraveling salesman Research + simulations Cryptography ","permalink":"https://www.jemoka.com/posts/kbhatoms_as_qubits/","tags":null,"title":"atoms as qubits"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhauthoritarianism/","tags":null,"title":"Authoritarianism"},{"categories":null,"contents":"autism is a spectrum disorder that are caused by both environmental and genetic factors.\nKey Question: how can different chromatin regulators lead to the same set of symptoms named \u0026ldquo;autism\u0026rdquo;.\nautism gene signature The gene signature of autism can be measured in clean and quantitative assays.\n","permalink":"https://www.jemoka.com/posts/kbhautism/","tags":null,"title":"autism"},{"categories":null,"contents":"Key sequence In this chapter, we defined complex numbers, their definition, their closeness under addition and multiplication, and their properties These properties make them a field: namely, they have, associativity, commutativity, identities, inverses, and distribution. notably, they are different from a group by having 1) two operations 2) additionally, commutativity and distributivity. We then defined \\(\\mathbb{F}^n\\), defined addition, additive inverse, and zero. These combined (with some algebra) shows that \\(\\mathbb{F}^n\\) under addition is a group (bonus! its also commutative). Lastly, we show that there is this magical thing called scalar multiplication in \\(\\mathbb{F}^n\\) and that its associative, distributive, and has an identity. New Definitions complex number addition and multiplication of complex numbers subtraction and division of complex numbers field: \\(\\mathbb{F}\\) is \\(\\mathbb{R}\\) or \\(\\mathbb{C}\\) power list \\(\\mathbb{F}^n\\): F^n coordinate addition in \\(\\mathbb{F}^n\\) additive inverse of \\(\\mathbb{F}^n\\) \\(0\\): zero scalar multiplication in \\(\\mathbb{F}^n\\) Results and Their Proofs properties of complex arithmetic commutativity associativity identities additive inverse multiplicative inverse distributive property properties of \\(\\mathbb{F}^n\\) addition in \\(\\mathbb{F}^n\\) is associative addition in \\(\\mathbb{F}^n\\) is commutative addition in \\(\\mathbb{F}^n\\) has an identity (zero) addition in \\(\\mathbb{F}^n\\) has an inverse scalar multiplication in \\(\\mathbb{F}^n\\) is associative scalar multiplication in \\(\\mathbb{F}^n\\) has an identity (one) scalar multiplication in \\(\\mathbb{F}^n\\) is distributive Question for Jana No demonstration in exercises or book that scalar multiplication is commutative, why? Interesting Factoids You can take a field, look at an operation, and take that (minus the other op\u0026rsquo;s identity), and call it a group (groups (vector spaces (fields ))) ","permalink":"https://www.jemoka.com/posts/kbhaxler_a/","tags":null,"title":"Axler 1.A"},{"categories":null,"contents":"DOI: 10.3389/fnagi.2021.635945\nOne-Liner extracted lexicographic and syntactical features from ADReSS Challenge data and trained it on various models, with BERT performing the best.\nNovelty ???????\nSeems like results here are a strict subset of Zhu 2021. Same sets of dataprep of Antonsson 2021 but trained on a BERT now. Seem to do worse than Antonsson 2021 too.\nNotable Methods Essentially Antonsson 2021\nAlso performed MMSE score regression. Key Figs Table 7 training result This figure shows us that the results attained by training on extracted feature is past the state-of-the-art at the time.\nTable 4 These tables tells us the feature extracted\n","permalink":"https://www.jemoka.com/posts/kbhbalagopalan_2021/","tags":["ntj"],"title":"Balagopalan 2021"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhbatchalign/","tags":null,"title":"batchalign"},{"categories":null,"contents":"Things to include Rev How to handle interspersed results Utterance segmentation Why --prealigned and the overall performance of MFA Beginning/End Bullet and why we throw away Rev\u0026rsquo;s output fixbullets and manual utterance segmentation \u0026amp;*INV= interspersed comments ","permalink":"https://www.jemoka.com/posts/kbhbatchalign_paper_outline/","tags":null,"title":"Batchalign Paper Outline"},{"categories":null,"contents":"A binomial distribution is a typo of distribution whose contents are:\nBinary Independent Fixed number Same probability The expected value of \\(X\\) following a binomial distribution is \\(np\\), and the standard deviation of \\(X\\) would be \\(\\sqrt{np(1-p)}\\).\n","permalink":"https://www.jemoka.com/posts/kbhbinomial_distribution/","tags":null,"title":"binomial distribution"},{"categories":null,"contents":"bioinformatics is a field of biology that deals with biology information. Blending CS, Data, Strategies and of course biology into one thing.\nFirst, let\u0026rsquo;s review genetic information\npossible use for bioinformatics Find the start/stop codons of known gene, and determine the gene and protein length ","permalink":"https://www.jemoka.com/posts/kbhbioinformatics/","tags":null,"title":"bioinformatics"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhblack_thursday/","tags":null,"title":"Black Thursday"},{"categories":null,"contents":"The bloch sphere is a sphere encoding all possible probabilities of a qubit shared between two axis, \\(|u\\big\u0026gt;\\) and \\(|d\\big\u0026gt;\\).\nYou will notice that its a unit sphere, in which any magnitude has size \\(1\\). Hence, probabilities would result as projected onto each of the directions.\n","permalink":"https://www.jemoka.com/posts/kbhbloch_sphere/","tags":null,"title":"bloch sphere"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhbluest_eye/","tags":null,"title":"Bluest Eye"},{"categories":null,"contents":"General Information Due Date Topic Important Documents \u0026lt;2022-05-06 Fri\u0026gt; Bluest Eye Essay Bluest Eye Prompt Beauty: discuss Morrison’s treatment of the idea of beauty. From what, where, or whom does this notion come? What effect does it have on the way one perceives the world? On the way others perceive an individual?\nHow does beauty (the acquisition of it, the lack of it, or the presence of it) determine one’s fate in America? Is beauty a necessarily fixed entity or does it fluctuate at the whim of society? How much or to what extent does one’s perception of beauty contribute to one’s sense of self-worth?\nQuotes Bin Beauty Claudia: I had only one desire: to dismember it. To see of what it was made, to discover the dearness, to find the beauty, the desirability that had escaped me, but apparently only me. Pecola: Thrown, in this way, into the binding conviction that only a miracle could relieve her, she would never know her beauty. She would see only what there was to see: the eyes of other people. Maureen: Maureen agreed. \u0026ldquo;Ooooo yes. My mother told me that a girl named Audrey, she went to the beauty parlor where we lived before, and asked the lady to fix her hair like Hedy Lamarr’s, and the lady said, \u0026lsquo;Yeah, when you grow some hair like Hedy Lamarr’s.\u0026rsquo;\u0026rdquo; She laughed long and sweet. (post pecola beat-up) Pauline (Polly): Along with the idea of romantic love, she was introduced to another—physical beauty. In equating physical beauty with virtue, she stripped her mind, bound it, and collected self-contempt by the heap. Pauline (Polly) cont\u0026rsquo;d: She was never able, after her education in the movies, to look at a face and not assign it some category in the scale of absolute beauty, and the scale was one she absorbed in full from the silver screen. Pauline (Polly): More and more she neglected her house, her children, her man\u0026mdash;\u0026hellip;the dark edges that made the daily life with the Fishers lighter, more delicate, more lovely \u0026hellip; Here she found beauty, order, cleanliness, and praise. Pauline (Polly): Pauline kept this order, this beauty, for herself, a private world, and never introduced it into her storefront, or to her children. Cholly after Aunt Death: The funeral banquet was a peal of joy after the thunderous beauty of the funeral. It was like a street tragedy with spontaneity tucked softly into the corners of a highly formal structure. Soaphead Church: He thought it was at once the most fantastic and the most logical petition he had ever received. Here was an ugly little girl asking for beauty. A surge of love and understanding swept through him, but was quickly replaced by anger. Claudia (reflecting on Pecola): All of our waste which we dumped on her and which she absorbed. And all of our beauty, which was hers first and which she gave to us. Eyes a: Her eyes are full of sorrow. She sings to me: \u0026ldquo;When the deep purple falls over sleepy garden walls, someone thinks of me\u0026hellip;.\u0026rdquo; ** Sub-Claim Synthesis There\u0026rsquo;s always the UCLA Writing Lab.\n","permalink":"https://www.jemoka.com/posts/kbhenglish_bluest_eye/","tags":null,"title":"Bluest Eye Essay Planning"},{"categories":null,"contents":"A secondary source comparison activity for the Bluest Eye\nTony Morrison\u0026rsquo;s Rootedness That, if an action were to be done as in a community, its regarded as safer It is a very personal grief and a personal statement done among people you trust. Done within the context of the community, therefore safe.\nPublic (white-washed) and private image, by necessesity, is separated it\u0026rsquo;s just important that it be private. And then, whatever I do that is public can be done seriously.\nthat people are only defined by the uniqueness they have out of the tribe My single solitary and individual Jifejs like the lives of the tribe; it differs in these specific ways, but it is a balanced life because it is both solitary and representative\nPurpose of the novel is enlightening as well as an art form It should have something in it that enlightens; something in it that opens the door arid points the way. Something in it that suggests what the conflicts are, what the problems are.\nThe Novel is a middle class art form The history of the novel as a form began when there was a new class, a middle class, to read it; it was an art form that they needed.\nThat there is already a form of artistry for the lower class, but not middle class The lower classes didn\u0026rsquo;t need novels at that time because they had an art form already they had songs and dances, and ceremony, and gossip, and celebrations.\nnovels of manners tell people of a different world we call 1t the novel of manners, an art form designed to tell peole something they didn\u0026rsquo;t know.\nPortrays quintessential forms of connection How to get married. What a good living was.\nThe African Americans became unexclusive For a long time, the art form that was healing for Black people was music. That music is no longer exclusively ours; we don\u0026rsquo;t have exclusive rights to it.\nThat the story of the novel is told where the reader constructs the story together To construct the dialogue so that it is heard. So that there are no adverbs attached to them: \u0026ldquo;loudly,\u0026rdquo; \u0026ldquo;softly,\u0026rdquo; \u0026ldquo;he said menacingly.'\nThat the artistry is not described as Black but inherently black Black, because it uses the characteristics of Black art\n","permalink":"https://www.jemoka.com/posts/kbhsecondary_source_comparison_activity/","tags":null,"title":"Bluest Eye: secondary source comparison activity"},{"categories":null,"contents":"BNT is a discourse task where subjects are shown 60 pictures decreasing frequency and asked to recall the word.\n","permalink":"https://www.jemoka.com/posts/kbhboston_naming_test/","tags":null,"title":"Boston Naming Test"},{"categories":null,"contents":"Way of performing action research developed by Victoria Clarke and Virginia Braun in 2006\n","permalink":"https://www.jemoka.com/posts/kbhbraun_and_clarke_thematic_analysis/","tags":null,"title":"Braun and Clarke thematic analysis"},{"categories":null,"contents":"Professor Brian Macwinney is a professor of psychology, modern languages, and language technology at CMU.\n","permalink":"https://www.jemoka.com/posts/kbhbrian_macwinney/","tags":null,"title":"Brian Macwinney"},{"categories":null,"contents":"Brown v. Board of Education is a landmark case in the US. This lead for schools to be integrated, and many children were taken out of school out of protest due to the subsequent integration movement between schools.\n","permalink":"https://www.jemoka.com/posts/kbhbrown_v_board_of_education/","tags":null,"title":"Brown v. Board of Education"},{"categories":null,"contents":"A cancer drug to synthesize Fluoropyrimidine.\n","permalink":"https://www.jemoka.com/posts/kbhcapecitabmine/","tags":null,"title":"Capecitabmine"},{"categories":null,"contents":"A category is defined as:\ncollection of objects, where if \\(X\\) is an object of \\(C\\) we write \\(X \\in C\\) ","permalink":"https://www.jemoka.com/posts/kbhcategory/","tags":null,"title":"category"},{"categories":null,"contents":"An abstract study of mathematics based on categories, functors, and natural transformations.\n","permalink":"https://www.jemoka.com/posts/kbhcategory_theory/","tags":null,"title":"category theory"},{"categories":null,"contents":"stock market crash of 1929 At October 24th, 1929, Black Thursday took place, and the stock market crashed. During this time, a record of 13 million shares traded, over $3b of losses. This began a 4 year slide of the global economy.\nCrash theories:\ndemand-driven theory Monetarist theory bank failures of 1929 Banks became irrelevant. Lots of risky loans given out, farmers are taken out huge loans and the banks can\u0026rsquo;t deal.\nother factors economy of credit tariffs ","permalink":"https://www.jemoka.com/posts/kbhcauses_of_the_great_depression/","tags":null,"title":"causes of the Great Depression"},{"categories":null,"contents":"\u0026ldquo;If sample size is large, the sampling distribution is normal. The larger \\(N\\) is, the more normal the resulting shape is.\n","permalink":"https://www.jemoka.com/posts/kbhcentral_limit_theorem/","tags":null,"title":"central limit theorem"},{"categories":null,"contents":" 80% of the human genome is actually transcribed very little \u0026ldquo;junk DNA\u0026rdquo; 40% IncRNA are gene specific ","permalink":"https://www.jemoka.com/posts/kbhchanges_to_central_dogma/","tags":null,"title":"changes to central dogma"},{"categories":null,"contents":"\\(\\chi^2\\) is a test statistic for hypothesis testing.\nmotivation for chi-square The motivation for chi-square is because t-test (means, \u0026ldquo;is the value significantly different\u0026rdquo;) and z-test (proportion, \u0026ldquo;is the incidence percentage significantly different\u0026rdquo;) all don\u0026rsquo;t really cover categorical data samples: \u0026ldquo;the categories are distributed in this way.\u0026rdquo;\nTake, for instance, if we want to test the following null hypothesis:\nCategory Expected Actual A 25 20 B 25 20 C 25 25 D 25 25 \\(\\alpha = 0.05\\). What do we use to test this??\n(hint: we can\u0026rsquo;t, unless\u0026hellip;)\nEnter chi-square.\nchi-square test chi-square test is a hypothesis test for categorical data. It is responsible to translate differences in distributions into p-values for significance.\nBegin by calculating chi-square after you confirmed that your experiment meets conditions for inference (chi-square test).\nOnce you have that, look it up at a chi-square table to figure the appropriate p-value. Then, proceed with normal hypothesis testing.\nBecause of this categorical nature, chi-square test can also be used as a homogeneity test.\nconditions for inference (chi-square test) random sampling expected value for data must be \\(\\geq 5\\) sampling should be \\(\u0026lt;10\\%\\) or independent chi-square test for homogeneity The chi-square test for homogeneity is a test for homogeneity via the chi-square statistic.\nTo do this, we take the probability of a certain outcome happening\u0026mdash;if distributed equally\u0026mdash;and apply it to the samples to compare.\nTake, for instance:\nSubject Right Hand Left Hand Total STEM 30 10 40 Humanities 15 25 40 Equal 15 5 20 Total 60 40 100 We will then figure the expected outcomes:\nRight Left 24 16 24 16 12 8 Awesome! Now, calculate chi-square with each cell of measured outcomes. Calculate degrees of freedom by (num_row-1)*(num_col-1).\nchi-square test for independence The chi-square test for independence is a test designed to accept-reject the null hypothesis of \u0026ldquo;no association between two variables.\u0026rdquo;\nEssentially, you leverage the fact that \u0026ldquo;AND\u0026rdquo; relationships are multiplicative probabilities. Therefore, the expected outcomes are simply the multiplied/fraction of sums:\ncalculating chi-square \\begin{equation} \\chi^2 = \\frac{(\\hat{x}_0-x_0)^2}{x_0} +\\frac{(\\hat{x}_1-x_1)^2}{x_1} + \\cdots + \\frac{(\\hat{x}_n-x_n)^2}{x_n} \\end{equation}\nWhere, \\(\\hat{x}_i\\) is the measured value and \\(x_i\\) is the expected value.\n","permalink":"https://www.jemoka.com/posts/kbhchi_square/","tags":null,"title":"chi-square"},{"categories":null,"contents":"Chiara Marletto is an physicist working on Quantum mechanics working in D. of Physics, Wolfson College, University of Oxford.\nSubfield: constructor theory. She studies quantum theory.\n","permalink":"https://www.jemoka.com/posts/kbhchiara_marletto/","tags":null,"title":"Chiara Marletto"},{"categories":null,"contents":"I was digging through my OneDrive recently for work, and found this piece of writing.\nThere is naught but a small, dirt-filled puddle in front of this lawn. Yet only here – by the puddle – can Gary find a small, much-needed respite from the neverending work. Of course, without the hours he has committed to the sweatshop, his mother would have died ages ago from colora.\nBut how does it matter now? Rarely now \u0026ndash; once every year \u0026ndash; does he even earn the privilege to exit the heavily-guarded area to visit his mother; and how little time he has during such visits: each visit seems to just be a long walk, a knock, a kiss on the cheek \u0026ndash; then back to the workhouse he goes.\nNo, he must push on. Focusing his tired mind back to the concrete structure in front of him, he sees the supervisor hollering the same old phrase. Back to work! Back to work! Move! Move! Break is over!\nWhat is this break, even? The notable lack of timepieces around the lawn means the important task of timekeeping falls to the supervisors \u0026ndash; who, notably, have an obvious interest in shortening the break. And ‘lo, the breaks are shortened: Gary has always remembered the session as until the bottom of the clock, yet doubtless he will find himself staring at a clock hand pointing to the horizontal upon walking into the building.\nHe can do nothing now: there is one \u0026ndash; and the ultimate \u0026ndash; sanction for not listening to the supervisor, and he wants nothing to do with it: beating. Beating that gets harder, faster, as time progresses is the one, the only, and the final answer to all cases of disobedience. Heck, if the supervisor demands time run backwards during breaks, Cronus will listen and obey \u0026ndash; for even he, a god, is probably as scared of these “correctional sessions” as anyone else.\nThere is, then, no time to be wasted. Up towards the factory he walks \u0026ndash; joined by hundreds of others suffering a similar fate, doing the same tedious, repetitive tasks as him. If he hadn\u0026rsquo;t been made dependent \u0026ndash; addicted! in fact \u0026ndash; to the meager wages he received, he could have achieved greatness the world has yet to see.\nBut, alas, towards the factory he walks, steps. Timidly, slowly, shuffling his feet quickly enough so as to not anger the increasingly stressed supervisor. Stressed understandably, perhaps, due to the increasing external talk of organizing such congregations as the “Child Labour Committee”, which Gary himself isn’t sure to what extent he should trust.\nThe quarter-bell strikes. Indeed, his suspicions were correct \u0026ndash; yet superfluous. When all was thought and done, he couldn\u0026rsquo;t possibly have even produced the thought of defying the wishes of the supervisor, let along execute it. But now, he has not even the physical capacity to escape \u0026ndash; the door was locked, and locked means work eternal \u0026ndash; at least until the next meager halt seemingly few decades later.\nSuddenly, a clicking occurs. A machine screeching to a halt, perhaps due to the same overwork and misuse. In walks the supervisor: nevermind that: the work must go on!\nIt is now down to the same routine \u0026ndash; picking the smallest, nimblist of the bunch \u0026ndash; Gary, of course \u0026ndash; to, through great persuasion and threatenings of beatings, climb under the mechanical beast and undo the mess. It’s a dance of oil and gear that Gary has rehearsed many times before, each time dreading the next. Yet he still brought himself to perform the task time and time again for it, although dreadful, seems to be heavenly compared to the alternate: getting the “correctional session.”\nDown the cover he goes: a little pulling there, a little dabbing there, and Hark! The machine jumped to a start with a splash of brilliant pink hue, announcing \u0026ndash; celebrating, it seems \u0026ndash; itself as Gary’s final quarters.\nNevermind that: the work must go on!\n","permalink":"https://www.jemoka.com/posts/kbhchild_labour/","tags":null,"title":"Child Labour: A Short Story"},{"categories":null,"contents":"DOI: 10.3389/fpsyg.2020.623237\nOne-Liner (thrice) Used features extracted by VGGish from raw acoustic audio against a SVM, Perceptron, 1NN; got \\(59.1\\%\\) classif. accuracy for dementia Then, trained a CNN on raw wave-forms and got \\(63.6\\%\\) accuracy Then, they fine-tuned a VGGish on the raw wave-forms and didn\u0026rsquo;t report their results and just said \u0026ldquo;we discovered that audio transfer learning with a pretrained VGGish feature extractor performs better\u0026rdquo; Gah! Novelty Threw the kitchen sink to process only raw acoustic input, most of it missed; wanted 0 human involvement. It seems like last method is promising.\nNotable Methods fine-tuning VGGish against raw acoustic waveforms to build a classifier via a CNN.\nKey Figs Their fancy network Its just a CNN afaik with much maxpooling; could have used some skipped connections. I wonder if it overfit?\nTheir actual training results Looks generally pretty bad, but a run of their DemCNN seem to have gotten state-of-the-art results. Not sure where transfer training data went.\nNew Concepts VGGish Notes Accuracy question According to this the state of the art at the time from pure audio was 56.6%? For a binary classifier isn\u0026rsquo;t that just doing nothing?\nSo somebody did get better before?\n","permalink":"https://www.jemoka.com/posts/kbhchlasta_2021/","tags":["ntj"],"title":"Chlasta 2021"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhchromatin/","tags":null,"title":"chromatin"},{"categories":null,"contents":"civil rights movement starting civil rights moment was kicked off by the Rosa Parks incident, which caused the Montomery Bus Boycott.\nMartin Luther King capitalized the incident to kick start civil rights movement. He employed the method of nonviolence movement.\neducational integration in the civil rights movement K-12 disintegration: Brown v. Board of Education University of Georgia was the first disintegrated university in the south service integration in the civil rights movement Lunch counter boycotts. Nashville became the first desegregated lunch counter.\nSNICK SNICK is a student organization founded by Ella Baker in the civil rights movement that sent students into the most dangerous areas of segregation and leading protests.\nMotown Records Motown Records is an African-American owned Detroit record business\nMalcom X A civil rights movement activist, calling for more violent forms of protest and prosecuting specific white actions. Malcom X and Martin Luther King contradicted each other in methods of active persecution vs. nonviolent integration.\nBloody Sunday Bloody Sunday was a voting rights march from Selma to Montgomery. Peaceful protesters were attacked with nightsticks and tear gas. The event was widely televised: transforming the movement as a televised morality play.\nNonviolence helps getting the clergy leaders as a form of leveraging religion in a show of unity.\nBlack Power Movement A new chapter in the civil rights movement which incorporated less of the elements of integration but instead in wanted more sense of self-determination. nonviolence movement, which the Black Power Movement overrided, had ran its course when Martin Luther King was assassinated.\n","permalink":"https://www.jemoka.com/posts/kbhcivil_rights/","tags":null,"title":"civil rights movement"},{"categories":null,"contents":"A part of the New Deal programs for unmarried men to go and build American infrastructure outdoors under reasonably harsh conditions. \u0026ldquo;Kind of like boy scouts for adults.\u0026rdquo; It is structured like the military; Black men were segregated and not given leadership roles.\n1933-1942.\n","permalink":"https://www.jemoka.com/posts/kbhcivillian_conservation_corps/","tags":null,"title":"Civillian Conservation Corps"},{"categories":null,"contents":"to be closed means that the operation of a group applied to an element of a group would produce another element of the group.\n","permalink":"https://www.jemoka.com/posts/kbhclosed/","tags":null,"title":"closed"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhcmu/","tags":null,"title":"CMU"},{"categories":null,"contents":"A brain signal to help maintain glucose homeostatis\nBrain takes glucose product + glucose uptake to control energy balance in food intake and energy expenditure.\nThe brain takes:\nNeural Behavioral Hormonal responses to maintain glucode uptake.\n","permalink":"https://www.jemoka.com/posts/kbhcns_regulation/","tags":null,"title":"CNS regulation"},{"categories":null,"contents":"The time it takes for a qubit to oscillate between two states between damping down.\n","permalink":"https://www.jemoka.com/posts/kbhcoherence_time/","tags":null,"title":"coherence time"},{"categories":null,"contents":"The cold war is a period of time in which there is blocks of conflict. This is after WWII.\nSee also:\ncold war in vietnam ","permalink":"https://www.jemoka.com/posts/kbhcold_war/","tags":null,"title":"cold war"},{"categories":null,"contents":"A fact sheet on the progress of the cold war in Vietnam.\nprogression of US escalation in the war, an overview Reading: encyclopedia Britannica\n1959-1960: VCs initiated a group of ambushes which the exiled government led by Ngô Đình Diệm can no longer fend off 1961: Kennedy takes office, institutes a plan to put American advisors at all levels of Vietnam leadership 1963: Buddest monks rebelled, Ngô family rule became bizarre and leveraged their Roman Catholic views to persecute Buddhists in the region 1963: Ngô Đình Diệm is assassinated after the support of the US (Kennedy) via Cable 243 seeking a regime change 1963: Kennedy assisinated 1964: Vietnam situation worsens 1965: American government fully went in, and Ky was eased out of power when Neuyen Van Thieu ad full control 1965: US fighting was effective though unpresistent; viet cong just went in after US leaves 1967: Protests in the US lead to a growing anti-war sentiment, which the VietCong picked up on 1968: the Tet Offensive, a VietCong operation, tried to pillage South Vietnam. Though it failed, strong anti-war sentiments were stirred. 1969: Anti-War protests pick up force 1970: Ohio National Guard opens fire on unarmed protesters 1973: Peace Pact Signed after the US giving up, essentially 1975: Saigon falls, US evacuates anti-war protest motivation in Vietnam Reading: Protest against the War in Vietnam\nThe first protests rose in the 1950 and picked up force by the late 1960s when LBJ decided not to seek re-election.\nForeign policy is usually hard to change, but the strength of domestic dissent in Vietnam represents an usual shift which drove foreign policy changes.\nRight-wing sentiment: seeing the war as a means of future-proofing the American government from Communistic influences. Left-wing protest More organized than the spontaneous of the right-wing protest Split between moralistic + legalistic interests vs. national interest domestic political influence of the Vietnam War Reading: The War that Killed Trust, Karl Marlantes, 2017\n\u0026ldquo;Of course presidents lie\u0026rdquo;\u0026mdash;that the Vietnam War represented the shift away from genuine truthfulness as a part of American politics Killed 58,000 service-members, and made Americans cynical and distrustful of governmental institutions Systemic Cynicism Johnson\u0026rsquo;s \u0026ldquo;credibility gap\u0026rdquo;: that the president maybe lying. Nowadays this is commonplace, but back then it was quite unusual.\nCLAIM: engendered Cynicism threatened inaction.\nRacial Integration The cold war promised higher degrees of racial integration because of collective service.\nRepeated Touring That, post-draft, the American working class became much more likely to serve \u0026ldquo;voluntarily\u0026rdquo; by being recruited. Unlike the draft, which is some ways is universal service, the volunteer system is much more reliant upon th emiddle class.\nsocial impacts of the Vietnam War Reading: The Social Impact of War, Modell and Haggerty, 1991\nWars\u0026rsquo; effects can be treated with a lens of social manifestation The Vietnam war had an impact on the last 20 years of primary war literature draft The draft is the principle mechanism by which people into the war. The system facilitating the draft in the United States, the Selective Service System, is a good case study for such a system in the Vietnam War.\nBy its design, the draft is supposed to be an equitable process (baring gender and age.) However, the Vietnam War reveals that the military services was not straightforwardly distributed: often drafting children of lower socioeconomic status.\nexperience of servicemen in Vietnam Soldiers in the Vietnam War have shown some negative psychological side effects. Solders are shown to be \u0026ldquo;working through\u0026rdquo; the ideas to process, creating a larger effects.\neffects on the economy War veterans generally had higher incomes than non-vets, mostly because they have more income per level of educational attanment.\nhistoriographical school of Vietnam War Reading: James McLeroy, Small Wars Journal, (Army Special Forces Officer in I Corps, Vietnam, in 1968)\nOrthodox treatment Vietnam War as an extension/afterthought of late-20th century cold war history\nVietnam War escalated only because of United States involvement \u0026ldquo;anti-war\u0026rdquo; is not opposition against communistic conquest but opposition against war in itself Revisionist treatment Vietnam War as a calculable implementation of escalator revolutionary strategy modeled after Mao.\nVietnam War is not an insurgency or a civil war, but instead a part of the three-step guerrilla warfare Provocation of the United States is a part of the strategy\u0026mdash;to force them to move out of Vietnam and to encourage the communist bloc to provide more support ","permalink":"https://www.jemoka.com/posts/kbhcold_war_in_vietnam/","tags":null,"title":"cold war in vietnam"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhcollectivist_economy/","tags":null,"title":"Collectivist Economy"},{"categories":null,"contents":"College application is the process of applying to an American college.\n","permalink":"https://www.jemoka.com/posts/kbhcollege_application/","tags":null,"title":"college application"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhcollegeboard/","tags":null,"title":"CollegeBoard"},{"categories":null,"contents":"commutativity means that the same operation can be ran in any order.\nThat is:\n\\begin{equation} ABC = ACB \\end{equation}\n","permalink":"https://www.jemoka.com/posts/kbhcommutivity/","tags":null,"title":"commutativity"},{"categories":null,"contents":"A complex number is a type of number. They are usually written as \\(a+bi\\).\nFormally\u0026mdash;\n\\begin{equation} \\mathbb{C} = \\left\\{a+bi\\ \\middle |\\ a,b \\in \\mathbb{R} \\right\\} \\end{equation}\nconstituents an order pair of two elements \\((a,b)\\) where \\(a,b\\in \\mathbb{R}\\).\nrequirements there are 6. For all statements below, we assume \\(\\alpha = a+bi\\) and \\(\\beta=c+di\\), \\(\\lambda = e+fi\\), where \\(a,b,c,d,e,f \\in \\mathbb{R}\\) and therefore \\(\\alpha, \\beta,\\lambda \\in \\mathbb{C}\\).\ncommutativity \\(\\alpha + \\beta = \\beta + \\alpha\\) and \\(\\alpha\\beta = \\beta\\alpha\\) for all \\(\\alpha,\\beta \\in \\mathbb{C}\\).\nProof of complex number commutativity We desire \\(\\alpha + \\beta = \\beta + \\alpha\\).\n\\begin{align} \\alpha + \\beta \u0026amp;= (a+bi)+(c+di) \\\\ \u0026amp;=(a+c)+(b+d)i \\\\ \u0026amp;=(c+a)+(d+b)i \\\\ \u0026amp;=(c+di) + (a+bi) \\\\ \u0026amp;=\\beta+\\alpha\\ \\blacksquare \\end{align}\nleveraging the commutativity inside real numbers.\nInsights: combining and splitting\nThis proof has the feature of combining, operating (commuting, here), the splitting.\nassociativity \\((\\alpha +\\beta) + \\lambda = \\alpha + (\\beta +\\lambda)\\) and \\((\\alpha\\beta) \\lambda = (\\alpha \\beta) \\lambda\\)\nProven via the same trick from last time\nidentities \\(\\lambda + 0 = \\lambda\\), \\(\\lambda 1 = \\lambda\\)\nProof of complex number additive identity We desire that \\(\\lambda + 0 = 0\\).\n\\begin{align} \\lambda + 0 \u0026amp;= (e+fi) + (0+0i) \\\\ \u0026amp;= (e+0) + (f+0)i \\\\ \u0026amp;= e+fi\\ \\blacksquare \\end{align}\nmultiplicative identity is proven in the same way\nadditive inverse \\(\\forall \\alpha \\in \\mathbb{C}, \\exists !\\ \\beta \\in \\mathbb{C}: \\alpha + \\beta = 0\\)\nProof of complex number additive inverse We desire to claim that \\(\\forall \\alpha \\in \\mathbb{C}, \\exists !\\ \\beta \\in \\mathbb{C}: \\alpha + \\beta = 0\\), specifically that there is a unique \\(\\beta\\) which is the additive inverse of every \\(\\alpha\\).\nTake a number \\(\\alpha \\in \\mathbb{C}\\). We have that \\(\\alpha\\) would then by definition be some \\((a+bi)\\) where \\(a,b \\in \\mathbb{R}\\).\nTake some \\(\\beta\\) for which \\(\\alpha + \\beta = 0\\); by definition we again have \\(\\beta\\) equals some \\((c+di)\\) where \\(c,d \\in \\mathbb{R}\\).\n\\(\\because \\alpha + \\beta =0\\), \\(\\therefore (a+bi) + (c+di) = 0\\). \\(\\therefore (a+c) + (b+d)i = 0\\) \\(\\therefore a+c = 0, b+d = 0\\) \\(\\therefore c = -a, d = -b\\) We have created a unique definition of \\(c,d\\) and therefore \\(\\beta\\) given any \\(\\alpha\\), implying both uniqueness and existence.\nInsights: construct then generalize\nIn this case, the cool insight is the construct and generalize pattern. We are taking a single case \\(\\alpha\\), manipulating it, and wrote the result we want in terms of the constituents of \\(\\alpha\\). This creates both an existence and uniqueness proof.\nmultiplicative inverse \\(\\forall \\alpha \\in \\mathbb{C}, \\alpha \\neq 0, \\exists!\\ \\beta \\in \\mathbb{C} : \\alpha\\beta =1\\)\nThis is proven exactly in the same way as before.\ndistributive property \\(\\lambda(\\alpha+\\beta) = \\lambda \\alpha + \\lambda \\beta\\ \\forall\\ \\lambda, \\alpha, \\beta \\in \\mathbb{C}\\)\nProof of complex number distributive property We desire to claim that \\(\\lambda(\\alpha+\\beta) = \\lambda \\alpha + \\lambda \\beta\\).\n\\begin{align} \\lambda(\\alpha+\\beta) \u0026amp;= (e+fi)((a+bi)+(c+di))\\\\ \u0026amp;=(e+fi)((a+c)+(b+d)i)\\\\ \u0026amp;=((ea+ec)-(fb+fd))+((eb+ed)+(fa+fc))i\\\\ \u0026amp;=ea+ec-fb-fd+(eb+ed+fa+fc)i\\\\ \u0026amp;=ea-fb+ec-fd+(eb+fa+ed+fc)i\\\\ \u0026amp;=(ea-fb)+(ec-fd)+((eb+fa)+(ed+fc))i\\\\ \u0026amp;=((ea-fb)+(eb+fa)i) + ((ec-fd)+(ed+fc)i)\\\\ \u0026amp;=(e+fi)(a+bi) + (e+fi)(c+di)\\\\ \u0026amp;=\\lambda \\alpha + \\lambda \\beta\\ \\blacksquare \\end{align}\nInsights: try to remember to go backwards\nAt some point in this proof I had to reverse complex addition then multiplication, which actually tripped me up for a bit (\u0026ldquo;how does i distribute!!!\u0026rdquo;, etc.) Turns out, there was already a definition for addition and multiplication of complex numbers so we just needed to use that.\nadditional information addition and multiplication of complex numbers \\begin{align} (a+bi) + (c+di) \u0026amp;= (a+c)+(b+d)i \\\\ (a+bi)(c+di) \u0026amp;= (ac-bd)+(ad+bc)i \\end{align}\nwhere, \\(a,b,c,d\\in\\mathbb{R}\\).\nsubtraction and division of complex numbers Let \\(\\alpha, \\beta \\in \\mathbb{C}\\), and \\(-a\\) be the additive inverse of \\(\\alpha\\) and \\(\\frac{1}{\\alpha}\\) be the multiplicative inverse of \\(\\alpha\\).\nsubtraction: \\(\\beta-\\alpha = \\beta + (-\\alpha)\\) division: \\(\\frac{\\beta}{\\alpha} = \\beta\\frac{1}{\\alpha}\\) Simple enough, subtraction and division of complex numbers is just defined by applying the inverses of a number to a different number.\ncomplex numbers form a field See properties of complex arithmetic, how we proved that it satisfies a field.\n","permalink":"https://www.jemoka.com/posts/kbhcomplex_number/","tags":null,"title":"complex number"},{"categories":null,"contents":"complexity theory is a theory in algorithms to analyze time classes.\nWe know that \\(O(n\\ log\\ n)\\) is between \\(O(n)\\) and \\(O(n^2)\\) \u0026mdash; so we can roughly call it \u0026ldquo;polynomial time.\u0026rdquo;\nSince the optimal comparison cannot be faster than polynomial time, we say that comparison-based sorting is a polynomial-time algorithm.\nFrom this information, we can come up with two main time classes: \\(P\\) for solutions with known polynomial time, \\(NP\\) for non-deterministic polynomial time.\nThink of it as \\(P\\) is solvable with polynomial time and \\(NP\\) is verifiable with polynomial time.\nThe cool thing about \\(NP\\) problems is that solving a subset of them (\u0026quot;\\(NP\\) hard\u0026quot; problems) solves all \\(NP\\) problems.\nreduction (algorithms) reduction is how you can use \\(NP-hard\\) problems to solve all \\(NP\\) problems in complexity theory.\nSay, multiplication:\nsay you have a basic algorithm to add we can perform multiplication by asking our black box addition algorithm to add \\(n\\) times in complexity theory terms, this means addition is \u0026ldquo;at least as hard\u0026rdquo; as multiplication. Because, if we can solve any addition problem, we can solve any multiplication problem. \u0026ldquo;Given this, do that.\u0026rdquo;\nproblem classes (see above)\n\u0026ldquo;Polynomial time\u0026rdquo; \\(P\\) \u0026mdash; problems solvable with polynomial time \u0026ldquo;Non-deterministic polynomial time\u0026rdquo; \\(NP\\) \u0026mdash; problem verifiable with polynomial time \u0026ldquo;Exponential time\u0026rdquo; \\(EXPTIME\\) \u0026mdash; problems that can only be solved in exponential time \u0026ldquo;2 Exponential time\u0026rdquo; \\(2EXPTIME\\) \u0026mdash; class of problems that takes \\(2^{2^n}\\) time to solve Space complexity works in a similar way.\n\\(P\\) and \\(NP\\) are deterministic and non-deterministic in context to a Turing machine.\nFundamentally, \\(P\\) and \\(NP\\) only apply to decision problems\u0026mdash;given a problem, output \u0026ldquo;yes\u0026rdquo; or \u0026ldquo;no.\u0026rdquo; However, this definition can be stretched: sorting is a decision problem, because it can be stated as \u0026ldquo;given an unsorted array, can you verify whether or not an array is sorted\u0026rdquo;\n","permalink":"https://www.jemoka.com/posts/kbhcomplexity_theory/","tags":null,"title":"complexity theory"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhcomposite_system/","tags":null,"title":"composite system"},{"categories":null,"contents":"conceptual grammar is the proposed universal grammar which connects semantic primes. In theory, this grammar is universal across languages.\nThere are three main categories of conceptual grammars:\nCombinatorics (connecting one idea to another) Account of valancies? #what Propositional complementation (location \u0026ldquo;something that happen in this place\u0026rdquo; ","permalink":"https://www.jemoka.com/posts/kbhconceptual_grammar/","tags":null,"title":"conceptual grammar"},{"categories":null,"contents":"Current automated lexicography (term definition) techniques cannot include contextual or new term information as a part of its synthesis. We propose a novel data harvesting scheme leveraging lead paragraphs in Wikipedia to train automated context-aware lexicographical models. Furthermore, we present ConDef, a fine-tuned BART trained on the harvested data that defines vocabulary terms from a short context. ConDef is determined to be highly accurate in context-dependent lexicography as validated on ROUGE-1 and ROUGE-L measures in an 1000-item withheld test set, achieving scores of 46.40% and 43.26% respectively. Furthermore, we demonstrate that ConDef\u0026rsquo;s synthesis serve as good proxies for term definitions by achieving ROUGE-1 measure of 27.79% directly against gold-standard WordNet definitions.Accepted to the 2022 SAI Computing Conference, to be published on Springer Nature\u0026rsquo;s Lecture Notes on Networks and Systems Current automated lexicography (term definition) techniques cannot include contextual or new term information as a part of its synthesis. We propose a novel data harvesting scheme leveraging lead paragraphs in Wikipedia to train automated context-aware lexicographical models. Furthermore, we present ConDef, a fine-tuned BART trained on the harvested data that defines vocabulary terms from a short context. ConDef is determined to be highly accurate in context-dependent lexicography as validated on ROUGE-1 and ROUGE-L measures in an 1000-item withheld test set, achieving scores of 46.40% and 43.26% respectively. Furthermore, we demonstrate that ConDef\u0026rsquo;s synthesis serve as good proxies for term definitions by achieving ROUGE-1 measure of 27.79% directly against gold-standard WordNet definitions.\n","permalink":"https://www.jemoka.com/posts/kbhcondef_abstract/","tags":null,"title":"ConDef Abstract"},{"categories":null,"contents":"There are many condition in the Great Depression caused\nby 1932, 1/4 had no work emigration exceeded immigration decrease in American birth increase of mental illness and suicide people create Hooverviles movies and radio became much more popular ","permalink":"https://www.jemoka.com/posts/kbhconditions_in_the_great_depression/","tags":null,"title":"conditions in the Great Depression"},{"categories":null,"contents":"proportional confidence intervals We will measure a single stastistic from a large population, and call it the point estimate. This is usually denoted as \\(\\hat{p}\\).\nGiven a proportion \\(\\hat{p}\\) (\u0026ldquo;95% of sample), the range which would possibly contain it as part of its \\(2\\sigma\\) range is the \\(95\\%\\) confidence interval.\nTherefore, given a \\(\\hat{p}\\) the plausible interval for its confidence is:\n\\begin{equation} \\hat{p} \\pm z^* \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} \\end{equation}\nwhere, \\(n\\) is the sample size, \\(\\hat{p}\\) is the point estimate, and \\(z*=1.96\\) is the critical value, the z-score denoting \\(95\\%\\) confidence (or any other desired confidence level).\nconditions for proportional confidence interval There are the conditions that make a proportional confidence interval work\ndistribution is normal \\(n\\hat{p}\\) and \\(n(1-\\hat{p})\\) are both \\(\u0026gt;10\\) we are sampling with replacement, or otherwise sampling \\(\u0026lt;10\\%\\) of population (otherwise, we need to apply a finite population correction value confidence intervals The expression is:\n\\begin{equation} \\bar{x} \\pm t^* \\frac{s}{\\sqrt{n}} \\end{equation}\nwhere \\(t*\\) is the \\(t\\) score of the desired power level with the correct degrees of freedom; \\(s\\) the sample standard deviation, \\(n\\) the sample size, and \\(\\har{x}\\) the mean.\n","permalink":"https://www.jemoka.com/posts/kbhconfidence_interval/","tags":null,"title":"confidence interval"},{"categories":null,"contents":"constructor theory deals with \u0026ldquo;constructors\u0026rdquo;, a general type of computer.\nconstructor theory can give us a theory of the universal quantum constructor by expanding upon quantum information theory. It allows us to unify quantum and classical information by simply defining operations in terms of counterfactuals exclusively: that a space is entirely defined by what\u0026rsquo;s possible and what\u0026rsquo;s not possible.\nAccording to constructor theory, fundamental laws are not dynamical laws instead are boundary conditions. We can take the boundary conditions to form the most general set of initial conditions.\nyou can conjecture a set of laws is fully complete at some point, you will find something that hits the bounds then you revise the theory ","permalink":"https://www.jemoka.com/posts/kbhconstructor_theory/","tags":null,"title":"constructor"},{"categories":null,"contents":"Cookie Theft is a Discourse-Completion Task that involves describing the following picture:\n","permalink":"https://www.jemoka.com/posts/kbhctp/","tags":null,"title":"Cookie Theft Picture Description Task"},{"categories":null,"contents":"quantum information theory requires manipulating counterfactual information\u0026mdash;not what the current known states are, but what are the next possible states.\nInside physics, there is already a few principles which are counterfactual.\nConservation of energy: a perpetual machine is *impossible Second law: its impossible to convert all heat into useful work Heisenberg\u0026rsquo;s uncertainty: its impossible to copy reliable all states of a qubit With the impossibles, we can make the possible.\n","permalink":"https://www.jemoka.com/posts/kbhcounterfactual/","tags":null,"title":"counterfactual"},{"categories":null,"contents":"\\begin{equation} cov(x,y) = E[XY]-E[X]E[Y] \\end{equation}\n","permalink":"https://www.jemoka.com/posts/kbhcovariance/","tags":null,"title":"covariance"},{"categories":null,"contents":"coveather is a novel consensus algorithm based on the proof of work mechanism.\nSee also minimum user base requirements for coveather and Coveather Abstract.\n","permalink":"https://www.jemoka.com/posts/kbhcoveather/","tags":null,"title":"coveather"},{"categories":null,"contents":"Digital Health Passes (DHP), systems of digitally validating quarantine and vaccination status such as the New York IBM Excelsior Pass, demonstrate a lawful means to approach some benefits offered by \u0026ldquo;true elimination\u0026rdquo; treatment strategies-which focus on the complete elimination of cases instead of investing more in controlling the progression of the disease-of COVID-19. Current implementations of DHPs require region-based control and central storage of Protected Health Information (PHI)-creating a challenge to widespread use across different jurisdictions with incompatible data management systems and a lack of standardized patient privacy controls. In this work, a mechanism for decentralized PHI storage and validation is proposed through a novel two-stage handshaking mechanism update to blockchain proof-of-stake consensus. The proposed mechanism, when used to support a DHP, allows individuals to validate their quarantine and testing universally with any jurisdiction while allowing their right of independent movement and the protection of their PHI. Implementational details on the protocol are given, and the protocol is shown to withstand a 1% disturbance attack at only 923 participants via a Monte-Carlo simulation: further validating its stability.\n","permalink":"https://www.jemoka.com/posts/kbhcoveather_abstract/","tags":null,"title":"Coveather Abstract"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhcram/","tags":null,"title":"cram"},{"categories":null,"contents":"crap to remember for AP Stats is a cram sheet for the AP Statistics exam.\n95% confidence: \\(z^*=1.96\\)\n\\(r=1\\): perfect positive correlation \\(r=-1\\): perfect negative correlation \\(r=0\\): no correlation S: standard deviation of residuals R-sq: how much of varience in dep. var can be explained by indp. var SE: estimate of standard deviation of the random var. that is slope.\nFor lines:\nNote that p value from regression outputs are two-tailed. So divide by 2 if you want a one-tail result.\nMultiplication changes mean as well as well as standard deviation. Adding changes mean but not standard deviation.\nExpected value of the sum and differences of random variables are just the sums and differences of their expected value. \\(S = X+Y, \\bar{S} = \\bar{X}+\\bar{Y}\\).\nVariance of random variables are just the sum and differences of their variance. \\(S=X+Y,{\\sigma^2}_S = {\\sigma^2}_X+{\\sigma^2}_Y\\).\n#WHAPS\nwhat test what hypothesis and what significance level assumptions and conditions; state! random independent: \\(\\le 10\\%\\) of population. t and z special: normal (z tests: \\(np, n(1-p) \\geq 10\\), t tests: \\(n\u0026gt;30\\) or given) chi-square special: \\(\\forall\\ EV \u0026gt; 5\\) p: z-statistic that would XD: Control (control for confounding and bias, placebo, etc.), Randomization (spread uncontrolled variability), Replication (need to have adequate units and ability to be repeated)\n=\u0026gt; Describing a distribution\nCenter: Mean, Median, or Mode? figure by skew Shape: Symmetric vs Skewed? Unimodal vs Bimodal Spread: Range and Inter-Quartile Range Outlier: anything more than 1.5*IQR away Context: what the distribution shows \u0026ldquo;Experimental Unit\u0026rdquo;: a physic entity that\u0026rsquo;s the primary unit of interest in a research objective.\nConditions for binomial distribution:\nBinary Independent Fixed number of trials All trials with same probability Conditions for geometric distrubiton\nBinary Independent Fixed number of successes All trials with same probability state the thing, state the conditions: \u0026ldquo;normal distribution with n= s=\u0026rdquo;, binomial distribution with n= p= etc.\n","permalink":"https://www.jemoka.com/posts/kbhcrap_to_remember_for_ap_stats/","tags":null,"title":"crap to remember for AP Stats"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhcredit/","tags":null,"title":"credit"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhcritical_value/","tags":null,"title":"critical value"},{"categories":null,"contents":"criticized the New Deal from all sides. Senator Huy P. Long claimed to \u0026ldquo;show our wealth.\u0026rdquo; nullification from conservative supreme court, FDR threatened to restructure + hurts his coalition.\nFDR ordered cuts in spending 1938 midterms: Republicans can block programs \u0026mdash; gained control of congress + created ability to gain control ","permalink":"https://www.jemoka.com/posts/kbhcriticism_of_the_new_deal/","tags":null,"title":"criticism of the New Deal (See file KBhnew_deal.org)"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhcultural_revolution/","tags":null,"title":"Cultural Revolution"},{"categories":null,"contents":"For data inference tasks, categorical data\n","permalink":"https://www.jemoka.com/posts/kbhdata_inference/","tags":null,"title":"data inference"},{"categories":null,"contents":"a student approach to learning where learning outcomes are driven by student\u0026rsquo;s own experience to deeply drive educational results independenlty\n","permalink":"https://www.jemoka.com/posts/kbhdeep_approach/","tags":null,"title":"deep approach"},{"categories":null,"contents":"demand-driven theory hypothesis that the reason why the Great Depression took place was because people were not buying stocks, etc, and there was no demand.\nSee also: Monetarist theory.\n","permalink":"https://www.jemoka.com/posts/kbhdemand_driven_theory/","tags":null,"title":"demand-driven theory"},{"categories":null,"contents":"DementiaBank is a shared database of multimedia interactions for the study of communication in dementia. There are a few projects being explored for DementiaBank.\nSee also: ADReSS Literature Survey\n","permalink":"https://www.jemoka.com/posts/kbhdementiabank/","tags":null,"title":"DementiaBank"},{"categories":null,"contents":"Ideas Can we correlate any longitudinal data with NACC?\nData dementia/English/Lanzi: Alyssa Lanzi\u0026rsquo;s new data\ndementia/English/Delaware\nWhat are the standard for acoustic features?\nMotor cortex/frontal control may also be impacted\nVocal tremer\nWhat are the predictors? How automatic can we make it?\n","permalink":"https://www.jemoka.com/posts/kbhdementiabank_acoustics_brainstoming/","tags":null,"title":"DementiaBank Acoustics Brainstoming"},{"categories":null,"contents":"The DementiaBank Acoustics Project is a working title for an acoustic-only challenge for AD detection. This document serves as the lab notebook for this project.\nThis project will attempt to replicate some of the results of Wang 2019 and Martinc 2021, but focusing on minimizing human involvement; we will first work on raw transcript classification with ERNIE (cutting all CHAT annotations), then introduce pause-encoding in a manner similar to Yuan 2021 which is automated by MFA. Goal is to replicate the results of Yuan 2021/or even Martinc 2021 in a completely automated manner.\nBackground Reading I first began by doing a literature survey on the ADReSS Challenge results published in the Frontiers AD special interest group issue.\nProposal And then, we wrote a proposal: DementiaBank Acoustics Project Proposal\nBrainstoming More notes from the meeting: DementiaBank Acoustics Brainstoming\nProtocol Notes July 1st Began by moving a subsample of Pitt\u0026rsquo;s Cookie Theft to pitt-7-1 in the raw data folder Ran flo on all collected samples. Arguments used are the same as that for batchalign, except we filter out the INV tier as we are detecting AD on patient and not investigator: so flo +d +ca +t* -tINV Moved all collected samples (and changed extension to .txt) to the same sub-folder, but in transcripts_nodisfluency July 2nd Created a dataprep script dataprep.py which dumps a pickled copy of cleaned data to transcripts_nodisfluency/pitt-7-1.dat. Created sliding windows of 5 pieces of dialogue concatenated, stored it in transcripts_nodisfluency/pitt-7-1-windowed.dat Used tencent/HuYong\u0026rsquo;s nghuyong/ernie-2.0-en Ernie 2.0 model, the continuous language model from Baidu (Layer:12, Hidden:768, Heads:12) July 4th Finalized training code. Selected base hyperparameters {bs: 8, epochs: 2, lr: 3e-3, length: 60}. Again, we are using Baidu\u0026rsquo;s nghuyong/ernie-2.0-en. Started training fastcalculator on 24bc812 train: faithful-frog-3 {bs: 8, epochs: 2, lr: 3e-3, length: 60, pitt-7-1-windowed.dat }\nCommentary: LR could be too high, looking at the divergent loss behavior. Decision: dropping bs to 4 and lr to 1e-5, similar to previous transformers. Also training for 3 epochs. train: revived-disco-5 {bs: 4, epochs: 3, lr: 1e-5, length: 60, pitt-7-1-windowed.dat }\nCommentary: quintessential overfitting Decision: Made the corpus bigger cleaned the entire Pitt corpus (pitt-7-4 in the raw folder) to become training data. Similar to pitt-7-1, ran flo on all collected samples; arguments used are the same as that for batchalign, except we filter out the INV tier as we are detecting AD on patient and not investigator: so flo +d +ca +t* -tINV; the flo\u0026rsquo;d results are in transcripts_nodisfluency. the notable difference between the previous dataset 7-1 and the current one 7-4 is that the 7-4 are prepended numbered by the task (cookie/100-01.cha \u0026gt; =cookie-100-01.txt) New (full) Pitt data as prepared above is ran though the dataprep script as of b325514cfad79da82d7a519ed29ea19ed87b2be4 (difference is that empty/dummy files are ignored), and pickled at transcripts_nodisfluency/pitt-7-4.dat and transcripts_nodisfluency/pitt-7-4-windowed.dat respectively. For new data, window size is still 5, splitting 10 cases out for testing now instead of 5. train: vocal-oath-6 {bs: 4, epochs: 3, lr: 1e-5, length: 60, pitt-7-4-windowed.dat}\nCommentary: high recall, low precision. Perhaps classes aren\u0026rsquo;t balanced? Spoiler alert: they are not. An inspection of data reveals that there is 3211 rows of dementia, 2397 rows of control Decision: Created pitt-7-4-bal and pitt-7-4-windowed-bal series of data based on dataprep.py on 703f79248a20fd7a13a5033ca2bf7f691f42c941. This version force-crops to make sure that the dementia and control indicies have the exact same length for each class. train: helpful-leaf-7 {bs: 4, epochs: 3, lr: 1e-5, length: 60, pitt-7-4-windowed-bal.dat}\nBeautiful. Question now is whether or not there is data leakage/external heuristics. It is a good time to do some LOOCV. Getting this result without any disfluency calculations seems unlikely.\nBut anyways, going to discuss these results as they seem to meet results we see in Yuan 2021, even without top-N ensemble; though this is one trial, LOOCV may still show that we actually need it.\nJuly 5th Began the day with creating the script k-fold validation; I originally hoped to exactly replicate the procedure of Yuan 2021 for comparability, but, not sure how they got the actual result of a min/max range with LOOCV on binary; therefore, we will instead create a 95% confidence interval analysis via a single-variable t test on standard k-fold validation. K=50 During one-off testing, another set of hyperparameters seems to work too: {bs: 72, epochs: 3, lr: 1e-5, length: 60, pitt-7-4-windowed-bal.dat}. As we have not begun tuning for hyperparameters, we are just going to use this set, K=50, for the first k-fold trial. k-fold: F4ZVbGfdBAQvtvXemWZCZD code: 55f77ff1dea03c3ed66967864dc52fd2c0062f23\n{bs: 72, epochs: 3, lr: 1e-5, length: 60, pitt-7-4-windowed-bal.dat} K = 50\nIt seems like the results we got is consistent and validates in a manner which we expect.\nJuly 7th Yesterday was a day filled with working on batchalign, but we are back now. Today, I aim to look into the heuristic that I identified yesterday by playing with the model, which is that it seems like the model prefers the use of long-focused sentences about cookies, so the heruistic its picking up is probably on-topicness.\nI am going to first leverage the lovely cdpierse/transformers-interpret tool to help build some explainability by adding it to validate.py. Upon some human validation with random sampling, the model seem to do less well than I\u0026rsquo;d hoped. Running a train cycle with the new results/params seen above to see if it does better.\ntrain: brisk-oath-10 {bs: 72, epochs: 3, lr: 1e-5, length: 60, pitt-7-4-windowed-bal.dat}\nCommentary: It seems like the model is doing overall worse from validation data, but it does fairly well during test data. Decision: I can fairly confidently claim that the model is just fitting on topic. As in, if the topic is about cookies (theft/taking/cookie/mother/etc.), it will be classified as control. One thing that we can do is to claim this task as directly task-controlled: that is, include no data except cookie and control for that difference Then, the model would\u0026rsquo;t be able to predict the result b/c the variation in topic won\u0026rsquo;t have influence. This is going to be prepared in the cookiepitt-7-7-bal* based on dataprep.py in commit 518dec82bb961c0a8ad02e3080289b56102aa1a2 train: super-durian-11 {bs: 72, epochs: 3, lr: 1e-5, length: 60, cookiepitt-7-7-windowed-bal.dat}\nCommentary: the model is no where near convergence Decision: multiplying the LR by 10 train: floral-sunset-12 {bs: 72, epochs: 3, lr: 1e-4, length: 60, cookiepitt-7-7-windowed-bal.dat}\nCommentary: There we go. This seem to be more in line with what we see in Yuan 2021 Decision: ok, let\u0026rsquo;s elongate the actual content. Perhaps we can try a 7-element search instead? This is written as cookiepitt-7-7-*-long. Code based on 9e31f4bc13c4bfe193dcc049059c3d9bda46c8d0 train: sweet-plasma-13 {bs: 72, epochs: 3, lr: 1e-4, length: 60, cookiepitt-7-7-windowed-long-bal.dat}\nCommentary: underfitting Dropping batch size down to 64 to add more steps train: smart-river-14 {bs: 64, epochs: 3, lr: 1e-4, length: 60, cookiepitt-7-7-windowed-long-bal.dat}\nCommentary: this finally fits to the specifications which Yuan 2021 have revealed Decision: running k-fold on this architecture k-fold: XgsP4FVS6ScFxCZKFJoVQ5. Code: 3870651ba71da8ddb3f481a7c3e046397a09d8b2\nJuly 8th Began the day with aligning the entirety of cookie for both control and dementia, named the dataset alignedpitt-7-8 in the RAW folder\nPer what we discussed, will add [pause] as a token to the model. Then, transcript the text such that it would contain normalized values to the pauses for pauses \u0026gt; 0.250 seconds. Therefore, the data would look like\n\u0026ldquo;hello my name is [pause] 262 [pause] bob\u0026rdquo;\nJuly 9th Created transcript.py, which coverts the data in raw to transcripts_pauses, which contains pause values \u0026gt; 250 msc and prepends them with [pause] tokens The code from above is taken from check.py in batchalign, used transcript.py from 7e19a4912cf0ad5d269c139da5ce018615495ebb to clean out the dataset; placed it in similar txt format to alignedpitt-7-8 Ran dataprep with window size of 5, created alignedpitt-7-8.bat and alignedpitt-7-8-windowed.bat as the dataprep file starting a new training run, with [pause] added as a new token, code 06846c6c95e6b1ccf17f0660c5da76aa50231567 train: golden-tree-16 {bs: 64, epochs: 3, lr: 1e-4, length: 60, alignedpitt-7-8-windowed.dat}\nSo realistically, we have the same F1 between the two, but pause encoding increased the accuracy of prediction yet dropped recall dramatically.\nAs a random check, let\u0026rsquo;s find out if simple fine-tuning (only training on classifier) would work, so:\ntrain: jumping-blaze-17 {bs: 64, epochs: 3, lr: 1e-4, length: 60, alignedpitt-7-8-windowed.dat}. This time with only training classifier.\nCommentary: we did not like. start coverging Bumping LR by a factor of 10 train: vital-water-18 {bs: 64, epochs: 3, lr: 1e-3, length: 60, alignedpitt-7-8-windowed.dat}. This time with only training classifier.\nCommentary: barely started converging, seem to be a local Training for 2 more epochs train: fiery-smoke-19 {bs: 64, epochs: 5, lr: 1e-3, length: 60, alignedpitt-7-8-windowed.dat}. This time with only training classifier.\nCommentary: classic overfitting At this point, unlocking the model would probably be a good bet\ntrain: leafy-deluge-20 {bs: 64, epochs: 5, lr: 1e-4, length: 60, alignedpitt-7-8-windowed.dat}.\nTraining once again with code without locking, and bump LR down\nCommentary: classic the recall is slowly creeping up Decision: let\u0026rsquo;s go for 8 epochs train: royal-pond-21 {bs: 64, epochs: 8, lr: 1e-4, length: 60, alignedpitt-7-8-windowed.dat}.\nCommentary: let\u0026rsquo;s run k-fold now, with these settings.\nk-fold: QskZWfEsML52ofcQgGujE2. {bs: 64, epochs: 8, lr: 1e-4, length: 60, alignedpitt-7-8-windowed.dat}.\nOk, the base hypothesis from Yuan 2021 is very much confirmed here. The same training, same content, but pause encoding is very beneficial to the quality of the results. The results that they reported contained an ensemble data, which is in the high 80s; we can now continue doing something new as Yuan 2021\u0026rsquo;s conclusion is fairly achieved.\nWe can probably call the replication stage done, with no dramatically better effect.\nJuly 10th FluCalc! Leonid\u0026rsquo;s lovely new program can be an uberuseful feature extraction tool Let\u0026rsquo;s try using to build a new dataset, and network. FluCalc + Pause Encoding + Textual Data late fusion This is becoming alignedpitt-7-8-flucalc. As the program is currently under heavy development to include results from batchalign, we will specify version V 09-Jul-2022 11:00 for now. Done, the new data has the same i/o shape, but then has a bunch of features filtered for nulls which contains outputs from flucalc. Again, alignedpitt-7-8-flucalc from 4346fc07c4707343c507e32786b6769b6bd6fb49 does not take into account results from the %wor tier! July 11th ab19abd6486884141c9ab4e4e185255a77ae833e is the final-ish version of the late fusion model We are going to use alignedpitt-7-8-flucalc to start training train: royal-pond-21 {bs: 64, epochs: 8, lr: 1e-4, length: 60, alignedpitt-7-8-flucalc-windowed.dat}.\nCommentary: overfitting Decision, droping lr by a factor of 10, also increasing length to 70 train: fallen-dust-25 {bs: 64, epochs: 8, lr: 1e-5, length: 70, alignedpitt-7-8-flucalc-windowed.dat}.\nCommentary: overfitting Decision, droping lr by a factor of 10, dropping batch size to 32, training more to 10 train: dainty-meadow-26 {bs: 32, epochs: 10, lr: 1e-6, length: 70, alignedpitt-7-8-flucalc-windowed.dat}.\nah\nAt this point, I think it\u0026rsquo;d be good to do some feature selection Let\u0026rsquo;s do a chi^2 correlation, and select 3 best features import pandas as pd DATA = \u0026#34;/Users/houliu/Documents/Projects/DBC/data/transcripts_pauses/alignedpitt-7-8-flucalc-windowed.bat\u0026#34; # read pickle df = pd.read_pickle(DATA) # test test_data = df[df.split==\u0026#34;test\u0026#34;] # also, get only train data df = df[df.split==\u0026#34;train\u0026#34;] df target mor_Utts ... split utterance trial sample ... 120-2 1049 1 -0.179084 ... train well the boy is getting some cookies handing o... 336-1 2492 0 -0.481740 ... train +oh okay, the the little girl askin(g) for the... 076-4 786 1 -0.179084 ... train well the little boy was looking at that cookie... 279-0 2250 1 1.980274 ... train kid\u0026#39;s stool turnin(g) [pause]540[pause] over s... 014-2 151 1 0.746355 ... train he\u0026#39;s fallin(g) off the chair down here or try... ... ... ... ... ... ... 208-0 1655 0 -0.481740 ... train the boy [pause]920[pause] is going after [paus... 492-0 2696 1 -0.179084 ... train oh yes quite a_lot the kid\u0026#39;s tryin(g) to get t... 497-1 2727 1 0.129396 ... train what else ? \u0026amp;uh the see the [pause]2400[pause]... 175-2 1535 0 0.863668 ... train the window is open you can see out the curtain... 279-0 2261 1 1.980274 ... train the other kid with [pause]610[pause] the stool... [2848 rows x 44 columns] Let\u0026rsquo;s slice out the bits which is labels, etc.\nin_data = df.drop(columns=[\u0026#34;utterance\u0026#34;, \u0026#34;target\u0026#34;, \u0026#34;split\u0026#34;]) in_data.columns Index([\u0026#39;mor_Utts\u0026#39;, \u0026#39;mor_Words\u0026#39;, \u0026#39;mor_syllables\u0026#39;, \u0026#39;#_Prolongation\u0026#39;, \u0026#39;%_Prolongation\u0026#39;, \u0026#39;#_Broken_word\u0026#39;, \u0026#39;%_Broken_word\u0026#39;, \u0026#39;#_Block\u0026#39;, \u0026#39;%_Block\u0026#39;, \u0026#39;#_PWR\u0026#39;, \u0026#39;%_PWR\u0026#39;, \u0026#39;#_PWR-RU\u0026#39;, \u0026#39;%_PWR-RU\u0026#39;, \u0026#39;#_WWR\u0026#39;, \u0026#39;%_WWR\u0026#39;, \u0026#39;#_mono-WWR\u0026#39;, \u0026#39;%_mono-WWR\u0026#39;, \u0026#39;#_WWR-RU\u0026#39;, \u0026#39;%_WWR-RU\u0026#39;, \u0026#39;#_mono-WWR-RU\u0026#39;, \u0026#39;%_mono-WWR-RU\u0026#39;, \u0026#39;Mean_RU\u0026#39;, \u0026#39;#_Phonological_fragment\u0026#39;, \u0026#39;%_Phonological_fragment\u0026#39;, \u0026#39;#_Phrase_repetitions\u0026#39;, \u0026#39;%_Phrase_repetitions\u0026#39;, \u0026#39;#_Word_revisions\u0026#39;, \u0026#39;%_Word_revisions\u0026#39;, \u0026#39;#_Phrase_revisions\u0026#39;, \u0026#39;%_Phrase_revisions\u0026#39;, \u0026#39;#_Pauses\u0026#39;, \u0026#39;%_Pauses\u0026#39;, \u0026#39;#_Filled_pauses\u0026#39;, \u0026#39;%_Filled_pauses\u0026#39;, \u0026#39;#_TD\u0026#39;, \u0026#39;%_TD\u0026#39;, \u0026#39;#_SLD\u0026#39;, \u0026#39;%_SLD\u0026#39;, \u0026#39;#_Total_(SLD+TD)\u0026#39;, \u0026#39;%_Total_(SLD+TD)\u0026#39;, \u0026#39;Weighted_SLD\u0026#39;], dtype=\u0026#39;object\u0026#39;) And the labels:\nout_data = df[\u0026#34;target\u0026#34;] out_data trial sample 120-2 1049 1 336-1 2492 0 076-4 786 1 279-0 2250 1 014-2 151 1 .. 208-0 1655 0 492-0 2696 1 497-1 2727 1 175-2 1535 0 279-0 2261 1 Name: target, Length: 2848, dtype: int64 And now, let\u0026rsquo;s select 3 best features.\nfrom sklearn.feature_selection import SelectKBest, f_classif k_best_tool = SelectKBest(f_classif, k=3) k_best_tool.fit(in_data, out_data) best_features = k_best_tool.get_feature_names_out() best_features %_WWR %_mono-WWR %Total(SLD+TD) OD = other disfluencies; SLD = stuttering-like disfluencies; TD = total disfluencies; WWR = whole-word-repetition\nok, let\u0026rsquo;s select those features\ntrain: visionary-plasma-27 {bs: 32, epochs: 10, lr: 1e-6, length: 70, alignedpitt-7-8-flucalc-windowed.dat}. Also with feature selection.\nhmmm.\nI am curious if we just ran something like a decision tree, what happens.\nin_features = df.drop(columns=[\u0026#34;utterance\u0026#34;, \u0026#34;target\u0026#34;, \u0026#34;split\u0026#34;]) test_features = test_data.drop(columns=[\u0026#34;utterance\u0026#34;, \u0026#34;target\u0026#34;, \u0026#34;split\u0026#34;]) in_targets = df[\u0026#34;target\u0026#34;] test_targets = test_data[\u0026#34;target\u0026#34;] seed the classifier, and fit.\nfrom sklearn.ensemble import RandomForestClassifier clsf = RandomForestClassifier() clsf.fit(in_features, in_targets) clsf.score(test_features, test_targets) 0.5932203389830508 OK nevermind. What about SVC?\nfrom sklearn.svm import SVC clsf = SVC() clsf.fit(in_features, in_targets) clsf.score(test_features, test_targets) 0.5932203389830508 Turns out, deep learning still does better. I\u0026rsquo;m thinking maybe the output is being faulty, say, for something like the loss function.\nDecision: switching activation to sigmoid.\ntrain: sunny-bush-31 {bs: 32, epochs: 10, lr: 1e-6, length: 70, alignedpitt-7-8-flucalc-windowed.dat}, selected features\nOk let\u0026rsquo;s think about this. Decision: added batch normalization.\ntrain: autumn-jazz-32 {bs: 32, epochs: 10, lr: 1e-6, length: 70, alignedpitt-7-8-flucalc-windowed.dat}, selected features\nThe model maybe overfitting on some simple heuristic; some basic statistics revealed that these variables are actually quite differently distributed.\nPerhaps we should increase the complexity of the model?\ntrain: fallen-microwave-33 {bs: 32, epochs: 10, lr: 1e-6, length: 70, alignedpitt-7-8-flucalc-windowed.dat}, selected features\nJust to test, I am bumping the LR to 1e-5, just to see what happens. I am very confused.\ntrain: upbeat-flower-35 {bs: 32, epochs: 10, lr: 1e-5, length: 70, alignedpitt-7-8-flucalc-windowed.dat}, selected features\nThe more we work on this, the more overfit it gets. (I FORGOT A RELUCTIFIER)\na note {bs: 32, epochs: 10, lr: 1e-5, length: 70, alignedpitt-7-11-flucalc-windowed.dat}, selected features\nPauses, no meta:\nPauses, meta:\nso effectively cointoss\nConcerns and Questions July 2nd pitt7-1/dementia/493-0 PAR tier \u0026ldquo;tell me everything you see going on in that picture\u0026rdquo; doesn\u0026rsquo;t seem to be labeled correctly; I am guessing that\u0026rsquo;s supposed to be INV? Has anyone tried to include investigator/participant cross-dialogue? July 4th Is the model overfitting on antiquated language? Is the model overfitting on cooke-theft on-topic-ness? July 11th LSTM only on pauses? ","permalink":"https://www.jemoka.com/posts/kbhdementiabank_acoustics_project/","tags":null,"title":"DementiaBank Acoustics Project"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhdepression/","tags":null,"title":"depression"},{"categories":null,"contents":"Derivat\n","permalink":"https://www.jemoka.com/posts/kbhderivational_words/","tags":null,"title":"derivational words"},{"categories":null,"contents":"A derived variable is a mapping between states to a set, usually the natural numbers. Remember, if we can, given a state and match it to a number and show a relation which would iterate the state and decrease the states\u0026rsquo; number. We can show that the algorithm terminates.\n","permalink":"https://www.jemoka.com/posts/kbhderived_variable/","tags":null,"title":"derived variable"},{"categories":null,"contents":"A health concern relating to glucose and obesity.\n","permalink":"https://www.jemoka.com/posts/kbhdiabetes/","tags":null,"title":"diabetes"},{"categories":null,"contents":"Isn\u0026rsquo;t parts of this equation not differentiable? The equation looks immediately separable, which means we can move the \\(dx\\) term on the bottom towards to the right side.\n","permalink":"https://www.jemoka.com/posts/kbhchallenge_1/","tags":null,"title":"DiffEq: Challenge #1"},{"categories":null,"contents":"Textbooks The textbook that we will be using is (Taylor 2011)\nAssignments Challenge #1 The Unreasonable Effectiveness of Mathematics in the Natural Sciences ","permalink":"https://www.jemoka.com/posts/kbhdiffeq_intro/","tags":["Index"],"title":"Differential Equations"},{"categories":null,"contents":"discourse features are marks of fluency/etc. which mark one\u0026rsquo;s speech.\n","permalink":"https://www.jemoka.com/posts/kbhdiscourse_features/","tags":null,"title":"discourse features"},{"categories":null,"contents":"A Discourse-Completion Task is a tool used to elicit speech acts, such as showing an image, etc. For instance,\ntypes of Discourse-Completion Tasks oral lexical retrival Cookie Theft ","permalink":"https://www.jemoka.com/posts/kbhdiscourse_completion_task/","tags":null,"title":"Discourse-Completion Task"},{"categories":null,"contents":"distributed algorithm is a type of algorithm that can be distributed across many modules.\nThere are a few core areas of research:\nfailure-proofing nodes is a distributed algorithm What if one processor fails? communication in a distributed algorithm What if communication between processors fails? What if timing fails? atomicity atomicity is a property of distributed algorithm where, for a set of steps, a processor can only do one or all of the steps. i.e.: if you are asking a node to do something, it can either do all of the thing or be able to roll back as if the entire thing didn\u0026rsquo;t happen.\nleader election (algorithms) leader election is the process by which a distributed algorithm elects the driving node among similar nodes.\nconsensus (algorithms) consensus is a mechanism in a distributed algorithm where the solution requires multiple processes to do the same calculation to confirm.\nalgorithms designed to be distributed MapReduce ","permalink":"https://www.jemoka.com/posts/kbhdistributed_algorithum/","tags":null,"title":"distributed algorithm"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhdistributed_morphology/","tags":null,"title":"distributed morphology"},{"categories":null,"contents":"Dopamine optical sensor. When dopamine is bound, it floreses and can detect micromolar changes and dopamine concentration.\n","permalink":"https://www.jemoka.com/posts/kbhdlight_1/","tags":null,"title":"dLight 1"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhdopamine/","tags":null,"title":"dopamine"},{"categories":null,"contents":"The dopamine circuitry in NF1.\nGenetically encoded \u0026ldquo;sensors\u0026rdquo; to measure circuits.\n","permalink":"https://www.jemoka.com/posts/kbhdopamine_circuitry_in_nf1/","tags":null,"title":"dopamine circuitry in NF1"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhdouble_slit_experiment/","tags":null,"title":"double slit experiment"},{"categories":null,"contents":"A human gene similar to the gene PreTA found in E. Coli, a bacterial found in microbiome. See effects of PreTA on Fluoropyrimidine, and by proxy Capecitabmine for implications on cancer treatment.\n","permalink":"https://www.jemoka.com/posts/kbhdpyd/","tags":null,"title":"DPYD"},{"categories":null,"contents":"Gah I have to do this. Not for public consumption. California laws 2022 DL600 R7 2022.\nConsequences Not licensed If unlicensed person is drivnig your car, it maybe impounded for 30 days Hired to drive interstate commercially need to be older than 21, also need to be older than 21 to transport hazardous materials Class C License Driving #knw Two axle vehicle with a GVWL of 26,000 lbs or less Three axle vehicle weighing 6,000 lbs or less House car \u0026lt; 40 feet or less Three wheel motocycles Vanpool vehicle designed to carry between 10 and no more than 15 people Towing #knw Single vehicle of 10,000 or less Vehicle weighing 4000 lbs or more unladen Trailer coach under 10,000 lbs Fifth wheel trailer exceeding 10,000 lbs but under 15,000 lbs, with endorsement Mor ethings Class C drivers can\u0026rsquo;t tow more than one Motor vehile weigning under 4000 lbs cannot tow more than 6000 lbs Getting in trouble Get a traffic ticket and fail to show up to court: suspend driving One at fault collision or one at fault traffic violation: may take action? Two of either at fault collision or violation conviction: no driving for 30 days unless accompanied by 25 year old adult Three of \u0026ldquo;\u0026rdquo;: no driving for 6 months, on probation for a year. Drugs or alcohol between 13-21: suspension for a year Minor driving Not sure if this applies\nPractice for 50 hours, 10 hours at night #knw\nPass knowledge test\nPass driving test\nCannot drive between 11P and 5A during the first year #knw\nCannot drive with under 20 Y/O unless 25 Y/O licensed accompanied #knw\nUnless\u0026mdash;\nMedical need with doctor\u0026rsquo;s note and end date School and dean\u0026rsquo;s note Work and employer\u0026rsquo;s note and employment status Family need and parent\u0026rsquo;s note Minors can\u0026rsquo;t use a phone while driving.\nSafe car #knw Working driver\u0026rsquo;s window, brake lights, horn, parking brake, turn signals Safe tire (1/32 inch tread) Full windshield Two rear view mirrors, incl. one on left side Working seatbelts Check: clean windows and mirrors, adjust seat and mirrors, check tires.\nSafe personage Vision Hearing Not tired Not medicated Health: no Lapses of conciseness AD \u0026ldquo;related disorders\u0026rdquo; \u0026mdash; anything the doctor reports to DMV Steering Hand to Hand hands 9/3 or 8/4 oclock Push and pull, hands stay where they are Hand over hand Start 9/3 or 8/4 Turn, but leave wheel sliding under Sliding under hand reach over, pull the wheel up One-hand Turning or backing up to turn back Hand at 12 oclock Limeted use Signaling Arm signals when lights are hard to see because of bright sun\nMotorcyclists use these signals, and bikers point their hand straight up to turning direction\nWhen to signal #knw Signal when: turn, change lanes, slow down, stop.\n100 feet before turning Before every lane change: look over and check blind spot 5 seconds before lane change on highway Pulling next to or away curb Signal even if no cars around you Horning \u0026ldquo;It is safer to slow down or stop instead of honking your horn.\u0026rdquo;\nWhen to horn #knw Avoid collisions Alert hazard Alert oncoming traffic on narrow mountain roads when you cannot see at least 200 feet in front of vehicle Don\u0026rsquo;t use horn to move people along, or \u0026ldquo;express anger.\u0026rdquo; The more ya know.\nHeadlights They are bright.\nWhen to headlight #knw When its too dark to see: if you can\u0026rsquo;t see a person 1000 feet away Beginning 30 minutes after sunset until 30 minutes before sunrise Adverse weather: windshield wipers on = low-beam headlights on Clouds dust smoke or fog prevent seeing other cars On sunny days on country or mountain roads When a white regulatory sign says so To help others see your car, when sun is low on horizon When not to high-beam headlight Dim when 500 feet of car coming towards you or 300 feet of a car you are following Emergency flashers If you can see a collision ahead, do:\nTurn on flashers #knw Lightly tap brake pedal three/four times Use hand signals How to stop in a middle of the road during an emergency #knw Start breaking early.\nGive drivers warning\nTurn on emergency flashers if you earn\u0026rsquo;t moving, or use turn signals\nPull off the road\nStop not on the road or, if isn\u0026rsquo;t possible, stop where people can see\nDon\u0026rsquo;t stop just over a hill\nLift the hook to signal an emergency\nPlace emergency triangles 200-300 feet behind vehicle; use flares if needed but be careful b/c they may cause fire\nCall for roadside assistance\n63, 92\nLanes! Reading \u0026rsquo;em Yellow: different directions Single yellow is the center of the road; cannot cross into oncoming traffic Double solid yellow line: not to be crossed \u0026hellip;except hov entrace lane which has a left entrance Instructed to cross because the road is blocked Entering or exiting a driveway, private road, or making a u-turn 2 double yellow line groups spaced 2 feet or more apart are considered a barrier; under no circumstance is to cross Broken yellow line: you may pass if the broken line is next to you White: same directions Single solid white line: traffic lanes in the same direction Double solid white lines: not to be crossed, regular use vs. preferential use lanes (carpool, etc.) Broken white lines: separate roads with two or more lines in the same direction White triangles: yield lines A line where you should yield. Triangles point to the direction of oncoming traffic (\u0026ldquo;towards you.\u0026rdquo;).\nChoosing \u0026rsquo;em Leftmost lane is lane 1, rightmost is lane n\nUse the left lane to pass or turn left Use the right lane to enter or exit traffic Change lanes when Moving from one lane to another Entering freeway Exiting freeway Entering the road from curb or shoulder Protocol for lane change #knw Signal Look in all mirrors Check traffic beside and behind you Look over solder in direction of desired lane change Check blind spots for other vehicles, motorcyclists, and bicycilsts Ensure room Tips stay in one lane don\u0026rsquo;t weave if you start a change, finish it Types of them Lane closest to the center divider is the \u0026ldquo;passing lane\u0026rdquo; HOV lanes is for high occupancy Center left turn lanes The center of some two-way streets has a left turn lane; marked on both sides by two painted lines. Inner line is broken and outer line is solid.\nYou may only drive 200 feet in the center left turn lane #knw\nProtocol for using this lane\nLook for other vehicles coming towards you in the center left turn lane Signal Look over shoulder Merge completely into the center left turn lane Turn when its safe. Turnouts Areas or lanes for turning that are marked? Use when:\nDriving slowly on a two-lane road where passing is unsafe, AND There are 5 or more vehicles following #knw Bike lanes Bike lanes\nBuffered bike lanes: uses chevrons or diagonals to buffer the bikes\nBike route: shared road markings to designate a preferred route\nBike boulevard: bike travel on streets with cars\nSeperated bikeways: completely different\nBikes share the road \u0026ldquo;sharrows!\u0026rdquo;\nCannot drive in bike lane unless\u0026hellip;.\nParking Entering or leaving road Turning (within 200 feet of intersection) Turning Right Drive close to the edge Drive in a bike lane, wait until about 200 feet to make turn #knw Watch for everybody Signal about 100 feet before #knw Look over sholder Stop behind limit line (/before entering crosswalk or intersection) Look both ways and turn when its safe; don\u0026rsquo;t turn into another lane Complete turn Details:\nCan\u0026rsquo;t turn when red arrow, but you can turn against red light You could cross a bus lane to make a right turn, but you can\u0026rsquo;t drive in it There could be designated right turn lanes which let you make a \u0026ldquo;free right turn\u0026rdquo; Left Drive close to the center divider or left turn lane Signal about 100 feed Look over sholder Stop behind limit line (/before entering crosswalk or intersection) Look left, right, then left Turn Details\nonly can turn against light when single-lane-to-single-lane U Conditions Across double-yellow line In a residential district No cars for 200 feet Whenever a sign or light protects against approachng cars At an intersection On a divided driveway, if opening provided Anticonditions WHen \u0026ldquo;no u-turn\u0026rdquo; is posted\nAt a railroad crossing\nOn a divided highway if needed to cross things\nCannot see 200 feet in each direction\nWhen other cars may hit you\nOn a one-way street\nIn front of a fire station\nooo. scary\nIn business districts, including churches apartments and buildings (except for schools); turn only at an intersection or opening if allowed. Merging Highways Enter at or near traffic speed Merge onto highway when safe to do so, don\u0026rsquo;t stop unless needed Merge into a space large enough for your car to join the lane Use mirrors and turn signals Watch for cars Leave three seconds of space (\u0026ldquo;three second rule\u0026rdquo;) between you and the car in front of you Exiting Know the exist Signal, look over sholder, etc. Change lanes Signal intention for 5 seconds Leave Space for entering You will need about a half a block on city streets Or, a full block on the highway Passing If anybody wants to pass, let them pass\nSpace for passing Don\u0026rsquo;t pass if\u0026hellip;\nYou are approaching a hill and cannot see oncoming traffic Within 100 feet of an intersection #knw At crossroads or driveways Condition of Passing You pass on the left, unless\u0026hellip;\nOpen highway with two or more lanes going in your direction Driver ahead of you is turning left, and you don\u0026rsquo;t have to drive off the road to pass You are on a one-way street Never drive off the road to pass.\nProtocol for passing Signal Shoulder Turn Speed up and pass Retturn Parking Find a space #knw three feet longer that your vehicle Turn on turn signal Pull up alongside the vehicle in front; leave about two feet between you and the car to your right. Stop when you rear bumper is aligned with the front of the space Check rearview mirror, look over sholder, keep foot on break and reverse Back up, 45% When rear view is within 18 inches from the curb, straighten out Set parking break. Leave when safe. Parking on a hill \u0026ldquo;Your car may roll when you breaks fail.\u0026rdquo;\nDownhill: wheels towards the curb Uphill: wheels away from curb No curb: turn towards the sholder of the road \u0026ldquo;towards the sholder, except when uphill with curb\u0026rdquo;\nColors White curb: stop for picking up or dropping off passengers or mails Green curb: park for limited time Yellow: load and unload, staying in the vehicle Red: no stopping Blue: disabled\u0026mdash;fine of $1,000, 6 months in county jail #knw Can\u0026rsquo;t park when No marking Unmarked or marked crosswalk Sidewalk, partially blocking sidewalk, or in front of driveway Within 3 feet of disabled sidewalk ramp #knw On diagnal lines next to disabled space Within 15 feet of a fire hydrant #knw Double parking On the wrong side of the street or freeway, except: 1) emergency 2) law enforcement officer 3) specificaly permitted stop.\nTo stop and park then, park off the pavement, stay with the car and lock the doors until help arrives; visibility is 200 feet in each direction required. #knw\nLights Flashing red: stop sign\u0026ndash;stop and go when its safe Flashing yellow: yield sign\u0026mdash;proceed with caution Flashing yellow arrow: unprotected turn Broken traffic lights become a four way stop sign.\nSigns Stop sign is stop; there should be a limit line; if no limit line, stop before intesection Yield sign is to yield; slow down Right of Way Without stop/yield signs Whomever gets to the intersection first has right of way T intersection without stop/yield signs The through road have right of way Stop signs Stop first, then follow right of way rules as if no intersection Turning left Right of way to anyone approaching that\u0026rsquo;s \u0026ldquo;close enough to be dangerous\u0026rdquo; Turning right Check for pedestrians crossing the street, and bikes and motors next to you Green light Pedestrians Divided highways Vehicles coming in the lane you are about to enter Entering traffic The traffic you are entering Roundabouts The logistics of using a roundabout\nSlow down Yield to traffic Watch for signs Travel in counter-clockwise direction, don\u0026rsquo;t stop or pass Signal when you change lanes or exit If you miss your exit, try again Choosing lane Rightmost for turning right Either lane (\u0026ldquo;middle\u0026rdquo;, if exists) for straight Innermost for left turn or u turn Pedestrians Pedestrians have right-of-way Pedestrian crossing need to cross first, you yield or slow to them Which means\u0026hellip;\nDo not pass a stopped vehicle Don\u0026rsquo;t drive on a sidewalk except to cross it or enter/exit it Don\u0026rsquo;t stop in a crosswalk If people make eyecontact, they are crossing the street Obey pedestrian\u0026rsquo;s signs Watch for seniors, people with disabilities, young children.\nCrosswalks Crosswalks are marked (but not all) School crossings have yellow lines Pedestrians have right of wall in all crosswalks Flashing light crosswalks exists to, just be prepared to stop regardless Blind White canes and guide dogs have absolute right of way Stop at all stop walks Don\u0026rsquo;t stop in the middle of stop walk Don\u0026rsquo;t give verbal directions to blind pedestrian Don\u0026rsquo;t turn right w/o looking for pedestrians Don\u0026rsquo;t honk at a blind person Don\u0026rsquo;t block sidewalk Pulling in cane + stepping away: you may go Mountain roads Uphill car has right of way Downhill car has more control backing up the hill Roadsharing Large cars Average passenter car at 55mph has 400 feet before stopping Large car takes 800 feet Don\u0026rsquo;t move in front of a large car and suddenly stop.\nLook at turn signals: large vehicles may swing their back, say, left in order to turn right.\nDon\u0026rsquo;t\nChange lanes in front of them to reach an exit or turn (tight spaces around large vehicles is dangerous) Drive next to them (unless passing); after you pass, move ahead of it Follow too closely: that\u0026rsquo;s tailgating. Give more space Underestimate the size and speed of the vehicle \u0026ldquo;If you can\u0026rsquo;t see a truck\u0026rsquo;s side mirrors, it can\u0026rsquo;t see you.\u0026rdquo;\nalways pass it on the left side\nBuses and rails when loading is happening without a safety zone, stop behind the nearest door Stopped busses can only be passed at 10mph Don\u0026rsquo;t pass on the left side, unless\u0026hellip; you are on a one-way street tracks are so close to the right you can\u0026rsquo;t pass on the right traffic officer directs you to Never turn in front of a light rail vehicle Check for traffic lights (light rails can interrupt them) Motocycles 4 second following distance Given a motocycle a full lane; its legal to share but its unsafe Don\u0026rsquo;t try to pass a motorcycle in the same lane When possible, move to one side of your lane Check for motocyclists Emergency vehicles Give them right of way: drive to the edge until they\u0026rsquo;ve passed \u0026hellip;except in intersections: never stop in an intersection (continue through and stop) Obey loudspeaker orders Illegal to follow 300 feet of any emergency vehicles with flashing siren Slow cars Slow down for them NEV LSV Like gold carts\nThey have max speed 25mph They can\u0026rsquo;t drive in roads with speed limit larger than 35 mph Bikes Front lamp with white light visible for 300 feet Rear red reflector (visible from 500 feet) White or yellow reflector on each pedal (visible for 200 feet) Travel lanes Must ride to the curb if slow, unless\nPassing in the same direction Preparing to turn left Avoiding a hazard/road condition Approaching right turn On a one way road with two or more lanes (if so, bikers may right next to left curb) Passing bikers 3 feet clearance\nSchool buses Yellow lights flashing is to slow Red lights flashing is to stop If you fail to stop, you can be fined up to $1,000 and driving maybe suspended for a year Workzone fines Traffic violations have fines of $1,000 or more Assulting a worker has a fine of $2,000 plus imprisonment for up to on year Some regions are double-fine zones Speed Limit \u0026ldquo;Basic speed law\u0026rdquo;: you may never drive faster than its safe.\n10mph to pas a roadcar\n15 mph in blind intersections (cannot see 100 in both directions when within 100 feet)\nif your view is blocked in a blind intersection, inch forward until you can see 15 mph also in some school, alleys (roads no wider 25 feet), 100 feet of railroad tracks if visiblity less then 400 feet\n25 mph when you are 500-1000 feet of a school, when crossing the street, residential\n55 mph on two lane undivided highway\nYou cannot block traffic flow\nDrive far-right lane of you are towing\nRailroad Look in both directions Except train anytime Don\u0026rsquo;t stop in traintracks Watch for other cars Stop between 15-50 feet from the neearest tracks Fines and Stuff Smoking with a minor: $100\nDumping animals: $1,000, six months in jail\nEvading law enforcement:\nstate prison up to 7 years, county jail for 1 year Fine between $2,000 and $10,000 Or both Evading law enforcement and commiting manslauter\nImprisonment for 4-10 years Speed content and reckless driving: fine and imprsionment\nTexting\nWear earplugs in bot hyears\nCarry anything that extends beyond the fenders on the left side, or more then 6 inches on the right side\nCargo more the 4 feet must display a 1 feet red or flourencesnt flag\nTransport animals unless secured\nAllow a person to be in a back of a pickup truck unless secured\nDrive a car with a video monitor except when it doesn\u0026rsquo;t face driver\nThrow a cig from the car\nCut signs that block the windshiled\nDon\u0026rsquo;t hang objects on the mirror\nDon\u0026rsquo;t sticker, unless\n7 inch square on lower corner of passengers or rear window 5 inch square on the lower corner of the driver window Side windows behind driver 5 inch located in the center uppermost portion Funeral pocessions have right of way\nPoints 36 month record Suspension when: 4 points in 12 months, 6 in 24, or 8 in 36 Once 18 months to earn back points via traffic school Best Practices Scan road 10-15 seconds ahead of you Don\u0026rsquo;t stare Don\u0026rsquo;t tailgate: 3 seconds between you and the car ahead passes Allow extra space when\u0026hellip; If you have a tailgator, (and move! if you can) The driver behind you wants to pass Slippery Following on icy or wet Towing a trailer Followiing a car that blocks you ahead Merging onto freeway Following Don\u0026rsquo;t stay in the blind spot Don\u0026rsquo;t driving alongside cars Make space when possible Keep space between you and parked cars Be careful when nearing motorcyclists and bicyclists At intersections Look both ways Look left first (vehicles coming from the left are closer) Look right Take one more look to the left 5-10mph on wet road, reduce speed by half on snow, tiny very slow on ice Don\u0026rsquo;t use breaks if starting to hydroplone If you can\u0026rsquo;t see farther than 100 feet, its unsafe to drive faster than 30mph Seat belts Click it or ticket Under 16 years old, you may also get ticket Child safety Under 2 years old: secure in a real facing child restraight system (unless child weighs more than 40 pounds or is more that 3 ft 4 inches taller)\nChilden under 8 years old, less than 4 feet 9 inches tall: secure in a front-facing restraight system\nCould use front seat if there\u0026rsquo;s no rear seat or if they are side facing jump seat\n8 years old or older, or 4 feet 9 inches tall: use seat belts\n6 y/o or younger unattended illegal to leave in car; supervision could be 12 year old.\nHot vehicle can kill\nEmergencies Skids Slippery surface Slowly remove foot from gas pedal Don\u0026rsquo;t use breaks Turn the steering wheel in the direction of the skid If your breaches get wet, dry them by pressing gas and brake at the same time.\nLock wheel Breaking too hard when going to fast: skid no matter steering wheel\nRemove foot from break Straighten front wheel If ABS not working, step on brake gradually until safe speed. If the brake petal sinks to the floor, bump the brakes.\nDriving off pavement Grip wheel slowly Remove your foot from gas Brake gently Check for traffic Steer back Accelerator mallfunction Shift to neutral Apply breakes Look for traffic Honk horn and emergency flashers Drive car off the road Turn of ignition Collision If collision causes more than $1000 in property damage, you msut report to DMV Driving is suspended for 4 years of no insurance Disabled Vehicle Safely pull over Exit on the right side Find assistance Return no vehicle Stay inside with your seat belt Uuse flashers Railroad If a train is coming, get out and run in a 45 degree away from the train and tracks. Dial 911 If train not coming, exit vehicle, dial emergency number on the railroad crossing box, and then call 911 DUI Don\u0026rsquo;t drink and drive Don\u0026rsquo;t take drugs Use any combination of drugs Illegal to drink alcohol or smoke or eat cannabis products while in a car, whether self or passenger. If you are carrying it, it must be full and unopened. If its open, keep it in the trunk.\nLimits 0.08% over 21 0.01% under 21 0.01% under DUI probation 0.04% if commercial 0.04% if driving for hire DUI Arrests Hold license for 30 days Hearing from 10 days DUI Convictions Completion of DUI program Install Ignition Interlock Device 6 months in jail $390-$1000 May inpound vehicle Carrying under 21 May not carry unless someone older Fine up to $1000 and impound for 30 days, suspencion for 1 year 0.01% or higher you have to complete program, 0.05% suspension ","permalink":"https://www.jemoka.com/posts/kbhdriving/","tags":null,"title":"Driving"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhdriving_practice/","tags":null,"title":"Driving Practice"},{"categories":null,"contents":"Dup15q Syndrome is an autistic syndrome associated with a gain of variant function in UBE3A. It is the opposite of Angelman Syndrome, which is a loss of function result on UBE3A.\n","permalink":"https://www.jemoka.com/posts/kbhdup15q/","tags":null,"title":"Dup15q Syndrome"},{"categories":null,"contents":"dynamic programming is a three-step algorithm to tackle large, multi-step problems; high level idea: guessing + caching + recursion.\ndynamic programming can sometimes not be good enough, and it doesn\u0026rsquo;t really give us fast enough to get what we need to use. That\u0026rsquo;s when we need to deal with relaxation, or possibly greedy programming.\nmain steps of dynamic programming Break a hard problem into sub-problems Guess what sub-problem to solve Solve the sub-problem and store the solution Repeat #2 and #3 Combine sub-problem solutions to solve the hard problem analyzing runtime of dynamic programming To analyze runtime of dynamic programming problems, you ask:\nHow many sub-problems are there? How long does it take to solve each sub-problem? How long does it take to combine sub-problems? fibonacchi numbers: dynamic programming here\u0026rsquo;s an example top-down dynamic programming problem:\nThere are \\(n\\) sub-problems: \\(F_1, F_2, \\ldots, F_{n-1}\\). Solve a sub-problem, then store the solution \\(F_{n-1} = F_{n-2}+F_{n-3}\\) Continue until \\(F_1 =1\\). Now, we can recurs back up (popping the call stack) and cache all calculated results So then we can just look up any \\(F_k\\). shortest path: dynamic programming here\u0026rsquo;s a graph! how do we get to node \\(6\\)?\nGuess that the shortest path goes through 10 Go recursively until you get to root, cache the solution Do it again until you got to all subproblems Look up cached result ","permalink":"https://www.jemoka.com/posts/kbhdynamic_programming/","tags":null,"title":"dynamic programming"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhe_coli/","tags":null,"title":"E. Coli"},{"categories":null,"contents":"Presented Project80 Talks Person Society Keywords Email Chhavi Chauhuan, PhD, ELS ASIP AI Ethics, Pathology cchauhan@asip.org J. Elliott Robinson, PhD, MD ASBMB NF1, Dopamine, ADHD elliott.robinson@cchmc.org Jason Yi, PhD ASBMB UBE3A, Recklinghaus, Dup15q domain Erica Korb, PhD ASBMB Autism, Chromatin ekorb@pennmedicine.upenn.edu Catherine Wang AAA student approach to learning ??? Megan Fagalde, PhD Candidate AAA anatomy learning mfagalde@iu.edu Michelle A. Sveistrup AAA haptic abilities, HAT msveistr@uwo.ca AAA anatomy learning Alam Boyd AAA partner vs. individual work Magnus ??? AAA Orna Issler ASBMB IncRNA, LINC00473, FEDORA orna.issler@mssm.edu Kaushik Ragunathan ASBMB whimsical adaptations ragunath@med.umich.edu Tracy l. Bale ASBMB i think like P80 scary tbale@som.umaryland.edu Gregory Morton APS thermoregulation, glucose gjmorton@uw.edu Peter Turnbaugh ASBMB Fluoropyrimidine, PreTA, DPYD peter.turnbaugh@ucsf.edu Ralph DeBernandis ASBMB metabolic alterations, LIPT1 People Meeters Person Place Email Job Followup Jay Pieczynski Rollins jpieczynski@rollings.edu Assist. Prof. P80, College Apps Sebastian Hernandez Rollins shernandez1@rollings.edu Undergrad \u0026quot;\u0026quot; Bryson Arnett U of Kentucky Undegrad Jennifer Pousont Pingry Eric P. Chang Pace U echang@pace.edu Assist. Prof P80 ","permalink":"https://www.jemoka.com/posts/kbheb_emails/","tags":["index"],"title":"EB2022 Index"},{"categories":null,"contents":"Slightly nontraditional Ted class, which is that it is in complete modular architecture: no large group lectures, work is done in 2-3 week sprints.\nFirst two days, we will be doing intro together. There are 12 modules, and you do 6. There will be core modules and branches.\nThere are 3 symposiums which the groups share out. This class is very hard; we are using a graduate school textbook. We will be sidestepping some depth: main idea is to show the big area.\nTracks 1 =\u0026gt; {2,4,5} 4 =\u0026gt; 5 7 =\u0026gt; 8 8 =\u0026gt; {11,12} 3 =\u0026gt; 6 6 =\u0026gt; 9 9 =\u0026gt; 10 Good to learn MatLab.\nLogistics Create a portfolio journal; supply one entry a week.\nIntroductory Reading How Did Economists Get It So Wrong?\n","permalink":"https://www.jemoka.com/posts/kbhecon320_architecture/","tags":null,"title":"ECON320 Architecture"},{"categories":null,"contents":"The economy of credit is an effect where credit is being traded liberally, and people are buying stocks on large margins and unable to pay back.\n","permalink":"https://www.jemoka.com/posts/kbheconomy_of_credit/","tags":null,"title":"economy of credit"},{"categories":null,"contents":" Many Mexican-Americans worked as migratory laborers + outside programs Indian Reorganization Act of 1934 Woman were paied less Environmental cost of damns and public projects commentary on the effects of the New Deal Incorporating aspects of Arthur M. Schlesinger\u0026rsquo;s Appraisal of the New Deal, William E. Leuchtenburg\u0026rsquo;s Appraisal of the New Deal, Anthony Badger\u0026rsquo;s Appraisal of the New Deal.\nThrough the analysis of the New Deal programs, what was particularly salient was Anthony Badger\u0026rsquo;s framing of the event as not one that is ultimately \u0026ldquo;successful\u0026rdquo; or \u0026ldquo;failed\u0026rdquo; but instead one which focuses on its long-term effects in context with the future policies. The equivocal labeling allows nuance that places the Deal properly in its historical content. According to Badger, helping the poor, a significant policy goal of the deals, were left as \u0026ldquo;unfinished business\u0026rdquo; when going to war. This idea contrasts with William E. Leuchtenburg\u0026rsquo;s framing of the same event\u0026mdash;that it was never the true intention of the deal to assist in subsidies on a humane level, but that which supported the economy and incidentally those that reaped benefits on it.\nThis new frame is much more useful when analyzing the deal. In fact, Leuchtenburg took this a step further and claimed that the New Deal didn\u0026rsquo;t work largely because it was impossible for it to have repaired the damage by the Hoover administration. Furthermore, according to Schlesinger, programs like the NRA were created with already the clear assumption that there were not enough policy tools in place to actually achieve it to the fullest extent. Under this mind frame, then, it is not difficult to see the New Deal as one that intentionally brought a failing US economy\u0026mdash;and those participating in it\u0026mdash;to full swing whilst ignoring those that didn\u0026rsquo;t have an economic influence. It was, therefore, never about helping \u0026ldquo;people\u0026rdquo;: it is a policy and economic tool like any other.\nThrough this somewhat revisionist view, it is much easier to place into perspective New Deal\u0026rsquo;s zealot focus on young men, strange deficiency in some areas, and central focus on infrastructure. In that regard, the New Deal worked very well to bring a failing economy back to a semblance of normalcy for the privileged few.\n","permalink":"https://www.jemoka.com/posts/kbheffects_of_the_new_deal/","tags":null,"title":"effects of the New Deal"},{"categories":null,"contents":"Eleanor Roosevelt is the first lady of the US.\nCreated minimum wage Wrote a weekly column named My Day, in 135 newspapers 2x a week broadcast ","permalink":"https://www.jemoka.com/posts/kbheleanor_roosevelt/","tags":null,"title":"Eleanor Roosevelt"},{"categories":null,"contents":"A civil rights movement organizer that founded SNICK.\n","permalink":"https://www.jemoka.com/posts/kbhella_baker/","tags":null,"title":"Ella Baker"},{"categories":null,"contents":"Your brain maintaing a stable level of energy. Closely related to glucose homeostatis.\nmethods to achive energy homeostasis by the CNS regulation of the brain AgRP signaling is activated to stimulate food intake when hypoglycemic. ","permalink":"https://www.jemoka.com/posts/kbhenergy_homeostasis/","tags":null,"title":"energy homeostasis"},{"categories":null,"contents":"motivating entanglement file:///Users/houliu/Documents/School Work/The Bible/Quantum/Leonard Susskind, Art Friedman - Quantum Mechanics_ The Theoretical Minimum-Basic Books (2014).pdf\nTake two actors, Alice \\(A\\) and Bob \\(B\\). They each have a space \\(S_A\\) and \\(S_B\\). What if, for instance, we want to create a composite system out of Alice and Bob?\nWe will define elements in the Alice space as being defined by bases \\(H\\) and \\(T\\), where each element \\(a \\in S_a\\) is defined as:\n\\begin{equation} \\alpha_H | H \\big\\} + \\alpha_T | T \\big\\} \\end{equation}\nWhy the weird kets? We will use different kets to be aware of where bases came from; as in, elements in Alicespace is not elements in Bobspace.\nLet\u0026rsquo;s take Bobspace to be a higher dimension, as in, using normal ket vectors:\n\\begin{align} |1\\big\u0026gt; \\\\ |2\\big\u0026gt; \\\\ |3\\big\u0026gt; \\\\ \\cdots \\\\ |6\\big\u0026gt; \\end{align}\n","permalink":"https://www.jemoka.com/posts/kbhentangled/","tags":null,"title":"entanglement"},{"categories":null,"contents":"epigenetics is the ability to make identical cells present distinct phenotipic states.\nWhy? DNA is packaged by charged histone proteins, and they wrap around the nucleosome. Upon acute changes in the environment, cells can change their epigenic states.\nwhimsical adaptations Epigenetic adaptive states in organisms with no clear path adaptation. For instance, a certain lung cancer cell has this ability. So, how do cells decide what genes they would activate?\nAnother example: treating fisheries in caffine\nGrowing in caffine will trigger caffine resistance Remove the caffine would cause some of them to default back, some of them to stay the same way ","permalink":"https://www.jemoka.com/posts/kbhepigenetics/","tags":null,"title":"epigenetics"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhequal_rights_act/","tags":null,"title":"Equal Rights Act"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbheugene_wigner/","tags":null,"title":"Eugene Wigner"},{"categories":null,"contents":"A type of cell.\nSample eukareotyic cell gene:\nTATA box promoter 5\u0026rsquo; non-coding sequence Non-coding introns interlaced between exons, unique to eukareotyic cells. Bacteria (prokateotic cells don\u0026rsquo;t contain introns or have small them) 3\u0026rsquo; non-coding sequence ","permalink":"https://www.jemoka.com/posts/kbheukareotyic_cell/","tags":null,"title":"eukareotyic cell"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbheurope/","tags":null,"title":"Europe"},{"categories":null,"contents":"The correlation is a relation between two random variables.\nStandardize variables to \\(z\\) by dividing The correlation is simply their \u0026ldquo;product\u0026rdquo;: means of positive and negative groups ","permalink":"https://www.jemoka.com/posts/kbhexpectation/","tags":null,"title":"expectation"},{"categories":null,"contents":"\\(\\mathbb{F}^n\\) is the set of all lists of length \\(n\\) with elements of \\(\\mathbb{F}\\).\nFormally\u0026mdash;\n\\begin{equation} \\mathbb{F}^n = \\{(x1,\\ldots,x_n):x_j\\in\\mathbb{F}, \\forall j =1,\\ldots,n\\} \\end{equation}\nFor some \\((x_1,\\ldots,x_n) \\in \\mathbb{F}^n\\) and \\(j \\in \\{1,\\ldots,n\\}\\), we say \\(x_j\\) is the \\(j^{th}\\) coordinate in \\((x_1,\\ldots,x_n)\\).\nadditional information addition in \\(\\mathbb{F}^n\\) Addition is defined by adding corresponding coordinates:\n\\begin{equation} (x1,\\ldots,x_n) + (y_1,\\ldots,y_n) = (x_1+y_1, \\ldots,x_n+y_n) \\end{equation}\naddition in \\(\\mathbb{F}^n\\) is commutative If we have \\(x,y\\in \\mathbb{F}^n\\), then \\(x+y = y+x\\).\nThe proof of this holds because of how addition works and the fact that you can pairwise commute addition in \\(\\mathbb{F}\\).\n\\begin{align} x+y \u0026amp;= (x_1,\\ldots,x_n) + (y_1,\\ldots,y_n)\\\\ \u0026amp;= (x_1+y_1,\\ldots,x_n+y_n)\\\\ \u0026amp;= (y_1+x_1,\\ldots,y_n+x_n)\\\\ \u0026amp;= (y_1,\\ldots,y_n) + (x_1,\\ldots,x_n)\\\\ \u0026amp;= y+x \\end{align}\nThis is a lesson is why avoiding explicit coordinates is good.\nadditive inverse of \\(\\mathbb{F}^n\\) For \\(x \\in \\mathbb{F}^n\\), the additive inverse of \\(x\\), written as \\(-x\\) is the vector \\(-x\\in \\mathbb{F}^n\\) such that:\n\\begin{equation} x+(-x) = 0 \\end{equation}\nWhich really means that its the additive inverse of each of the coordinates.\nscalar multiplication in \\(\\mathbb{F}^n\\) At present, we are only going to concern ourselves with the product of a number \\(\\lambda\\) and a vector \\(\\mathbb{F}^n\\). This is done by multiplying each coordinate of the vector by \\(\\lambda\\).\n\\begin{equation} \\lambda (x_1,\\ldots,x_n) = (\\lambda x_1, \\lambda, \\lambda x_n) \\end{equation}\nwhere, \\(\\lambda \\in \\mathbb{F}\\), and \\((x_1,\\ldots,x_n) \\in \\mathbb{F}^n\\).\nThe geometric interpretation of this is a scaling operation of vectors.\n","permalink":"https://www.jemoka.com/posts/kbhlists_over_fields/","tags":null,"title":"F^n"},{"categories":null,"contents":"A New Deal program to help long-term families to have home. Tho program lowered down-payment for homes down from \\(50\\%\\) down to only \\(\u0026lt;10\\%\\). This is part of Roosevelt\u0026rsquo;s New Deal to lower interest rates and increased national home ownership rates. This could have been attributed to programs to stabilize home prices. This specifically helped white families: favoured single-family homes.\n","permalink":"https://www.jemoka.com/posts/kbhfederal_housing_administration/","tags":null,"title":"Federal Housing Administration"},{"categories":null,"contents":"The Federal Project Number One is a branch of projects under the WPA which created opportunities for writers, musicians, artists, writers, etc.\n","permalink":"https://www.jemoka.com/posts/kbhfederal_project_number_one/","tags":null,"title":"Federal Project Number One"},{"categories":null,"contents":"A field is a special set.\nconstituents distinct elements of at least \\(0\\) and \\(1\\) operations of addition and multiplication requirements closed commutativity associativity identities (both additive and multiplicative) inverses (both additive and multiplicative) distribution Therefore, \\(\\mathbb{R}\\) is a field, and so is \\(\\mathbb{C}\\) (which we proved in properties of complex arithmetic).\nadditional information Main difference between group: there is one operation is group, a field has two operations.\n","permalink":"https://www.jemoka.com/posts/kbhfield/","tags":null,"title":"field"},{"categories":null,"contents":"There\u0026rsquo;s not one market, there is a host of different markets. This field is filled with interesting markets which unique dynamics. The field can really be seen as an advanced statistics application, but its just happening to be modeling the case of financial dynamics.\n","permalink":"https://www.jemoka.com/posts/kbhfinancial_markets_intro/","tags":null,"title":"Financial Markets Intro"},{"categories":null,"contents":"A graph of states which is closed and connected.\nAlso relating to this is a derived variable. One way to prove reaching any state is via Floyd\u0026rsquo;s Invariant Method.\n","permalink":"https://www.jemoka.com/posts/kbhfinite_state_machine/","tags":null,"title":"Finite State Machine"},{"categories":null,"contents":"Fireside Chats are a group of broadcasts by Franklin D. Roosevelt (FDR) which allowed him to speak directly to the people.\n","permalink":"https://www.jemoka.com/posts/kbhfireside_chats/","tags":null,"title":"Fireside Chats"},{"categories":null,"contents":"To prove properties on Finite State Machines, we can construct a proof:\nstating an invariant proving that the invarient is true for all states for all transitions: assume invarient is true before transition and prove that its true after So, essentially induction.\n","permalink":"https://www.jemoka.com/posts/kbhfloyd_s_invariant_method/","tags":null,"title":"Floyd's Invariant Method"},{"categories":null,"contents":"Abstract Alzheimer\u0026rsquo;s Disease (AD) is a demonstrativeness disease marked by declines in cognitive function. Despite early diagnoses being critical for AD prognosis and treatment, currently accepted diagnoses mechanisms for AD requires clinical outpatient testing with a medical professional, which reduces its accessibility. In this work, we propose a possible feature extraction mechanism leveraging the previously demonstrated errors of Hidden Markov-based forced alignment (FA) tools upon cognitively impaired patients as an automated means to quantify linguistic disfluency.\nBackground Annotated linguistic disfluency features, used in combination with semantic features, have been shown ((Antonsson et al. 2021)) to improve the accuracy of AD classification systems. However, manual annotation of disfluency hinders the throughput of AD detection systems. Furthermore, there is a dearth ((Guo et al. 2021)) of data provided with preexisting annotated results.\nExisting acoustic-only approaches ((Lindsay, Tröger, and König 2021; Shah et al. 2021)) frequently places focus on the actual speech features such as silence, energy, rate, or loudness. While this approach has returned promising results ((Wang et al. 2019)), it renders the acoustic data features extracted independent of actual linguistic disfluency. Of course, some approaches (including that in (Wang et al. 2019)) perform separate, manual annotation on both aspects and treat them jointly with late fusion. However, no existing approaches have an effective feature representation that bridges the acoustic-linguistic gap.\nAn incidental effect of Hidden Markov Model (HMM) based Viterbi forced alignment (FA) tools (such as P2FA) is that its quality is shown ((Saz et al. 2009)) to be lowered in cognitively impaired speakers, resulting from a roughly \\(50\\%\\) decrease in power of discrimination between stressed and unstressed vowels. Other ASR and FA approaches ((Tao, Xueqing, and Bian 2010)) has since been designed discriminate against such changes more effectively.\nProposal By encoding FA results of HMM based approaches in embedding space, we introduce a novel feature representation of acoustic information. As FA requires an existing transcript, this method is considered semi-automated because the test must be either administered via a common-transcript, transcribed manually later, or transcribed using ASR techniques. After encoding, the proposed feature can be used in a few ways.\nEuclidean distance The Euclidean Distance approach compares the embedding of the HMM FA vector with a \u0026ldquo;reference\u0026rdquo; benchmark via pythagoras in high dimension.\nThere are two possible modalities by which the \u0026ldquo;reference\u0026rdquo; can be acquired; if the data was sourced via the patient sample reading a standardized transcript, a reference FA sample could be provided via the audio of another individual reading the same transcript screened traditionally screened without AD. Therefore, the \u0026ldquo;deviation from reference\u0026rdquo; would be used as an input feature group to any proposed model architectures.\nAlternatively, as stated before, other FA approaches are less susceptible to lexical hindrances with decreased discriminatory power. Therefore, we could equally take the Euclidean distance between embedded results of two different FA mechanisms\u0026mdash;one shown to be more sustainable to cognitively impaired speakers and one not\u0026mdash;as input features to training architectures.\nCross-Attention One key issue with the Euclidean Distance approach is that the difference between \u0026ldquo;normal\u0026rdquo; pauses, changes in speaker pace, etc. which would be variable between different speakers even controlling for AD prognoses.\nIn computer vision, few-shot classification cross-attention ((Hou et al. 2019)) has shown promising results in discrimination; furthermore, trainable cross-attention ensures more flexible control to non-prognostic verbal disturbances such as a normal change in pace which would otherwise cause a large difference in the Euclidean Distance approach.\nIn practice, a model similar to that proposed by ((Hou et al. 2019)) would be used as the basis to encode (or even discriminate) between pairwise samples of different FA approaches or against a non-AD control, as per highlighted in the section above.\nAs input features Of course, the raw FA embedding can be used as an input feature. There are less prior work on this front as this project would be, as far as we know, proposing the use of forced aligner outputs as a feature input heuristic.\nReferences Antonsson, Malin, Kristina Lundholm Fors, Marie Eckerström, and Dimitrios Kokkinakis. 2021. “Using a Discourse Task to Explore Semantic Ability in Persons with Cognitive Impairment.” Frontiers in Aging Neuroscience 12 (January): 607449. doi:10.3389/fnagi.2020.607449. Guo, Yue, Changye Li, Carol Roan, Serguei Pakhomov, and Trevor Cohen. 2021. “Crossing the ‘Cookie Theft’ Corpus Chasm: Applying What BERT Learns from Outside Data to the ADReSS Challenge Dementia Detection Task.” Frontiers in Computer Science 3 (April): 642517. doi:10.3389/fcomp.2021.642517. Hou, Ruibing, Hong Chang, Bingpeng Ma, Shiguang Shan, and Xilin Chen. 2019. “Cross Attention Network for Few-Shot Classification.” Advances in Neural Information Processing Systems 32. Lindsay, Hali, Johannes Tröger, and Alexandra König. 2021. “Language Impairment in Alzheimer’s Disease—Robust and Explainable Evidence for AD-Related Deterioration of Spontaneous Speech through Multilingual Machine Learning.” Frontiers in Aging Neuroscience 13 (May): 642033. doi:10.3389/fnagi.2021.642033. Saz, Oscar, Javier Simón, W Ricardo Rodr\\’ıguez, Eduardo Lleida, and Carlos Vaquero. 2009. “Analysis of Acoustic Features in Speakers with Cognitive Disorders and Speech Impairments.” Eurasip Journal on Advances in Signal Processing 2009. Springer: 1–11. Shah, Zehra, Jeffrey Sawalha, Mashrura Tasnim, Shi-ang Qi, Eleni Stroulia, and Russell Greiner. 2021. “Learning Language and Acoustic Models for Identifying Alzheimer’s Dementia from Speech.” Frontiers in Computer Science 3 (February): 624659. doi:10.3389/fcomp.2021.624659. Tao, Ye, Li Xueqing, and Wu Bian. 2010. “A Dynamic Alignment Algorithm for Imperfect Speech and Transcript.” Computer Science and Information Systems 7 (1): 75–84. doi:10.2298/CSIS1001075T. Wang, Tianqi, Chongyuan Lian, Jingshen Pan, Quanlei Yan, Feiqi Zhu, Manwa L. Ng, Lan Wang, and Nan Yan. 2019. “Towards the Speech Features of Mild Cognitive Impairment: Universal Evidence from Structured and Unstructured Connected Speech of Chinese.” In Interspeech 2019, 3880–84. ISCA. doi:10.21437/Interspeech.2019-2414. ","permalink":"https://www.jemoka.com/posts/kbhdementiabank_acoustics_project_proposal/","tags":null,"title":"Forced-Alignment Error for Feature Extraction for Acoustic AD Detection"},{"categories":null,"contents":"FDR is an American president.\nFDR and Teddy Roosevelt is Got Polio, which played in his favor =\u0026gt; press agree to not photograph him when he was in a wheelchair Created the New Deal Models himself after his cousin Teddy Roosevelt, and believed that charisma and moral leadership work. \u0026ldquo;Above all, try something\u0026hellip; let the court shoot it if need to.\u0026rdquo;\nHe was able to gain single party control, wh.\nCreated Fireside Chats.\nHis wife, Eleanor Roosevelt, was very controversial.\nlegacy of FDR Never spent enough to end the depression Expanded government regulation, government size, and social welfare Modernization of presidency: sets agenda, initiates legislation Realigned the democratic party (created the progressive democrats) Maintained democracy \u0026lt;=== compared to Authoritarianism ","permalink":"https://www.jemoka.com/posts/kbhfdr/","tags":null,"title":"Franklin D. Roosevelt (FDR)"},{"categories":null,"contents":"Saltwater economists are economists from coastal schools that are mostly classical Keynsians\nFreshwater economists are economists who are mostly Neoclassical Economists\n","permalink":"https://www.jemoka.com/posts/kbhfreshwater_economists/","tags":null,"title":"Freshwater economists"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhfunctor/","tags":null,"title":"functor"},{"categories":null,"contents":"fusion in machine learning is the process of adding features or encoding.\nlate fusion late fusion adds features together to a model in a multi-modal approach by first embedding the features separately\nearly fusion early fusion adds features together to a model in a multi-modal approach by concatenating the features first then embedding\n","permalink":"https://www.jemoka.com/posts/kbhfusion/","tags":null,"title":"fusion (machine learning)"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhgeneral_relativity/","tags":null,"title":"general relativity"},{"categories":null,"contents":"a hissyfight with the transformational generative syntax.\ngenerative semantics states that structure is in support of meaning, rather than the other way around that transformational generative syntax suggests.\nThis means that you need to first come up with a meaning then imbew the best structure to support the expression of that meaning.\nThis (along with distributed morphology) is the main opposition of the Lexicalist Hypothesis, and because proof for the existence of semantic primes, also the main opposition of the existence of semantic primes.\n","permalink":"https://www.jemoka.com/posts/kbhgenerative_semantics/","tags":null,"title":"generative semantics"},{"categories":null,"contents":" A genetic algorithm is a search heuristic that is inspired by Charles Darwin\u0026rsquo;s theory of natural evolution.\nIts what Grey\u0026rsquo;s video says. The picking and chucking iterative thing.\n","permalink":"https://www.jemoka.com/posts/kbhgenetic_algorithum/","tags":null,"title":"genetic algorithm"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhgolden_gate_bridge/","tags":null,"title":"Golden Gate Bridge"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhgorup/","tags":null,"title":"gorup"},{"categories":null,"contents":"Using constructor theory to test whether or not gravity in quantum theory is just entanglement.\nThis solves problem with gravity.\n","permalink":"https://www.jemoka.com/posts/kbhgravitational_entanglement/","tags":null,"title":"gravitational entanglement"},{"categories":null,"contents":"The Great Depression is a period of time of American depression.\n","permalink":"https://www.jemoka.com/posts/kbhgreat_depression/","tags":null,"title":"Great Depression"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhgreedy_programming/","tags":null,"title":"greedy programming"},{"categories":null,"contents":"Participate in Demo Day.\nGetting something:\nOpportunity to get partnering Networking opportunities, having access to contract manufacturing =\u0026gt; Conrad Challenge, $600 each, $1200\nUser conversation\nSpoke again with CompassionKind: wanting to get 20 units shipped out Spoke with SustainableEnergy for All: started by one of the UN reps. of an African country; wanted to have us featured on Social Media Wanted to connect Start diving into user connections Hiring requests\nFulfilling orders MechE ","permalink":"https://www.jemoka.com/posts/kbhgreenswing_april_checkin/","tags":null,"title":"GreenSwing April Checkin"},{"categories":null,"contents":"In this experiment, an efficient and accurate network of detecting automatically disseminated (bot) content on social platforms is devised. Through the utilisation of parallel convolutional neural network (CNN) which processes variable n-grams of text 15, 20, and 25 tokens in length encoded by Byte Pair Encoding (BPE), the complexities of linguistic content on social platforms are effectively captured and analysed. With validation on two sets of previously unexposed data, the model was able to achieve an accuracy of around 96.6% and 97.4% respectively — meeting or exceeding the performance of other comparable supervised ML solutions to this problem. Through testing, it is concluded that this method of text processing and analysis proves to be an effective way of classifying potentially artificially synthesized user data — aiding the security and integrity of social platforms.\n","permalink":"https://www.jemoka.com/posts/kbhgregarious_abstract/","tags":null,"title":"Gregarious Abstract"},{"categories":null,"contents":"grid search is a hyperparameter tuning technique by trying pairs of all hyperparemeters sequentially\n","permalink":"https://www.jemoka.com/posts/kbhgrid_search/","tags":null,"title":"grid search"},{"categories":null,"contents":"components a set of constituent objects an operation requirements for group closed existence of identity existence of inverses associative ","permalink":"https://www.jemoka.com/posts/kbhgroup/","tags":null,"title":"group"},{"categories":null,"contents":"DOI: 10.3389/fcomp.2021.642517\nOne-Liner Used WLS data to augment CTP from ADReSS Challenge and trained it on a BERT with good results.\nNovelty Used WLS data with CTP task to augment ADReSS DementiaBank data Notable Methods WLS data is not labeled, so authors used Semantic Verbal Fluency tests that come with WLS to make a presumed conservative diagnoses. Therefore, control data is more interesting:\nKey Figs Table 2 Data-aug of ADReSS Challenge data with WSL controls (no presumed AD) trained with a BERT. As expected the conservative control data results in better ferf\nNew Concepts ADReSS Challenge is small so use WLS to augment it ","permalink":"https://www.jemoka.com/posts/kbhguo_2021/","tags":["ntj"],"title":"Guo 2021"},{"categories":null,"contents":"Gut bacteria are both adversly affected by 5-Fluoropyrimidine, and but they mtaybe able to inactivate synthesized Fluoropyrimidine.\nPreTA in E. Coli is an example of a bacterial that can do this. See implications of PreTA deactivating Fluoropyrimidine.\n","permalink":"https://www.jemoka.com/posts/kbh5_fluoropyrimidine_maybe_inactivated_by_gut_microbiome/","tags":null,"title":"gut microbiome deactivating Fluoropyrimidine"},{"categories":null,"contents":"Hello Internet is a podcast hosted by Brady Haran and CGP Grey.\n","permalink":"https://www.jemoka.com/posts/kbhhello_internet/","tags":null,"title":"Hello Internet"},{"categories":null,"contents":"Herber Hoover is an American president.\nHerber Hoover\u0026rsquo;s response to the Great Depression Hoover\u0026rsquo;s Programs: too little, too late Makes business pledge to maintain wages, tax cuts, Smoot-halwey Tariff, bank financial support Builds Golden Gate Bridge and the Hoover Dam Rejects the idea of the direct federal relief, which is against FDR\u0026rsquo;s thoughts ","permalink":"https://www.jemoka.com/posts/kbhherber_hoover/","tags":null,"title":"Herber Hoover"},{"categories":null,"contents":" Reading Date Notes New Deal Flip-book \u0026lt;2022-03-24 Thu\u0026gt; New Deal Historian Flipbook Legacy of McCarthyism \u0026lt;2022-04-25 Mon\u0026gt; Legacy of McCarthyism Soviet Perspective on the Cold War \u0026lt;2022-04-29 Fri\u0026gt; Soviet Perspective on Cold War MLK and Malcom X \u0026lt;2022-05-10 Tue\u0026gt; MLK and Malcom X Reading Origins of American Conservatism \u0026lt;2022-05-27 Fri\u0026gt; Origins of American Conservatism ","permalink":"https://www.jemoka.com/posts/kbhhistory_readings_index/","tags":["index"],"title":"History Readings Index"},{"categories":null,"contents":"Homogeneity is a measure of how similar many things are.\n","permalink":"https://www.jemoka.com/posts/kbhhomogeneity/","tags":null,"title":"homogeneity"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhhoover_dam/","tags":null,"title":"Hoover Dam"},{"categories":null,"contents":"Hoovervile are homeless encampments named after Herber Hoover, where homeless people band together after loosing jobs in the Great Depression.\n","permalink":"https://www.jemoka.com/posts/kbhhooverviles/","tags":null,"title":"Hoovervile"},{"categories":null,"contents":"me\n","permalink":"https://www.jemoka.com/posts/kbhhoujun_liu/","tags":null,"title":"Houjun Liu"},{"categories":null,"contents":"A reading: (Krugman 2009)\nReflection The discussion here of the conflict between \u0026ldquo;saltwater\u0026rdquo; and \u0026ldquo;freshwater\u0026rdquo; (Keynesian and Neoclassical) economists is very interesting when evaluated from the perspective of our recent impending recession.\nOne particular statement that resonated with me in the essay was the fact that a crisis simply \u0026ldquo;pushed the freshwater economists into further absurdity.\u0026rdquo; It is interesting to see that, once a theory has been well-established and insulated in a community, it becomes much more difficult to parcel out as something that could be wrong.\nAs the same time, the forcibly-correcting \u0026ldquo;fudge\u0026rdquo; inconsistencies of the Keynesian model is also a strong weakness which perhaps further exacerbated the freshwater economists\u0026rsquo; dissent into their models. Modeling human behavior has been consistently quite messy, so it is unsurprising that both neoclassical and Keynesian economists strayed away from those models.\nCircling back to the COVID-trigger economic downturn: we definitely see a push towards increased \u0026ldquo;absurdity\u0026rdquo; in terms of increased polarization in the US; but not only that, the deeply rooted idea of \u0026ldquo;pandemics don\u0026rsquo;t affect the States\u0026rdquo; or at least \u0026ldquo;the Feds/our supply chain have preparation for absurd events\u0026rdquo; is again shown to be false\u0026mdash;despite the Obaman re-discovery of Keynesian management earlier.\nThis all raises a question: under what circumstances is a tangibly \u0026ldquo;better\u0026rdquo; result going to surface and be accepted when one model is tangibly perfect yet wrong, the other requiring flawed corrections or unrigorous analysis. Must we reject one model completely before the other one can be used?\nI don\u0026rsquo;t believe behavioral economics, though providing a partial solution as Krugman outlines, is the be-and-end-all of macroeconomic models during a depression. All of the models which were theorized (bar pure neoclassicalist \u0026ldquo;perfect agents\u0026rdquo;) ostensibly do one thing: trying to \u0026ldquo;rationally\u0026rdquo; model the \u0026ldquo;irrational\u0026rdquo; behavior of market participants. I don\u0026rsquo;t believe that this is ultimately going to be feasible on a macroeconomic scale to create models that will last (sans repeated, empirical testing\u0026mdash;but there are not enough depressions to go around.) Perhaps, then, the basic Keynesian idea of simply creating fiscal corrections may very well be the best second thing.\nReading notes the main problem was the fact that nobody saw a catastrophie coming More important was the profession’s blindness to the very possibility of catastrophic failures in a market economy.\npeople either believed that the market would never go wrong or the Fed fixes everything free-market economies never go astray and those who believed that economies may stray now and then but that any major deviations from the path of prosperity could and would be corrected by the all-powerful Fed.\nThe economists thought the humans are perfectly rational, and the fact that they are not is what leads to failures Unfortunately, this romanticized and sanitized vision of the economy led most economists to ignore all the things that can go wrong. They turned a blind eye to the limitations of human rationality that often lead to bubbles and busts\nKeynsian Economics was not trying to entirely replace markets Keynes did not, despite what you may have heard, want the government to run the economy. \u0026hellip; He wanted to fix capitalism, not replace it.\nMilton Friedman lead the return to Neoclassical Economics The neoclassical revival was initially led by Milton Friedman of the University of Chicago, who asserted as early as 1953 that neoclassical economics works well enough as a description of the way the economy actually functions\nNeoclassical Economics with the monetarist theory under Milton asserted that keeping the money supply growing is all that needed Monetarists asserted, however, that a very limited, circumscribed form of government intervention — namely, instructing central banks to keep the nation’s money supply, the sum of cash in circulation and bank deposits, growing on a steady path — is all that’s required to prevent depressions.\nMilton Freedman believes that large-scale expansion would lead to inflation and high unimployment excessively expansionary policies, he predicted, would lead to a combination of inﬂation and high unemployment\nAnti-Keynesian seniments overtook Freedman\u0026rsquo;s original proposition Eventually, however, the anti-Keynesian counterrevolution went far beyond Friedman’s position, which came to seem relatively moderate compared with what his successors were saying.\n#question why is this obvious? for obvious reasons\nBecause the new economists beliefed that the market is right, the advise was for business to max stock price ﬁnance economists believed that we should put the capital development of the nation in the hands of what Keynes had called a “casino.”\nMajor stock events didn\u0026rsquo;t blunt the disregard to Keynesian policy These events, however, which Keynes would have considered evidence of the unreliability of markets, did little to blunt the force of a beautiful idea.\nNew \u0026ldquo;perfect\u0026rdquo; economic models earned large respect in industry mild-mannered business-school professors could and did become Wall Street rocket scientists, earning Wall Street paychecks.\nNew models often analyzed financial systems independently of their real-world worth Finance economists rarely asked the seemingly obvious (though not easily answered) question of whether asset prices made sense given real-world fundamentals like earnings. Instead, they asked only whether asset prices made sense given other asset prices\nMacro split into two factions: the Keynes recessionists or the anti-Keynesians macroeconomics has divided into two great factions: “saltwater” economists (mainly in coastal U.S. universities), who have a more or less Keynesian vision of what recessions are all about; and “freshwater” economists (mainly at inland schools), who consider that vision nonsense.\nFreshwater economists\u0026rsquo; theory: recessions were just people confused? Nobel laureate Robert Lucas, argued that recessions were caused by temporary confusion: workers and companies had trouble distinguishing overall changes in the level of prices\nUnder freshwater theories, unemployment is just people electing not to work due to unfavorable environment ampliﬁed by the rational response of workers, who voluntarily work more when the environment is favorable and less when it’s unfavorable. Unemployment is a deliberate decision by workers to take time off.\n\u0026hellip;\nPut baldly like that, this theory sounds foolish — was the Great Depression really the Great Vacation?\nThe new Keysians still kept more or less to non-dramatic thinking They tried to keep their deviations from neoclassical orthodoxy as limited as possible. This meant that there was no room in the prevailing models for such things as bubbles and banking-system collapse.\nNew Keysians believed entirely in the Fed, without need for large fiscal policy They believed that monetary policy, administered by the technocrats at the Fed, could provide whatever remedies the economy needed.\nPeople just thought that there can\u0026rsquo;t be a bubble in housing What’s striking, when you reread Greenspan’s assurances, is that they weren’t based on evidence — they were based on the a priori assertion that there simply can’t be a bubble in housing.\nObama\u0026rsquo;s economic policies are much more on the Keynes side Such Keynesian thinking underlies the Obama administration’s economic policies — and the freshwater economists are furious.\nFailure of neoclassicalist theory is that breaking Keynsian economical behavior requires perfect rationality, which is absurd if you start from the assumption that people are perfectly rational and markets are perfectly efﬁcient, you have to conclude that unemployment is voluntary and recessions are desirable.\nEconomists thought that economics would have been perfect Economics, as a ﬁeld, got in trouble because economists were seduced by the vision of a perfect, frictionless market system.\nBehavioral Economics Behavioral Economics is a study of economics which hinges on the irrationality of human behavior. Its an answer to both the Neoclassical Economics\u0026rsquo; poor assumption that humans and markets are perfect, but also Keynsian Economics\u0026rsquo;s increasingly large need for a random \u0026ldquo;fudge\u0026rdquo; to get their models working right.\npillars of Behavioral Economics \u0026ldquo;Many real-world investors bear little resemblance to the cool calculators of efﬁcient-market theory: they’re all too subject to herd behavior, to bouts of irrational exuberance and unwarranted panic.\u0026rdquo; \u0026ldquo;even those who try to base their decisions on cool calculation often ﬁnd that they can’t, that problems of trust, credibility and limited collateral force them to run with the herd.\u0026rdquo; Good arbitrageurs are just forced out of the economy in large downward spirals As a result, the smart money is forced out of the market, and prices may go into a downward spiral.\n","permalink":"https://www.jemoka.com/posts/kbhhow_did_economists_get_it_so_wrong/","tags":null,"title":"How Did Economists Get It So Wrong?"},{"categories":null,"contents":"hypothesis testing is the mechanism by which a hypothesis is tested statistically.\nThe core logic of hypothesis testing: have a metric, do tests, calculate probability that the outcome could have happened given the metric is true.\nExamples include\nt-test (for sample means) z-test (for sample proportions) chi-square test (for sample categories) Common to all hypothesis tests are the following terms.\nnull hypothesis A null hypothesis is a \u0026ldquo;no difference\u0026rdquo; hypothesis created as a part of hypothesis testing. It is usually stated as an equality.\nalternative hypothesis The alternative hypothesis is the \u0026ldquo;new news\u0026rdquo; hypothesis created as a part of hypothesis testing, whereby the confirmation would introduce new information.\np-value the p-value of a hypothesis test is the probability of the results acquired taking place given if the null hypothesis. That is:\n\\begin{equation} p(\\hat{p} | H_0\\ true) \\end{equation}\nTo figure out the above probability, you could either simulate the occurrence and look at a histogram (more common for AP Statistics anyways) or measure a few other statistics. We will talk about them later.\nTo use p-value as a hypothesis test, the sample has to meet the conditions for inference.\nType I Error A Type I Error takes place when you reject the null hypothesis during hypothesis testing even while its true: i.e., a false positive.\nThe probability of having a Type I Error is the significance level of the test.\nType II Error A Type II Error takes place when you accept the null hypothesis during hypothesis testing even while its false.\nThe probability of having a Type II Error is the conjugate of the power of a test.\nsignificance level significance level is the level by which one would accept a p-value is being indicative of the success of a test. We usually use the letter \\(\\alpha\\) to denote this.\npower (statistics) power is a statistic calculable during hypothesis testing. Its the probability of rejecting the null hypothesis given the null hypothesis is false. Also known as the conjugate of the Type II Error.\npower increases as significance level increases, but then the probability of a Type I Error increases as well.\n","permalink":"https://www.jemoka.com/posts/kbhhypothesis_testing/","tags":null,"title":"hypothesis testing"},{"categories":null,"contents":"identities allows another number to retain its identity after an operation.\nWhat identities are applicable is group dependent. Identities are almost always object dependent.\n","permalink":"https://www.jemoka.com/posts/kbhidentity/","tags":null,"title":"identity"},{"categories":null,"contents":"\u0026lt;\u0026gt; NUS-HIST301 American History\nThe idea of identity politics is proposed, that politics became associated with sub-population of identities:\nBlack Pride Movement Chicano Activism The American Indian movement Termination of reservation system Pan-Indian Rights Alcatraz and Wounded Knee Occupations LGBT movement Stonewall GLF starts marching Asian American Yellow Peril Model minority movement NOW Femanism Acts The Equal Rights Act almost possible, and then Phyllis Schlafly happened Environmental Movement Silent Spring Cuyahoga River on fire Richard Nixon creates the EPA Earth Day ","permalink":"https://www.jemoka.com/posts/kbhactivism_during_the_1970s/","tags":null,"title":"identity politics"},{"categories":null,"contents":"to prove that something goes both ways: given \\(A\\Rightarrow B\\), and \\(A \\Leftarrow B\\), \\(A \\Leftrightarrow B\\).\n","permalink":"https://www.jemoka.com/posts/kbhequivalence/","tags":null,"title":"if and only if"},{"categories":null,"contents":"Here\u0026rsquo;s a list of all indexes:\nProjects Index Research Index Production Index About This should be reflected on a fancier way on my home page.\n","permalink":"https://www.jemoka.com/posts/kbhindex_index/","tags":["index"],"title":"Index Index"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhinflectional_words/","tags":null,"title":"inflectional words"},{"categories":null,"contents":"Information Units are unique entities mentioned during an utterance; for a sentence like \u0026ldquo;There is a boy. The boy is a brother. He is stealing a cookie. The sister is watching.\u0026rdquo;, \u0026ldquo;boy, cookie, sister\u0026rdquo; are possible IUs.\n","permalink":"https://www.jemoka.com/posts/kbhiu/","tags":null,"title":"Information Units (Linguistics)"},{"categories":null,"contents":"an integer (\\(\\mathbb{Z}\\)) is the natural numbers, zero, and negative numbers: \u0026hellip;,-4,-3,-2,-1,0,1,2,2,3\n","permalink":"https://www.jemoka.com/posts/kbhinteger/","tags":null,"title":"integer"},{"categories":null,"contents":"the inverse is the the opposite of an operation. As in, if you apply the inverse of an operation to the result of applying the original with the same operation it will cancel it.\nThat is,\n\\begin{equation} A * B * B^{-1} = A \\end{equation}\n\\(B^{-1}\\) is then the inverse of \\(B\\) for the \\(*\\) operation. This is operation dependent.\n","permalink":"https://www.jemoka.com/posts/kbhinverses/","tags":null,"title":"inverse"},{"categories":null,"contents":"irrational numbers are real numbers that are not rational numbers.\nFormally:\n\\begin{equation} \\mathbb{C} = \\mathbb{R} \\backslash \\mathbb{Q} \\end{equation}\nwhere, \\(\\backslash\\) is subtracting two sets.\n","permalink":"https://www.jemoka.com/posts/kbhirrational_number/","tags":null,"title":"irrational number"},{"categories":null,"contents":" Date Notes \u0026lt;2022-04-13 Wed\u0026gt; PCP April Checkin \u0026lt;2022-04-13 Wed\u0026gt; Alivio April Checkin \u0026lt;2022-04-16 Sat\u0026gt; GreenSwing April Checkin TODO Stack Get asthma kids leads for Alivio Poke Morgan for greensween mentors ","permalink":"https://www.jemoka.com/posts/kbhistudio_meeting_notes/","tags":null,"title":"iStudio Meeting Notes"},{"categories":null,"contents":"(context: I\u0026rsquo;m Chinese btw)\nI pretend to be a lot of things in life. Screw you, I\u0026rsquo;m not Stupid\u0026hellip;. I\u0026rsquo;m just Chinese. Joke\u0026rsquo;s on you, I\u0026rsquo;m both Chinese AND stupid. ","permalink":"https://www.jemoka.com/posts/kbhjokes/","tags":null,"title":"jokes"},{"categories":null,"contents":"DOI: 10.3389/fcomp.2021.642633\nOne-Liner Developed a kitchen sink of diagnoses tools and correlated it with biomarkers.\nNovelty The kitchen sink of data collection (phones, tablet, eye tracker, microphone, wristband) and the kitchen sink of noninvasive data imaging, psych, speech assesment, clinical metadata.\nNotable Methods Here\u0026rsquo;s their kitchen sink\nI have no idea why a thermal camera is needed\nKey Figs Here are the features they extracted\nDeveloped the features collected via a method similar to action research, did two passes and refined/added information after preliminary analysis. Figure above also include info about whether or not the measurement was task specific.\nand there are the biomarkers and medical data they collected\nAnd then they correlated their kitchen sink with biomarker from the tap\nNew Concepts spinal tap Notes ","permalink":"https://www.jemoka.com/posts/kbhjonell_2021/","tags":["ntj"],"title":"Jonell 2021"},{"categories":null,"contents":" Orbits of planetary bodies are ellipses with the sun at one of the two foci Drawing a line from the sun to the orbiting body, they would sweep out equal areas Planets that are closer to the sun have much shorter periods than that Squares of the periods of the planets is equal to the cubes of the distance from the planet to the sun ","permalink":"https://www.jemoka.com/posts/kbhkepler_s_laws_of_planetary_motion/","tags":null,"title":"Kepler's Laws of Planetary Motion"},{"categories":null,"contents":"Keynsian Politics is a economy strategy to support large projects via the government to boost economic output (i.e. that the economy needs a minder, but is generally free-sustaining.)\nSee also: Keynsian Economics was not trying to entirely replace markets\n","permalink":"https://www.jemoka.com/posts/kbhkeynsian_politics/","tags":null,"title":"Keynsian Politics"},{"categories":null,"contents":"KLA is a semiconductor process control company. https://www.kla.com/ Rick Wallace is the CEO.\n135000 employees 8.2B of revenue 72-300 tools 15% of revenue in R\u0026amp;D Their main business is in automatically inspecting chips and wafers in time.\n","permalink":"https://www.jemoka.com/posts/kbhkla/","tags":null,"title":"KLA"},{"categories":null,"contents":"knowledgebase testing is a space to test the knowledgebase! Other utility and maintained pages include random and Index.\n","permalink":"https://www.jemoka.com/posts/kbhknowledgebase_testing/","tags":null,"title":"knowledgebase testing page"},{"categories":null,"contents":"A KS test is a hypothesis test that measures if two groups of samples are drawn from the same distribution.\n","permalink":"https://www.jemoka.com/posts/kbhkolmogorov_smirnov_test/","tags":null,"title":"Kolmogorov-Smirnov test"},{"categories":null,"contents":"DOI: 10.3389/fcomp.2021.624694\nOne-Liner Proposed a large multimodal approach to embed auditory info + biomarkers for baseline classification.\nNovelty Developed a massively multimodal audio-to-embedding correlation system that maps audio to biomarker information collected (mood, memory, respiratory) and demonstrated its ability to discriminate cough results for COVID. (they were looking for AD; whoopsies)\nNotable Methods Developed a feature extraction model for AD detection named Open Voice Brain Model Collected a dataset on people coughing and correlated it with biomarkers Key Figs Figure 2 This is MULTI-MODAL as heck\nThis figure tells us the large network the came up with.\nTable 2 and 3 The descriminator tacked on the end of the network is transfer-trained to different tasks. It shows promising results for cough-to-COVID classification\nNew Concepts OVBM Lyu 2018 Notes Biomarker correlation Is biomarker data something that is commonly used as a feature extraction/benchmark tool?\n","permalink":"https://www.jemoka.com/posts/kbhlaguarta_2021/","tags":["ntj"],"title":"Laguarta 2021"},{"categories":null,"contents":"LOOCV is a cross validation method whereby the entire dataset bar one sample is used for training; then, validation is ran on one sample. This is repeated \\(N\\) times (with a fresh model and a fresh item left out) to get a distribution of one-shot validation results that is an approximately-normal curve centered around the mean validation result from many one-shot samples.\n","permalink":"https://www.jemoka.com/posts/kbhloo/","tags":null,"title":"Leave-One-Out Cross Validation"},{"categories":null,"contents":"Reading notes :claim: Mccarthyism was a process that de-politicized America Since political activities could get you in trouble, prudent folk avoided them\nSocial conformaty became standard middle-class Americans became social conformists\nCommunism serves as a form of balance checking, which Mccathyism lost With their demise, the nation lost the institutional network that had created a public space where serious alternatives to the status quo could be presented.\nModerate-left was also diminished Moreover, with the disappearance of a vigorous movement on their left, moderate reform groups were more exposed to right-wing attacks and thus rendered less effective.\nMccarthyism also diminshed America\u0026rsquo;s liberal modernization Measures like national health insurance, a social reform embraced by the rest of the industrialized world, simply fell by the wayside.\nCold-war opposition became quelled by mccarthism Opposition to the cold war had been so thoroughly identified with communism that it was no longer possible to challenge the basic assumptions of American foreign policy without incurring suspicions of disloyalty\nThat there may have been more international collaboration if mccarthism was not done early on American policymakers feared to acknowledge the official existence of the People\u0026rsquo;s Republic of China until Richard Nixon, who was uniquely impervious to charges of being soft on communism, did so as president in 1971\nControvercial issues were avoided intellecturally and artistically Similarly, the blacklist contributed to the reluctance of the film industry to grapple with controversial social or political issues. In the intellectual world, cold war liberals also avoided controversy.\nThat \u0026ldquo;ideology\u0026rdquo; became irrelavent, pure pragmatism took hold They celebrated the \u0026ldquo;end of ideology,\u0026rdquo; claiming that the United States\u0026rsquo; uniquely pragmatic approach to politics made the problems that had once concerned left- wing ideologists irrelevant.\nState power became expanded federal agents attacked individual rights and extended state power into movie studios, universities, labor unions, and many other ostensibly independent institutions.\nThat Mccarthism produced a threat to demcrocy in itself McCarthyism alone did not cause these outrages; but the assault on democracy that began during the 1940s and 1950s with the collaboration of private institutions and public agencies in suppressing the alleged threat of domestic communism was an important early contribution.\n","permalink":"https://www.jemoka.com/posts/kbhlegacy_of_mccarthyism/","tags":null,"title":"Legacy of McCarthyism"},{"categories":null,"contents":"The Lexicalization Hypothesis is a hypothesis proposed by Chomsky that states that syntactic transformations can only apply on syntatic constituents; therefore, the rules of putting words together is different from the rules that puts phrases together. This theory stands in opposition to generative semantics.\nThere are two versions of the Lexicalization Hypothesis:\nStrong Lexicalization Hypothesis The Strong Lexicalization Hypothesis states that both derivational words (changes meaning, bench=\u0026gt;benching) or inflectional words (changes grammar, eat=\u0026gt;eating) cannot be put together via syntatical rules. (Geeraerts 2009)\nWeak Lexicalization Hypothesis Weak Lexicalization Hypothesis states that semantic rules cannot work in the formation of derivational words only.\n","permalink":"https://www.jemoka.com/posts/kbhlexicalization_hypothesis/","tags":null,"title":"Lexicalization Hypothesis"},{"categories":null,"contents":" Poster-modern search for individualism ","permalink":"https://www.jemoka.com/posts/kbhliberal_center/","tags":null,"title":"Liberal Center"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhlina/","tags":null,"title":"lina"},{"categories":null,"contents":"DOI: 10.3389/fnagi.2021.642033\nOne-Liner Proposed cross-linguistic markers shared for AD patients between English and French; evaluated features found with standard ML.\nNovelty Multi-lingual, cross-linguistic analysis.\nNotable Methods Looked at common patters between the two languages Linguistic results scored by IUs on CTP task Key Figs Figure 1 This figure tells us the various approaches measured.\nTable 2 Here\u0026rsquo;s a list of semantic features extracted\nTable 3 Here\u0026rsquo;s a list of NLP features extracted. Bolded items represent P \u0026lt;0.001 correlation for AD/NonAD difference between English and French.\nSame thing but semantic features\nsame thing but acoustic features. As we can see, acoustic features didn\u0026rsquo;t do much.\nNew Concepts CTP IU Notes ","permalink":"https://www.jemoka.com/posts/kbhlindsay_2021/","tags":["ntj"],"title":"Lindsay 2021"},{"categories":null,"contents":"The bible stays the same: (Axler 1997)\nWe will be less exploratory, Axler will pretty much tell us. However, we should try to say stuff in the class every single class period.\nThere is a ban on numbers over 4 on this class.\nBest Practices Ask questions Talk to each other Make mistakes Know the Proof Design Patterns Non-Axler but Important Things we explicitly are told to know, but is not immediately in Axler. You bet you determinants are going to be here.\ngroup 1 Axler 1.A 2 3 4 5 Misc Knowledge algebra vector integer additive identity ","permalink":"https://www.jemoka.com/posts/kbhlinear_algebra_index/","tags":["index"],"title":"Linear Algebra Index"},{"categories":null,"contents":"A list is an ordered collection of \\(n\\) elements.\nrequirements as list length cannot be negative list length cannot be \\(\\infty\\) repetition matters order matters additional info two lists are equal IFF they have same \\(n\\) same elements same order they are different from sets because order matters (therefore, because in/out is no longer a binary) number of entries of the same object matters length is finite ","permalink":"https://www.jemoka.com/posts/kbhlist/","tags":null,"title":"list"},{"categories":null,"contents":" Number Name 31 Herber Hoover 32 Franklin D. Roosevelt (FDR) ","permalink":"https://www.jemoka.com/posts/kbhlist_of_american_presidents/","tags":null,"title":"list of American presidents"},{"categories":null,"contents":"TODO: connect Logan with a few fire departments\n","permalink":"https://www.jemoka.com/posts/kbhlogan_s_team_check_in/","tags":null,"title":"Logan's Team Checkin"},{"categories":null,"contents":"DOI: 10.1101/2021.03.24.21254263\nOne-Liner Review paper presenting the \\(ADReSS_o\\) challenge and current baselines for three tasks\nNotes Three tasks + state of the art:\nClassification of AD: accuracy \\(78.87\\%\\) Prediction of MMSE score: RMSE \\(5.28\\) Prediction of cognitive decline: accuracy \\(68.75\\%\\) Task 1 AD classification baseline established by decision tree with late fusion\n(LOOCV and test)\nTask 2 MMSE score prediction baseline established by grid search on parameters.\nSVR did best on both counts; results from either model are averaged for prediction.\nTask 3 Same thing here, DT does better but notably its F1 is smaller; data trained with final late fusion\n","permalink":"https://www.jemoka.com/posts/kbhluz_2021/","tags":["ntj"],"title":"Luz 2021"},{"categories":null,"contents":"Seed: walking, loving\nWalking\nSkipping\nShoes\nRoad\nRunning\nForward\nSpeed\nPlane\nTravel\nUnique\nCold\nHouse\nLoving\nCuddling\nKissing\nHolding\nTogether\nStaring\nLonging\nEstablish\nSpending time\nWaving\nWelling\nWalking together, staring forward longing you\nLoving together, skipping forward, a cold house\nCuddling down the avenue, spending time there, Waving by\nEstablish what it\u0026rsquo;s like,\n","permalink":"https://www.jemoka.com/posts/kbhlyrics_ping/","tags":null,"title":"Lyrics: Ping"},{"categories":null,"contents":"Seed: explore, wild\nexplore\nlearn\nresources\nmineral\ndetail\nfeature\nfact\npolice\nduty\nparticulars\ndeposit\nassign\nundertake\nnatural\nenvironment\ncultivate\nregion\nharshly\nuntrusting\nnervous\nincreasing\nchanging\nperiod\nbecome greater\nWe go explore, changing times, parting ways.\nWanting no praise, become greater Than ever\nWe go explore, shining lights moving stars\nFinding no target, we cannot expect to see\nHow can we explore if we can\u0026rsquo;t even feed? Ourselves? Our families? Our digitaries?\nHow can we explore if we can\u0026rsquo;t even seek. Unatural exploration Touching the depths with our feet\nWe go explore, wondrous depths, random seas\nWanting someone, reminicing the never\nWe go explore, purple skies acid rain\nFinding the target, we didn\u0026rsquo;t know to see\nHow can we explore if we can\u0026rsquo;t even feed? Ourselves? Our families? Our digitaries?\nHow can we explore if we can\u0026rsquo;t even seek. Unatural exploration Probing the depths with our feet\n","permalink":"https://www.jemoka.com/posts/kbhlyrics_laws/","tags":null,"title":"Lyrics: Unnatural Exploration"},{"categories":null,"contents":"DOI: 10.1109/CISP-BMEI.2018.8633126\nA dataset paper with which auditory info about people talking is collected.\nHere are the state-of-the-art as of Laguarta 2021 on the dataset proposed.\n","permalink":"https://www.jemoka.com/posts/kbhlyu_2018/","tags":null,"title":"Lyu 2018"},{"categories":null,"contents":"DOI: 10.3389/fnagi.2021.623607\nOne-Liner Trained a bimodal model on speech/text with GRU on speech and CNN-LSTM on text.\nNovelty A post-2019 NLP paper that doesn\u0026rsquo;t use transformers! (so faster (they used CNN-LSTM) lighter easier) \u0026ldquo;Our work sheds light on why the accuracy of these models drops to 72.92% on the ADReSS dataset, whereas, they gave state of the art results on the DementiaBank dataset.\u0026rdquo; Notable Methods Bi-Modal audio and transcript processing vis a vi Shah 2021, but with a CNN-LSTM and GRU on the other side.\nKey Figs Figure 1: Proposed Architecture The figure highlights the authors\u0026rsquo; proposed architecture\nFigure 2: confusion matrix In addition to validating prior work by Karlekar 2018 and Di Palo 2019, proposed model C and got accuracy of \\(73.92\\%\\).\n","permalink":"https://www.jemoka.com/posts/kbhmahajan_2021/","tags":["ntj"],"title":"Mahajan 2021"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhmahatma_ghandi/","tags":null,"title":"Mahatma Ghandi"},{"categories":null,"contents":"MapReduce is an distributed algorithm.\nMap: \\((in\\_key, in\\_value) \\Rightarrow list(out\\_key, intermediate\\_value)\\). Reduce: Group map outputs by \\(out\\_key\\) \\((out\\_key, list(intermediate\\_value)) \\Rightarrow list(out\\_value)\\) example of MapReduce Say, if you want to count word frequencies in a set of documents.\nMap: \\((document\\_name, document\\_contents) \\Rightarrow list(word, #\\ occurrences)\\) You can see that this can be distributed to multiple processors. You can have each processor count the word frequencies in a single document. We have now broken the contents into divide and conquerable groups.\nReduce: \\((word, list\\ (occurrences\\_per\\_document)) \\Rightarrow (word,sum)\\) We just add up the occurrences that each of the nodes\u0026rsquo; output for word frequency.\n","permalink":"https://www.jemoka.com/posts/kbhmapreduce/","tags":null,"title":"MapReduce"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhmartin_luther_king/","tags":null,"title":"Martin Luther King"},{"categories":null,"contents":"DOI: 10.3389/fnagi.2021.642647\nOne-Liner Combined bag-of-words on transcript + ADR on audio to various classifiers for AD; ablated BERT\u0026rsquo;s decesion space for attention to make more easy models in the future.\nNovelty Pre-processed each of the two modalities before fusing it (late fusion) Archieved \\(93.75\\%\\) accuracy on AD detection The data being forced-aligned and fed with late fusion allows one to see what sounds/words the BERT model was focusing on by just focusing on the attention on the words Notable Methods Used classic cookie theft data bag of words to do ADR but for words multimodality but late fusion with one (hot-swappable) classifier Key Figs How they did it This is how the combined the forced aligned (:tada:) audio and transcript together.\nBertbelation Ablated BERT results.\nThe model overall tends to focus on early parts of sentences. y is attention weight, x is position in sentence, blue is TD, red is AD.\nNew Concepts Active Data Representation ","permalink":"https://www.jemoka.com/posts/kbhmartinc_2021/","tags":["ntj"],"title":"Martinc 2021"},{"categories":null,"contents":"DOI: 10.3389/fcomp.2021.624558\nOne-Liner analyzed spontaneous speech transcripts (only!) from TD and AD patients with fastText and CNN; best was \\(83.33\\%\\) acc.\nNovelty threw the NLP kitchen sink to transcripts fastText CNN (with vary n-gram kernel 2,3,4,5 sizes) Notable Methods embeddings seaded by GloVe fastText are much faster, but CNN won out Key Figs the qual results PAR (participant), INV (investigator)\nNotes Hey look a review of the field:\n","permalink":"https://www.jemoka.com/posts/kbhmeghanani_2021/","tags":["ntj"],"title":"Meghanani 2021"},{"categories":null,"contents":"Applying the MFA aligner upon the Pitt (cookie only) data and performing statistics upon the calculated disfluency information. The ultimate goal is to replicate Wang 2019.\nThe code is available here.\nThe (unvalidated, draft) results are reported below:\nMean value reported, standard deviation in parens. For our data, \\(N=422\\), cases balanced.\nVariable AD (Pitt, ours) MCI (Wang) Control (ours) Control (Wang) Silence Duration 28.10 (21.28) 13.55 (5.53) 18.06 (12.52) 7.71 (5.03) Speech Duration* 23.77 (14.11) 46.64 (5.79) 27.23 (15.3) 53.63 (7.82) Voice-Silence Ratio 1.79 (4.88) 4.43 (2.78) 5.78 (31.95) 10.11 (6.05) Verbal Rate 1.59 (0.61) 1.56 (0.40) 1.989 (0.51) 1.91 (0.43) *speech duration would obviously vary with file length\nFurther statistical quantification also tells us some more things. Although the data does not make a good classifier, I performed two tests: a Kolmogorov-Smirnov test for goodness of fit, and a good \u0026lsquo;ol Pearson\u0026rsquo;s correlation with AD/control target. p-values are reported below.\nKS test silence duration: \\(1.31 \\times 10^{-5}\\) speech duration: \\(2.98 \\times 10^{-3}\\) voice-silence ratio: \\(2.01 \\times 10^{-7}\\) verbal rate: \\(4.32 \\times 10^{-10}\\) Pearson\u0026rsquo;s silence duration: \\(4.15 \\times 10^{-8}\\) speech duration: \\(0.164\\) voice-silence ratio: \\(0.732\\) verbal rate: \\(1.22 \\times 10^{-12}\\) As per the values reported in Wang 2019, we can see that\u0026mdash;apart from audio metadata\u0026mdash;verbal rate is a strongly correlated indicator against MCI/AD. We can reasonably say that Wang 2019\u0026rsquo;s data collection can be automated with reasonable success using batchalign + MFA.\nBroken ML I applied an RBF Support-Vector machine to classify AD/control based only on the two most highly correlated variables: verbal rate and silence duration. The results were disappointing.\nOn test data, N=42, balanced labels:\nSVC: \\(61.9\\%\\) Random forest: also \\(61.9\\%\\) We have fairly disappointing results. Here\u0026rsquo;s my hypothesis of why:\nif you take a look at this figure, we can see two main distributions\nSo, if we, like Wang 2019, used statistics on independence (they used chi-square, I used KS test), we will come up that the distributions are different.\nHowever, if you take a look at a randomly sampled set of validation data (crosses on the figure), you can see that a lot of them lands in the \u0026ldquo;mostly control\u0026rdquo; area: making the classifier not super useful.\nWe can therefore catch a lot of the \u0026ldquo;slow talking, long pausing\u0026rdquo; patients, but most speaking fluently will possibly need semantic information for prediction.\nI have some preliminary results on Pitt+ERNIE (a kind of BERT) that indicate that a key semantic factor is \u0026ldquo;on-topicness.\u0026rdquo; However, Pitt does not contain a lot of off-topic control data (say, the fluency task, which it has for dementia) for me to validate those claims easily. I will continue work on that front.\n","permalink":"https://www.jemoka.com/posts/kbhmfa_disfluency_measurement/","tags":null,"title":"MFA Disfluency Measurement"},{"categories":null,"contents":" Lanzi WNL (August 12) 1%. Selection Seed 7. Houjun. 82.64% ± 4.48% with a 95% confidence. Lanzi MCI (August 12) 1%. Selection Seed 7. Houjun. 78.70% ± 7.85% with a 95% confidence. Lanzi WNL (August 13) 1%. Selection Seed 7; syllabic balanced. Houjun. Within which, 90.97%±3.40% of multi-syllabic words were correctly identified 86.28%±4.08% of mono-syllabic words were correctly identified 88.63%±2.65% of all words were correctly identified at a confidence interval of 95% based on a single-variable t test. Lanzi MCI (August 13) 1%. Selection Seed 7; syllabic balanced. Houjun. Within which, 76.85%±8.08% of multi-syllabic words were correctly identified 72.22%±8.58% of mono-syllabic words were correctly identified 74.54%±5.86% of all words were correctly identified at a confidence interval of 95% based on a single-variable t test. Lanzi WNL (August 13) 1%. Selection Seed 7; syllabic balanced; 3-tier labeling. Houjun. Within which, 96.75%±2.10% of multi-syllabic words were correctly identified 90.61%±3.46% of mono-syllabic words were correctly identified 93.68%±2.03% of all words were correctly identified at a confidence interval of 95% based on a single-variable t test.\nWithin sucesseses, 16.57% are partial.\nLanzi MCI (August 13) 1%. Selection Seed 7; syllabic balanced; 3-tier labeling. Houjun. Within which, 91.67%±5.30% of multi-syllabic words were correctly identified 78.70%±7.85% of mono-syllabic words were correctly identified 85.19%±4.78% of all words were correctly identified at a confidence interval of 95% based on a single-variable t test.\nWithin sucesseses, 18.48% are partial.\n","permalink":"https://www.jemoka.com/posts/kbhmfa_performance_statistics/","tags":null,"title":"MFA Performance Statistics"},{"categories":null,"contents":"Mia is a student at the Nueva School\n","permalink":"https://www.jemoka.com/posts/kbhmia_tavares/","tags":null,"title":"Mia Tavares"},{"categories":null,"contents":"Micah Brown is a student at The Nueva School, also the host of Project80, among other things.\n","permalink":"https://www.jemoka.com/posts/kbhmicah_brown/","tags":null,"title":"Micah Brown"},{"categories":null,"contents":"Milton Freedman is an economist.\n","permalink":"https://www.jemoka.com/posts/kbhmilton_freedman/","tags":null,"title":"Milton Freedman"},{"categories":null,"contents":"MMSE is not mean squared error! It is a short mental state test to measure one\u0026rsquo;s neuralpsycological capabilities; frequently used as a first line by a psycologist.\n","permalink":"https://www.jemoka.com/posts/kbhmmse/","tags":null,"title":"Mini-Mental State Examination"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhminimum_spanning_tree/","tags":null,"title":"minimum spanning tree"},{"categories":null,"contents":"How many disturbance users can coveather take without crashing? Let\u0026rsquo;s find out.\nCode Util function to mapreduce a list:\ndef multiplyList(l) : # Multiply elements one by one result = 1 for x in l: result = result * x return result We first set a user count:\nN = var(\u0026#34;N\u0026#34;) # Pool size val_percent = var(\u0026#34;val_percent\u0026#34;) # Pools val_pool = N*val_percent user_pool = N*(1-val_percent) # Disturbance disturbance_percent = var(\u0026#34;disturbance_percent\u0026#34;) # Validation Pools + Disburbance val_disturbance_pool = disturbance_percent*val_pool val_normal_pool = (1-disturbance_percent)*val_pool # Chance of three or more disturbance attestors # which is equal to one minus chance of zero, one, or two disturbance attesors no_disturbance_attestor = (val_normal_pool/val_pool)*((val_normal_pool-1)/(val_pool-1))*((val_normal_pool-2)/(val_pool-2))*((val_normal_pool-3)/(val_pool-3)) one_disturbance = [] for disturbance_point in range(0,4): res = [] res.append((val_disturbance_pool)/(val_pool-disturbance_point)) for pre_disturbance in range(0,disturbance_point): res.append((val_normal_pool-pre_disturbance)/(val_pool-pre_disturbance)) for post_disturbance in range(disturbance_point+1,4): res.append((val_normal_pool-post_disturbance)/(val_pool-post_disturbance)) one_disturbance.append(multiplyList(res)) one_disturbance_attestor = sum(one_disturbance) two_disturbance = [] for disturbance_point_i in range(0,4): for disturbance_point_j in range(disturbance_point_i+1,4): res = [] res.append((val_disturbance_pool)/(val_pool-disturbance_point_i)) res.append((val_disturbance_pool-1)/(val_pool-disturbance_point_j)) for pre_i_disturbance in range(0,disturbance_point_i): res.append((val_normal_pool-pre_disturbance)/(val_pool-pre_disturbance)) for sandwich in range(disturbance_point_i+1,disturbance_point_j): res.append((val_normal_pool-post_disturbance)/(val_pool-sandwich)) for post_j_disturbance in range(disturbance_point_j+1,4): res.append((val_normal_pool-post_disturbance)/(val_pool-post_j_disturbance)) two_disturbance.append(multiplyList(res)) two_disturbance_attestor = sum(two_disturbance) distubrance_chance(N, val_percent, disturbance_percent) = expand(1-(no_disturbance_attestor+one_disturbance_attestor+two_disturbance_attestor)) # no_disturbance_attestor (N*(disturbance_percent - 1)*val_percent + 3)*(N*(disturbance_percent - 1)*val_percent + 2)*(N*(disturbance_percent - 1)*val_percent + 1)*(disturbance_percent - 1)/((N*val_percent - 1)*(N*val_percent - 2)*(N*val_percent - 3)) z = var(\u0026#34;z\u0026#34;) val_dist(val_percent, disturbance_percent) = distubrance_chance(100, val_percent, disturbance_percent) implicit_plot3d(val_dist-z, (val_percent,0.1,1), (disturbance_percent, 0,1), (z, 0,1) ,frame=True,axes_labels=[\u0026#39;Validation\u0026#39;,\u0026#39;Disturbance\u0026#39;, \u0026#39;Chance\u0026#39;],axes=False, color=(val_dist,colormaps.Blues)) Launched html viewer for Graphics3d Object z = var(\u0026#34;z\u0026#34;) n_dist(N, disturbance_percent) = distubrance_chance(N, 0.1, disturbance_percent) show(implicit_plot3d(n_dist-z, (N,100,100000), (disturbance_percent, 0,1), (z, 0,1) ,frame=True,axes_labels=[\u0026#39;N\u0026#39;,\u0026#39;Disturbance\u0026#39;, \u0026#39;Chance\u0026#39;],axes=False, color=(n_dist,colormaps.Blues)), aspect_ratio=[1,100000,100000], plot_points=100) Launched html viewer for Graphics3d Object n_dir(N) = distubrance_chance(N, 0.1, 0.1) # plot(n_dir, (N,100,100000),axes_labels=[\u0026#39;N\u0026#39;, \u0026#39;Disturbance\u0026#39;], thickness=1) # solve(distubrance_chance(100, N, 0.1)==0.01, N, to_poly_solve=True) # implicit_plot(distubrance_chance(100, N, 0.1)==0.01, (N, 0,1), (z, 0, # solve(distubrance_chance(N, val_perc, 0.1)==0.01, val_perc, to_poly_solve=True) # implicit_plot(solve(distubrance_chance(N, val_perc, 0.1)==0.01, val_perc)[0]) # val_perc = var(\u0026#34;var_perc\u0026#34;) show(implicit_plot(distubrance_chance(N, val_perc, 0.1)==0.01, (N, 15, 1000), (val_perc, 0,1), plot_points=300,axes_labels=[\u0026#39;N\u0026#39;,\u0026#39;Val Ratio\u0026#39;],axes=False), aspect_ratio=800) # solve(distubrance_chance(800, val_perc, 0.1)==0.01, val_perc, to_poly_solve=True) \u0026lt;/Users/houliu/.sage/temp/baboon.jemoka.com/64368/tmp_9bdcu2si.pn\u0026gt;\n","permalink":"https://www.jemoka.com/posts/kbhminimum_user_base_requirements_for_coveather/","tags":null,"title":"minimum user base requirements for coveather"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhminimum_wage/","tags":null,"title":"minimum wage"},{"categories":null,"contents":"Reading notes Malcom X\u0026rsquo;s father was an active prechear in the scene Malcom X and MLK are both made mostly charactures out of context Malcom X had a belligent upbringing with a belligent father, whereas MLK lived in relative comfort as a son of a successful minister Malcom was sent into white foster families as his mother became institutionalized Becasue of his experience in foster system, Malcom tried to pass/be white King\u0026rsquo;s nonviolent priciples not understood and became conflicted with ideas of local leaders Malcom found a father figure in the Nation of Islam, changing his name in prison MLK had more positive African American role models in life Malcom X disallusioned with the policy of nonengagement by the nation of islam Malcom X had support over racial seperatism Nation of Islam wanted to create a completely seperate Black state, promoting Black Nationalism secret Malcom X wanted break because of skeptism again Eli Mohammed Malcom charged MLK with infiltration Martin believes that the process of voilence is a form of naïve expression King believes that the \u0026ldquo;strong demagogic oratory\u0026rdquo; of Malcom was detrimental and extremist Martin believes that the personal nature of assults from Malcom maybe result in physical assult Malcom was suspended during 1963, and became independent\u0026mdash;wanted to combine religion and politics like King Malcom began forging ties with millitan Black movement Martin regretted that integration has not proceeded, but believed it would have been difficult anyways Rejected nonviolent and intergrational movement People saw King and X\u0026rsquo;s ideas inrecosiliable But, King and X themselves made a possible shared ending by the end Believes that suicides were cut short Racial pride was a centering point: while Malcom saw it as something to be harbored, Martin saw it as inate ","permalink":"https://www.jemoka.com/posts/kbhmlk_and_malcom_x_reading/","tags":null,"title":"MLK and Malcom X Reading"},{"categories":null,"contents":"modalization is the\n","permalink":"https://www.jemoka.com/posts/kbhmodalization/","tags":null,"title":"modalization"},{"categories":null,"contents":"Monetarist theory is a theory of economics proposed by Milton Freedman which asserts that Keynsian economics only applies in the limited case that central bank need to keep the money supply growing; otherwise, the free market can handle itself.\nTherefore the Monetarist theorists propose that the stock market crash of 1929 was caused that the US monetary fund did a bad job of actually controlling the funds, and didn\u0026rsquo;t inject enough money into economy.\nSee also the opposite: demand-driven theory.\n","permalink":"https://www.jemoka.com/posts/kbhmonetarist_theory/","tags":null,"title":"Monetarist theory"},{"categories":null,"contents":"The fallout of the Rosa Parks incident, which is when many of Montgomery residents.\nThe boycotts were developed by Martin Luther King.\n","permalink":"https://www.jemoka.com/posts/kbhmontomery_bus_boycott/","tags":null,"title":"Montgomery Bus Boycott"},{"categories":null,"contents":"The multiplicative identity allows another number to retain its identity after multiplying. Its \\(1\\) [for fields?].\n","permalink":"https://www.jemoka.com/posts/kbhmultiplicative_identity/","tags":null,"title":"multiplicative identity"},{"categories":null,"contents":"TBD\n","permalink":"https://www.jemoka.com/posts/kbhmultiplying/","tags":null,"title":"multiplying"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhmy_day/","tags":null,"title":"My Day"},{"categories":null,"contents":"NACC is a large, longitudinal dataset for neurodegentitive disease as a project in collaboration with Dr. Alyssa Weakley at UC Davis.\nDr. Alyssa Weakley is interested in\nEarly Cognitive Change Mild Cognitive Impairment (MCI) \u0026ldquo;How early can we detect, using NACC, change?\u0026rdquo;\ndataset construction Participants are given a battery of mental capacity tests, these values are tracked over time There are also family member questionnaire Neuroimaging and biomarker data Other things tracked in the data\u0026mdash;\nAmyloid levels of spinal fluid Detecting even earlier focus good to focus on specifically alzheimer\u0026rsquo;s type dementia (so, ignore things on lewy body disease) Using clinical diagnosis as the dependent variable, but good to see the autopsy results Items 3 and 7 are independent codes; if alzhimer\u0026rsquo;s is measured, MCI is not measured. visa versa.\n","permalink":"https://www.jemoka.com/posts/kbhnacc/","tags":null,"title":"NACC"},{"categories":null,"contents":"natural numbers (\\(\\mathbb{N}\\)) are the counting numbers: 1,2,3,4\u0026hellip;.\nZero is not part of it; this produces interesting results like set of natural number under addition is not a group because there is no identity (tbh nor inverse (inverse of 1 is -1 which is not in the set.))\n","permalink":"https://www.jemoka.com/posts/kbhnatural_numbers/","tags":null,"title":"natural number"},{"categories":null,"contents":"The nsm theory is a theory that\u0026hellip;\nclaims that there exists a set of semantic primes and logic universal across languages which is indefinable by other words within the language which, as a corollary, resolves the epistemological problem that if all words are defined by other words in the language there will (why?) be no connection to the real world the theory of NSM rests on\u0026hellip;\ntwo pillars of NSM theory existence of semantic primes The existence of semantic primes is codified more formally as the strong version of the Lexicalization Hypothesis.\nIssues with it: problems with semantic primes\nthe ability to perform the act of reductive paraphrase Issues with that: problems with reductive paraphrasing\noh cool! (Bohnemeyer 2004)\nAlso the fact that NSM is first found in English means that there is a certain anglo-centrism that comes with the language.\n","permalink":"https://www.jemoka.com/posts/kbhnatural_semantic_metalanguage/","tags":null,"title":"Natural Semantic Metalanguage"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhnatural_transformations/","tags":null,"title":"natural transformation"},{"categories":null,"contents":"needfinding as a process of finding need.\nneedfinding with Rick Wallace needfinding with Rick Wallace. You don\u0026rsquo;t find out what they need, but you find what they need and how to fix it. (duh?)\n","permalink":"https://www.jemoka.com/posts/kbhneedfinding/","tags":null,"title":"needfinding"},{"categories":null,"contents":"Neoclassical Economics is a view of economics that disregards the Keynsian Politics theory of the economy needs a minder started by Milton Freedman. It believes that free market economy will prevail.\n","permalink":"https://www.jemoka.com/posts/kbhneoclassical_economics/","tags":null,"title":"Neoclassical Economics"},{"categories":null,"contents":"A set of policy by Franklin D. Roosevelt (FDR) which helped saving the economy during the Great Depression.\nSaving the Banks Unemployment Relief Industrial Recovery Agriculture Creates the WPA. Also the Social Security Administration. Also created Rural Electrification Administration\nMany people were still left out.\n","permalink":"https://www.jemoka.com/posts/kbhnew_deal/","tags":null,"title":"New Deal"},{"categories":null,"contents":"A reformist, counterculture movement during the \u0026rsquo;80s lead by Ronald Reagan. Its a new response to the neoliberalism which aligned the blocks of Evangelical Christians (25% of voters) and Business leaders (powerful leaders.)\nAmerican liberalism expands under the new right as well.\nPresident as a party leader: Reagan is often shown as shining beaken of the Republican Party Leadership\u0026mdash;won every single state except Georgia .\n","permalink":"https://www.jemoka.com/posts/kbhnew_right/","tags":null,"title":"New Right"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhchomsky/","tags":null,"title":"Noam Chomsky"},{"categories":null,"contents":"The nonviolence movement a method of protest which is developed by Mahatma Ghandi and leveraged by Martin Luther King in the civil rights movement.\nThe idea is to achieve civil disobedience and allowing oneself to be punished so egregiously without inciting violence so at to elicit sympathy across the nation.\nThe civil rights movement leveraged training tactics and training to ensure its participants would be completely nonviolent and so elicit the correct response.\n","permalink":"https://www.jemoka.com/posts/kbhnonviolence_movement/","tags":null,"title":"nonviolence movement"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhnormal_distribution/","tags":null,"title":"normal distribution"},{"categories":null,"contents":"Foreword Hi there, internet traveler.\nThe time is 2015/2016, I was either in 5th or 6th grade. At that time, I was barely beginning to be actually comfortable using the language of English.\nOne of the ways I practiced English, which is also a habit I continue to do today, is to write. I write mostly expository prose now, but, back then, shining with childish naïvete, I decided to write a multi-part story as a means of practicing English.\nAt the time, I was fortunately supported by four very helpful adults\u0026mdash;ESL instructors, teachers from the local government\u0026rsquo;s ESL program, local students, family friends\u0026mdash;who have supported me and edited this silly story as a means of helping me better my command of English.\nIronically, this story is set in 2018, I think, two years after when I wrote it. Its now 2022, almost 7 years after. Make of that what you will.\nTherefore\u0026mdash;\nNorman, an epic tale told in N parts\nWritten by yours truly, Houjun Liu, circa 2016.\nEdited by: Lynne Zummo, Dorit Hahn, Susan Cole, and Jennifer Fan.\nTypesetted: May 10th, 2022. Menlo Park, California.\nPrologue: James Peter On a sunny day, in a small house at 1623 Wesson Ave, James lay on a dirty, tiny bed. Suddenly a dog was in James’ sight. James stood up, stared at the dog. It was a small, brown, white, fuzzy dog with a tiny stump. The dog walked around James’ bed, looking silly.\n“Let’s call you Norman! It is a good name for you!”\n“There is no dog allowed in my house, get’em out! RIGHT now, or I will get YOU out!” shouted Mr. Miller.\n“Dude,” a voice came from James’ mind. Mr. Miller, the owner of the Wacky Hair Salon, who is James’ uncle, barged into James’ room, continuously shouting.\n“Get’em out, RIGHT NOW! NOW! YOU HEAR ME?”\nJames, staring at Norman, just didn’t care.\nNorman seemed to not understand all this. He followed Mr. Miller to the window, and \u0026hellip; just as suddenly as he had come in, he was thrown out by Mr. Miller.\nWhile Norman was wandering around, James started crying.\nMonths passed…\nPart 1 On a cold winter afternoon, Mr. Miller is sending James to an orphanage as punishment for doing “bad” things. James just doesn’t understand this. He SIMPLY wants Norman to come back!\nWhen they arrive, James finally realizes why he didn’t have parents. The truth is dreadful: his dad went crazy from programming in binary code.\n“I will go crazy, too,” James thinks. “It is not an easy job, no sir.” His mom’s situation was even worse, for she was killed by the African disease Ebola.\nHe trudges into the front building with Dr. Brains, and sees children that had been starved, gone mad, and even had been wandering around hopelessly! Many questions flew into James’ mind: Will I go crazy, too? Will I be starving, too? Will I also be wandering around like a zombie?! Feeling scared, he starts to wander, feel hungry, and starve like the other kids ……\n“Wait ! NO, I can’t do that,” thought James.\nDr. Brains takes James to walk around the orphanage, he realizes it is actually a better place to be rather than 1623 Wesson Ave. He sees cats, he sees ducks, he sees horses, he sees a playground, and he sees…\nNORMAN!\nPart 2 Dr. Brains, who looks bewildered, is staring at him.\n“How can you know him? You just arrived here!”.\n“Long story…,” explains James. “I once met the dog, and he was thrown out by Mr. Miller from where I used to live.”\n“So, this is PART of our orphanage. As you see, it is big. We now should thank the donor, who passed away, Dr. James Rover Peter…” There is a little pause, then Dr. Brains continues.\n“Who is YOUR dad!”\nThey continue walking until they get to a building labeled ‘EDU_K-4’.\n“This is the K-4 grade educational multifunctional building,” explains Dr. Brains, “where you will be staying for half a year. Then you will move to this building for study.”\nDr. Brains is now pointing at a building labeled ‘EX-EDU_5-12’.\nThey continue to walk until they get to another building labeled ‘OPH_LV #20312’. It is a small, lovely building, much like an apartment. “This is where you will live, in room # 20312_004,” says Dr. Brains while he hands James a key. Then he gives him a packet, which reads: Vanilla orphanage grand rules and schedule.\n“This is all you need, good day! I will leave you here.”\nJames watches Dr. Brains until he is out of sight.\nHe walks straight into the room. It looks clean, neat, like a 3-star hotel. There is a twin size bed, a desk, and a restroom. He sits down and starts to read the packet:\nChapter 1: Grand rules Welcome to Vanilla Orphanage! This is a place where you can enjoy yourself, explore yourself, and get prepared for the world!\nBut, there MUST be some rules in our orphanage to keep you and your classmates safe.\nFirst of all, you MUST not run in the front building.\nSecond, no talking is allowed while a grand meeting is taking place (see chapter 2 for more info).\nThird, follow your schedule all the time.\nFourth, if you have an emergency, use the emergency call phone (You don’t need to dial it, it will automatically connect to Vanilla Orphanage Hospital). But if you can walk and speak normally, go to Vanilla Orphanage Hospital for more help.\nFifth, the use of a regular telephone is only allowed three times a day. If your teacher calls you, it won’t count. You can only use a regular telephone for calling inside-the-orphanage friends, no outside call is allowed. To see the interior telephone numbers, see chapter 3.\nChapter 2: Grand schedule + your personal schedule Grand schedule\nYour personal schedule\nMeet me every OTHER Sunday at 15:00 at grand office starting 1/2/2019.\nGrand meeting will take place every first day of the month at the big hall in the front building. Everyone will attend the grand meeting; it lasts the whole day.\nDinner, Lunch, and Breakfast will be served at Front Building.\nDr. Flynn (k-4 Sciences) 4242-5000-2525 Dr. Jones (5-12 Sciences) 2134-1000-1045 Dr. Foster (k-4 Math) 2456-6206-6200 Ms. Garcia (5-12 Math) 1341-4000-4012 Mrs. Newman (k-4 Talk-it-out assistant) 2563-6374-7407 Mrs. Willems (5-12 Talk-it-out assistant) 8908-6997-9000 Dr. Brains (Headmaster) 2563-0035-3526\nPart 3 A brief day, he does whatever he is told, follows the schedule, does the work. But, something that amazes James is that the food is actually YUMMY.\nHe does enjoy eating at vanilla orphanage. Normally, it is like a buffet, but a limited one. You only can have one serving of meat, 2 vegetables, a delicious main dish (e.g. cooked rice, cooked noodles …).\nBy the table, James sees students laugh at each other, talk with each other, and, from far away, he sees a little brown-white puppy is running to a girl with curly hair, and stops.\nNorman!!!!!!!!!!!!!\nIt is funny that the girl asks exactly the same thing as Dr. Brains asked:” How can you know him?” He explains the whole story why he knows Norman and asks his very own and very first question to the very first student he meets at the vanilla orphanage: “How did he get here?”.\n“Long story,” says the girl, “he first arrived here because of our save the dogs project, Calvin and I found him.”\n“And who are you? I’m James”.\n“Sorry, I forgot about that, my name is Amelia!”.\nA tall, black haired student comes and joins them. “Hi there, what’s up? I heard someone mention my name.”\n“Oh, we were just talking about the dog. Our new friend, James, gave him a name: Norman,” responds Amelia.\n“Guess what?” asked Calvin, “I taught him Chinese!”.\n“Oh interesting, show us!” says Amelia.\n“狗儿，请来一下; I told him to come.” Suddenly, Norman comes and starts running around Calvin. “你的名字叫做 Norman; I told him that his name is Norman,” says Calvin. The dog starts moving around in a funny way, which James feels weird about. “Oh, don’t worry about that, that’s the Funny-Brown-Hula-Stump-Wiggle-Wag-Dance that I taught him,” Says Amelia.\nPart 4 Dong, dong, dong, dong…… The school bell rings, everyone gets up to do everything they need. It’s Sunday. According to Dr. Brains, James needs to meet Dr. Brains at the grand office.\nWhen he arrives, Dr. Brains says nothing but a greeting, and he hands James a slip of paper that says:\nThe organization of Brainiacs: 52345 Brainful way, North town, CA 94780\n“What is the org…”. “Stop! I will explain everything right after!” explains Dr. Brains. “Just remember what this parchment says!”\nHe hands him a telephone, and says, “Dial 52325, when you hear a beep, dial 900. Answer every question it’s asking you.”\nHe does what he is told, then a girl’s voice says: “Welcome to the new member registration center of TOFB, or the Organization of Brainiacs. Please answer the question: What is your address? “James states the orphanage’s address. “What is your reason to join?” Dr. Brains says quietly,” Invited.”\nWho invited you?” James answers:”Dr. Brains.” “ Welcome, again, new member. Please take the blood needle that appears in front of you and use it to poke your left ring finger.” James does this, and the voice says, ”Thanks for joining! Please hang up the phone!”\n“Understand this?” Dr. Brains says, ”Let’s go!”. “But, go where?” asks James. ”T-O-F-B,” replies Dr. Brains. They walk straight into a box, where James spots a device. Dr. Brains pushes a button on the device, and suddenly, James feels dizzy. They are spinning. They spin faster and faster. Finally, he hears a pop, then, suddenly, he falls into another device which is like a poison chamber. He and Dr. Brains open the door, and he sees a small, transparent house that reads T-O-F-B.\nPart 5 They walk straight into the house, and see a small elevator that is made out of glass. While they walk into the elevator, James feels something is seriously wrong. First, this is a one-story building, and unlike the 5th avenue apple retail store, it has no underground floor. Second, the elevator has NO button, how can Dr. Brains go anywhere with this elevator?\nDr. Brains seems solemn, he carefully looks at the emergency speaker, then, suddenly, James hears a loud CRACK. Then the elevator starts getting darker and darker. After 5 seconds, it is not transparent anymore.\nThe elevator starts to go down deeper and deeper. Then a screen pops up.”Hello, WELCOME to the Organization of Brainiacs. Please scan your card…” says a voice. He doesn’t have a card!! He looks around to find Dr. Brains, but, he is gone!\n“Where else can he be?”James thinks,”there is no way out!”. Suddenly, smoke fills the elevator, James first doesn’t realize what it is, but suddenly, he knows it.”Oh oh!” thinks James, ”IT IS GAS!!!!!”\nChapter 2: T-O-F-B Way underground, Dr. Brains hesitates. “OOOOOOOOOOPS! I forgot James in the elevator..” , he thinks, ”and the killer gas X03-00 would be deadly.”\nHe rushes to the “hacker center”, and shouts, ”You guys! STOP the elevator! And STOP the gas! Open the doors! Clear out the gas! He is NOT a criminal!”\nEverybody freezes, and some whisper, ”Oops, x03-00 gas can knock a human out in 10 seconds”.\nPart 6 Back in the elevator, James barely has time to call the emergency. “Does Dr. Brains mean to kill me?” he thinks, ”or is this a test for me?” He has more things to worry about than that. However, the good news is that Dr.Brains and his team hurry to the elevator just in time, which is when he gets knocked off. They give him the medicine that will neutralize the effect of the gas, and then they hurry to prepare the WELCOME event of the new T-O-F-B members in this season.\nSoon after, James wakes up, safe and sound. Dr. Brains is right by him.\n“Sorry for the accident, but here, welcome to T-O-F-B”, Dr. Brains says with a little smile.\nThere is a little awkward moment when he and Dr. Brains both try to say something, but no sounds come out. It doesn’t last long, just a few seconds. Then Dr. Brains continues, ”The Organization of Brainiacs is a little like what you see in the movie M-I-B. We basically are the only legal group in human and alien law that can meet, communicate with, and study the aliens from outer universe. You know one of our aliens: Norman. He actually can speak Hidoeneese AND English.”\n“But what is Hidoeneese?” James asks.\n“Hidoeneese is the language of the Hidonipothan.” Dr.Brains says.\n“And what is Hidonipothan?” he asks, again.\n“Long story short, it’s kind of an alien tribe. Later at breakfast, Norman will explain. By the way, he likes his name Norman.” Dr. Brains responds.\n“What? Breakfast? It’s already morning?” James asks.\n“Well yes, you have been knocked out by gas for almost 12 hours, and now it is 6:00 in the morning,” Dr. Brains says, ”you still can get about 3 hours rest. Everyone in T-O-F-B sleeps late and wakes up late. And one last thing, I will give you the NEW MEMBER #04 packet so you can learn more about T-O-F-B.”\nHe hands him a packet, just like the packet in the orphanage. But it is hand written.\nWelcome, new member, we are proud that you are here. As the founder of T-O-F-B, I will introduce you to the few basics of daily life.\nFirst, you all have an outside “job”, which you will still perform. Since you are a child, AS I KNOW, we will just keep you up-to-date and call you via the headphones that we will give you. We won’t interrupt your class, unless it is an emergency, I promise. You will be meeting once a month so it won’t affect any of your grades.\nSecond, in T-O-F-B, we treat any child like an adult. It means a large work load, but you can also access any part of our centre freely with your BNPS. But in some areas, we want you to have adult supervision.\nYour supervisor is:\nGrave Hono ( Dr. Brains, as a substitute name in the human world)\nWe will give you a map and what you should do later.\nDr. Ranboro\n9/23/2018\nPart 7 He falls asleep……… He dreams about aliens attacking the centre, and only Dr. Brains, Dr. Ranboro, Norman, Amelia, Calvin and a guy who he didn’t know survived. He thinks it’s just a dream, but what he doesn’t know is, this day is coming closer and closer.\n“Wakey, Wakey!” Dr. Brains shouts, laughing” JJJJJJJJAAAAAAMMMMMMMEEEEEEEESSSSSSSSSSSS!!!!!!!!!!!!”. James finally wakes up, and mumbles, ”What the heck in the world was this?”\nDr. Brains seems to be confused. “You didn’t recognize my voice? Wake up, Buddy! Get dressed! The welcoming party is waiting!!”.\nHe gets dressed, hurries to follow Dr. Brains, and they go outside to a “secretive” room that is labeled “G—CHECK, BNPS ROOM”. They go in, and he sees a bunch of devices that are new to him. He sits down, just as Dr. Brains ordered, and Dr. Brains brings a needle to his face, straight into his eyes. “Watch out!” James shouts. He doesn’t even have time to think, as the needle goes in and out of his eyes. Dr. Brains says, “Good, we already got the DNA, scanned the iris, scanned the brain map. Ok, 2 last things, then we are good to go!” He does a bunch of scans on James’ finger, and he enters a password into a machine. “Ok, one last thing. Print your BNPS and tattoo it to your shoulder!” Dr. Brains says. The machine reads “bring human to the tattoo station …… step 3/5”. Dr. Brains orders him to put his shoulder into a cylinder. He feels a little pressure and his shoulder pops out of the machine. He sees a little piece of metal on his shoulder and it reads ”TOFB.1029358612.JP/////////” The machine also prints out a metal card. “Don’t lose it!” Dr. Brains says, “it is your ID here!”\nThey walk out of the room and into the elevator. It is an elevator like the one in the TOFB’s entrance. The one that changes color and transparency, only much more slowly. When it tells him to scan the card, he knows better than to not do so. The elevator seems smart, and it asks “Homo, and James! Morning! Which level area do you want to go to?”. Dr. Brains responds, “Dining room number three, formal, both of us”. The elevator responds with a “TOFB wishes you a pleasant day!” When the door opens again, they enter a large area, like the first level of a 5 star hotel. Everything is white: people’s clothes, the ground, the staircase, the light, etc,. He sees Dr.Brains’ clothes change to white! He says, “Dr.Brains! Your outfit changed color!” “Yours did, too!” Dr. Brains responds. James looks down at his clothes. His had actually, as Dr. Brains said, changed color and texture.\nThey eat their breakfast—salmon, soup and broccoli, and Dr. Brains announces to him, “OK, now let’s do some work stuff”. They head back to the living area, and they wash themselves. Then they head to the meeting area. Norman, Dr. Ranboro and the other guy James sees in his dream are waving to James-and-Dr.Brains-in-the-black-suit-and-a-tie.\nPart 8 “So”, Dr. Ranboro says, “Welcome! Thank you for joining the organiza………?!!!\u0026gt;?*\u0026amp;%*\u0026amp;^%\u0026amp;^%%∆˙ßå˚µß∂˙”. FFF! A small arrow flies though the walls and hits Dr. Ranboro, making his words into nonsense. “å∆∆ß¬—å˚å!!!!!!¡¡¡¡¡¡?¿!¡……Jams…….main sq……is com…..tel..hom……nnnoor…….¡¡¡!!!???¿¿¿å∂ß˚˚˚˚∆ƒå˙”, he says. James can barely understand, but he knows one thing, they will tell him about the main sq…whatsoever.\n“Let’s jump into the topic,” Norman says. “The main sq… is actually an attack called The Main Square Rattle, or what we call TMSR. It’s started because another kind of alien, The Froakan, wants to use humans as slaves, own the TOFB AND the Hidonipothan.The only way to stop that is to get the battle-rattler and rattle it. But if The F’s got the rattler and rattle it, well, we will all freeze and do what they want, like a bunch of zombies. The state of being a zombie is called ratling. Sadly, there isn’t a known cure yet for ratle. But Dr. Brains is working on it! Lastly, the battle-rattler is locked in the Ratle Mountains. And the only way to enter the Ratle Mountain is by using Dr. Ranboro’s key. Otherwise, you will have very little chance to get out alive! And that’s why they shot Dr. Ranboro. As a matter of fact, the arrow is poisonous. If we don’t send him to hospital now, he will become a baby in 72 hours.”\nTalking about Dr. Ranboro, James notices Dr. Ranboro’s hair getting darker and darker from the old-man-white. They send him to the hospital about 5 minutes later.\nChapter 3:That’s called war After another ride on the “TOTP—0111”, which is the “squeeze box” to get to the North Town, they are back at Dr. Brains’ office. But something weird has happened, only students in OPH_LV # 40000 - OPH_LV # 49999 are still in the orphanage. Dr. Brains tries to find out why, but he can’t. And that’s when all of the humans in the orphanage hear a gigantic laugh coming from nowhere.”HHHAAAHHHAAAAHAHHAAA! This is your day, Homo, your death ceremony!HHAAHAHA!”\nMonths passed again……..\nPart 9 The daily live is almost the same as before, just that a part of the students in the orphanage is missing. But live is still very simple. Tasty food, friendly teachers, and visits to TOFB every other week.\nOne day, James is in his math class.\n“So when 2 is raised to the……”\n“Beep! Beep!”\nHis secret headphones from TOFB send a message request to him.\n“Beep! Beep!”\n“Didn’t that Ranboro guy say they won’t interrupt our classes?” James thought.\n“And let’s do some prob….”\n“Beep! Beep!”\nJames requests a bathroom break and answers the headphones in the boys’ restroom.\n“It’s an emergency!!! The Froakans are getting closer to the rattler!!! Help!!!! James, take Homo and get here now!” Norman cries.\nAs fast as he can, he rushes to Dr. Brains’ office, grabs Dr. Brains and locks him and himself into the TOTB-0111.\nAnd as fast as lightning, they are here, in the North town.\nThey rush into the elevator, he swipes his and Dr. Brains’ card and rushes to Dr. Ranboro’s office.\n“Quick! They will rattle it in like…like 20 minutes and we will all ratle!!!”, Norman hollers.\nAnd again, as fast as lightning, they get war-dressed and get into the fastest transport system in TOFB.\nAs James looks down, he is wearing a strong iron chest plate that reads ’T-O-F-B///////The Smarter one’. And on his shoulder, there is a cord which extends from his Digital ID to the chest plate. There is a screen in his chest plate that is unbreakable. There is a soft protection layer, then there is a swimming layer, then the pressure layer, an iron pad, an air supply on his side if the enemy spreads poisonous gas, and an armor on the outside.\nAmazingly, these things only weigh 1 pound and fit perfectly.\nHe is war-trained, so he knows exactly what to do with this fancy outfit. The screen is the main control, the outfit will detect the environment and change to the perfect layer.\nUploaded ate 10/25/2015 [sic.]\nPart 10 The ride seems to be long, but it’s actually only 5 minutes. They will enter the Ratle Mountains from the North End, which is the second-safest route into the mountains without Dr. Ranboro’s key.\nAnd there they are, in the Ratle Mountains. They are led by Mr. Giose, who was the other guy in his dream when he came to the TOFB the first time. The other four warriors are Norman, Dr. Ranboro, Dr. Brains and James. The first 20 miles are short and boring. Nothing happens. But after the 29th mile mark, they enter a cave.\nThe cave is dark. There are only few lights flashing. They are not worried, until they hear a scream.\n“OOOOOOO! Eeeek!”\n“Ahhhhhhhhhhhh! ZZZ! ZZZ…ZZZ..ZZZ…ZZZ…ZZZ…zzz…” The voice is getting smaller and smaller.\n“It is the sleeping spider! It will knock out a human in NO time!” Mr. Giose shouts.\nJames and the whole crew know what to do. They press a few buttons on their screens, and their helmets of their armor dissolve into the air. What is left behind, is the air filtering system.\n“Three! Two! One! It’s gas,” Norman says, playfully.\nDr. Brains spreads out the SSG gas, which will, hopefully, knock out the sleeping spider.\nThat wastes a LOT of time. Before they know it, they all starts to ratle.\nIt is James who feels it first. He feels extremely and uncontrollably happy. He starts running around and talking to other people in a rude way. To himself, it feels like as if he is drifting into unconsciousness.\nThen the same happens to Dr. Brains, and then Norman, followed by Mr. Giose. Luckily, Dr. Ranboro called the TOFB’s team 2 to come for help before he changes, too.\nI never knew what happened after this incident until the year of 2021. Since James was ratling, he couldn’t remember the whole year of 2020. He recovered on the day of 10/26/2021. Dr. Foster, who works at the orphanage AND at TOFB found a cure using Chinese Herbal Tea.\nWell, let’s jump into the time machine. Backward to 2014!!\nChapter 4:Childhood We jump into the time machine, and swoosh. Here we are, in the year of 2014. We are standing in front of 1623 Wesson Ave. It is a sunny day. The Peters are getting ready for a trip to Africa. James greets his uncle, who will look after the house while they are gone. Mrs. Peter is packing hastily. And Mr. Peter is bringing his computer, because, weirdly, he is starting to like CODING in BINARY CODE. Nothing more to say, so here the story goes.\nPart 11 “Hurrrrrryyyy!” Mr. Peter shouts. “Or else we will be late for the plane!”\nThe Peters hurry to the bus stand, waiting for the airport express.\nAfter about an hour ride, they finally arrive at the San Francisco International Airport.\nThey check in. And they hurry to the security check. At the security check, Mrs. Peter thinks she forgot something. Yes, she forgot to bring ANY medication for the disease Ebola.\n","permalink":"https://www.jemoka.com/posts/kbhnorman_an_epic_tale_in_n_parts/","tags":null,"title":"Norman: An Epic Tale in N Parts"},{"categories":null,"contents":"\u0026ldquo;Doing NSM analysis is a demanding process and there is no mechanical procedure for it. Published explications have often been through a dozen or more iterations over several months\u0026rdquo; \u0026mdash; (Heine, Narrog, and Goddard 2015)\nApproach and XD Introduction and Theory The Natural Semantic Metalanguage (NSM) approach (Wierzbicka 1974) is a long-standing hypothetical theory in structural semantics which claims that all human languages share a common set of primitive lexical units\u0026mdash;usually words, but, in some languages, short connected phrases\u0026mdash;through which all other words in each language can be defined.\nFor NSM to hold, two main results must be demonstrated. (Heine, Narrog, and Goddard 2015) The theory\u0026rsquo;s validity hinges, first, upon the existence of semantic primes\u0026mdash;a series of primitive lexical units both indefinable via other words in the same language but also is universally lexicalized across all languages. Second, the theory\u0026rsquo;s confirmation requires the ability to perform \u0026ldquo;reductive paraphrasing\u0026rdquo;, the process of defining all other words in a language with respect to the universal semantic primes\u0026rsquo; manifest in that language.\nIf proven as fact, the NSM theory and its implications has reaching implications into the long-standing (footnote: not to mention often personally fierce) conflict between the newer theories of generative semantics\u0026mdash;where structure of language is created in support of meaning\u0026mdash;and Noam Chomsky\u0026rsquo;s transformational generative syntax\u0026mdash;where meaning is filled to precomputed structure, which NSM suggests (Harris 2021).\nThe difficulty of forming adequate investigations in the area of NSM is due the theory itself being exceedingly hard to falsify\u0026mdash;the principle method through which NSM is demonstrated is via the manual (i.e. non-standardized) lexicalization of semantic primes and a partial demonstration of their relations (Geeraerts 2009) to other words in the language. Whenever one irregularity in the theory is identified (Bohnemeyer 1998), the proponents of the theory simply respond with another update to the (non standardized) set of reductive paraphrasing rules to account for the irregularity (NO_ITEM_DATA:goddard1998bad.)\nYet, there are repeated empirical (again, non-standardized) confirmations of the existence of the original set (Wierzbicka 1974) of semantic primes in other languages (Chappell 2002; Peeters 1994; Travis 2002); there are also numerous demonstrations of the proposed applications (Goddard 2012) of the theory in structural semantics. These facts has therefore maintained the relevance of NSM in current linguistic study but rendered the theory without a very clear path forward. Due to this reason, recent research has placed larger focus on functional (cognitive linguistical) theories (Divjak, Levshina, and Klavan 2016) and largely overlooked structuralist arguments like the NSM.\nBroad Goals and Approach To complement the very large body of work already in the identification of semantic primes for NSM in numerous languages, we aim in this project to investigate the process of reductive paraphrasing to provide a baseline evaluation of the feasibility of NSM as a theory. The approach proposed below is intended to very generally test the practicality of the act of reductive paraphrasing from the published set of primes: whether paraphrasing from those primes is even broadly possible across the entire lexicon of the few languages for which it is purported to be possible. This test remains needed because, quite counter-intuitively, metalanguage theorists have been constructing lexicalizations for non-prime words on an \u0026ldquo;as-needed\u0026rdquo; basis such as in (Wierzbicka 2007). No lexicon-wide demonstrations of lexicalizability has been performed (i.e. reductive paraphrasing all words down to the primes) as the current approach of manual definition of words from primes is significantly time-consuming and requires careful consideration of NSM\u0026rsquo;s semantic grammar between primes.\nWe aim perform a lexicon-wide test of reductive paraphrasing computationally via much newer approaches in computational linguistics, specifically model-based Natural Language Processing (NLP).\nIn order to isolate the exact problem of reductive paraphrasing, we first will have to highlight a few key assumptions by the NSM theory and therefore this project.\nThe semantic metalanguage theory is itself built on the assumption that \u0026ldquo;each language is its own metalanguage\u0026rdquo; (Goddard 2002)\u0026mdash;that human languages are broadly lexicalizable by itself (i.e. one can write an English dictionary by only using English.) We believe that the examination of this assumption is not within scope of the study and\u0026mdash;given it is fairly universally true from a practical standpoint (i.e. English dictionaries exist)\u0026mdash;we will take it as fact. We will use this fact further as the control for the feasibility of the approach, as discussed in the section below.\nThe remaining assumptions of NSM to be tested here, then, is that 1) semantic primes exist and 2) the original set of NSM primes published (Wierzbicka 1974) (and in subsequent studies in various other languages highlighted before) are correct and, through reductive paraphrase, can lexicalize every word in the lexicon.\nAims and Experimental Design In this study, we aim to develop a computational protocol for lexicon-wide testing of the possibility of performing reductive paraphrasing for every word in the lexicon given a set of purported semantic primes. Practically, this means that we are trying create a model to test whether all words in a language is lexicalizable when restricted to only using a chosen subset of primes in the same language.\nTo create a truly replicable test for lexicalizability under restriction, we turn to probabilistic NLP approaches. We propose the following metric for lexicalizability: a word is \u0026ldquo;lexicalizable\u0026rdquo; under some set of semantic primes if there is a lossless mapping between a linear combination of the primes\u0026rsquo; latent embeddings to the word in lexicon space.\nUnder this model, all words in the lexicon are lexicalizable by the set of primes being tested if there is a lossless projection of the bases of the lexical space to the primes\u0026rsquo; latent embedding space.\nThat is, given we have a latent embedding space of \\(n\\) semantic primes \\(P^n\\) and some lexicon \\(W\\) with \\(m\\) words, we aim to identify a linear mapping \\(M\\) such that:\n\\begin{equation} Mp = e_{W_j}\\ |\\ p \\in P^n, \\forall j=1\\ldots m \\end{equation}\nwhere, \\(e_{W_j}\\) is the \\(j\\) th standard basis of \\(W\\) (i.e. \\(j\\) th word in the lexicon.)\nThis projection is not, in principle, impossible. In the high-dimensional space of the entire lexicon, individual lexicalized words represent only the basis vectors of the space (and indeed in one-hot encodings for deep learning they are shown as the standard-basis of the lexicon-wide space.) Whereas in the lower-dimensional subspace of primes, a linear combination of primes can be used to represent each lexicalized word in the full lexicon.\nSuccess in identifying a feasible \\(M \\in \\mathcal{L}(P, W)\\) for a given \\(P\\) and \\(W\\) indicates the feasibility of finding a linear combination in \\(P\\) which maps to all \\(w \\in W\\), which means reductive paraphrase of \\(w\\) to a set of primes in \\(P\\) is possible as there is a direct \u0026ldquo;translation\u0026rdquo; (namely, \\(W\\)) from \\(P\\) to \\(W\\).\nTo actually compute \\(W\\) given \\(P\\) and \\(M\\), we leverage the well-established Transformer encoder-decoder architecture for language modeling (Vaswani et al. 2017). Furthermore, we frame the problem as one of unsupervised multi-lingual translation without alignments.\nThe basis of the model proposed to be used to obtain \\(W\\) is (Artetxe et al. 2018), a unsupervised multi-lingual translation model.\nFigure from (Artetxe et al. 2018).\nAs we are performing the task with word embeddings, not sentences like that of (Artetxe et al. 2018), the cross-attention lookup vector will serve no purpose (be \\(0\\)) (Niu, Zhong, and Yu 2021) and hence removed.\nFor the sake of standardization, we will call \\(P\\) the primary language/lexicon \\(L1\\), and \\(W\\) the second language/lexicon \\(L2\\). The basic hypothesis provided by (Artetxe et al. 2018) is that, through alternating samples of \\(L1\\) and \\(L2\\) through the model against their corresponding decoders using a shared encoder and separate decoders, the shared encoder is trained to perform the task of autoencoding for both lexicons at once. Therefore, at prediction time, to get the \u0026ldquo;translation\u0026rdquo; of an input, one simply applies the decoder of the desired lexicon to obtain a result.\nDuring training, the input to the shared encoder can either be a word from either \\(P\\) or $W$\u0026mdash;sampled with equal probability. If the input is from \\(P\\), we connect the output of the shared encoder with the \\(L1\\) decoder and train with the objective of recovering the input. Essentially, we are using the model as a alternate method of training a variational auto-encoder (Klys, Snell, and Zemel 2018) with alternating decoders given the lexicon being analyzed.\nThis task is trivial if the embedding space after the shared encoder is exactly as wide as both lexicon. However, we will restrict the output dimension of the shared encoder to \\(dim(P)\\) which after training we will call the latent embedding space of \\(L1\\); this name is verified and justified as a part of the feasibility check below.\nWe will also use the backtranslation mechanism proposed by (Artetxe et al. 2018) during training: whereby the autoencoded output from \\(L1\\) is used as target for the same input as \\(L2\\) (as well as the reverse), mimicking the process of translation.\nAfter training, the \\(L2\\) decoder would then be the candidate \\(W\\), mapping from the (proposed) latent embedding space of \\(P\\) to the lexicon \\(W\\).\nFollowing both (Artetxe et al. 2018; Conneau and Lample 2019) we will use cross-entropy as the objective function of training.\nFeasibility Checkpoint We first need to show that, as expected, the model architecture proposed above\u0026mdash;upon convergence\u0026mdash;will create a latent embedding for \\(L1\\) after encoding if the output size for encoding is \\(dim(L1)\\) (defined to be equal to \\(dim(P)\\)).\nA trivial test of whether the encoding output is desirably the embedding space of \\(L1\\) is that, through training with a toy mapping \\(P=W=L1=L2\\), we would expect both decoders to be an one-to-one mapping that simply copies the input. That is, after training with \\(P=W\\), we should see that activating one input in the shared post-encoding space should activate one or close to one feature only in both decoder\u0026rsquo;s output space.\nNumerically, this means that the result obtained from taking the mean entropy of both outputs given a singular input activation should be statistically insignificantly different from \\(0\\).\nThat is, we expect that given trained decoders \\(L_1\\) and \\(L_2\\), and standard bases of \\(W=P\\) named \\(e\\), we should see that:\n\\begin{equation} \\frac{\\log(L_1e_j) + \\log(L_2e_j)}{2} \\approx 0: \\forall j = 1\\ldots dim(W) \\end{equation}\nWe expect this result because, through gradient-descent, the quickest minima reachable to capture variation in the input perfectly is the copying task; therefore, we should expect here that if the post-encoding distribution is the same distribution as the input, the model\u0026rsquo;s decoders will fit to the copying task. If the post-encoding distribution is different from the input, the model\u0026rsquo;s decoders would then have to actually perform nontrivial mappings to achieve the desired autoencoding result.\nCheckpoint 2 + Hypothesis 1 The following is the first novel result that we can show with the new architecture. We first hypothesize that the model should converge when training to the target of the (already linguistically accepted, as aforementioned) result that English words are themselves a metalanguage.\nFor \\(dim(W)\\) iterations (similar to (Webb et al. 2011)), we will leave a word chosen at random out of the lexicon of \\(P\\). This operation results in \\(dim(P) = dim(W)-1\\). We will then train the model until a local minima is reached and measure convergence.\nTo test this hypothesis, we will measure the cross-entropy performance of \\(L2\\) decoder upon the word that is left out. The resulting loss should be statistically insignificantly different from \\(0\\) if the word is successfully lexicalized via the \\(dim(W)-1\\) other words not left out in \\(P\\) in the latent embedding space after encoding.\nIf the hypothesis is not successful, the model cannot converge even on a large subset of the entire lexicon, much less in the limited subset of the 60-word NSM-proposed metalanguage; it is therefore imperative not to continue the study unless convergence at this point can be shown. Importantly, however, failures in this step does not show any claims about reductive paraphrasing as we are simply benchmarking the model against a control linguistic assumption we discussed earlier.\nIn any case, it would be valuable at this point to again perform analyze for post-encoding output to observe any reductive paraphrasing behavior.\nHypothesis 2 At this point, we will set the lexicons to the sets we are actually testing. We will set \\(P\\) to be the list of semantic primes established by (Heine, Narrog, and Goddard 2015), and \\(W\\) to the English lexicon.\nShould lexicalization of all of the English lexicon via the semantic primes only be possible, this model should again converge after training with cross-entropy inappreciably different from \\(0\\). This result would indicate the existence of a \\(W\\) (i.e. \\(L2\\) decoder), indicating the possibility of lexicon-wide reductive paraphrasing.\nInstitution and Experience The actual protocol proposed as a part of this study (namely, creating, training, and calculating metrics from the autoencoder) is a technical concept taught as a part of the regular curriculum of Advanced Machine Learning at Nueva; however, expertise and mentorship may still be required when implementing a complex model topology and training mechanism like the one proposed. The open-ended project structure of the Advanced Machine Learning course supports and sometimes necessitate implementing a model like the one proposed with the help of the CS faculty. Therefore, if additional mentorship is indeed required, there exists support available within the institution.\nThe more difficult skill-set to capture is the knowledge regarding the theories of NSM and the field of structuralist linguistics in general. As of writing, we are not aware of any students which has an active research interest in traditional linguistics; however, this knowledge constitute a far more insignificant portion of the actual mechanics of the project and is more importantly very easily taught. Mentorship is also available here from members of the Mathematics and CS faculty with prior research interest in computational linguistics.\nIn terms of equipment, the most important tool required in working with a large-scale neural network is a matrix-mathematics accelerator; this often takes the form of a consumer graphics card and typical desktop computing setup. For the Machine Learning course taught at Nueva, Google\u0026rsquo;s Colab (and their free graphics card addition) is frequently used to address this need and would at a minimum suffice here. Also, it is based on the personal experience of the author, though by no means definite, that a large selection of students at Nueva has comparable hardware for training available at home.\nProvided network access to the computing accelerator, this experiment can be done under any setting and definitely does not necessitate the use of the biology lab.\nImpact Academic Significance Within the short term, this experiment provides two major results. First, it establishes the use of a bifercated unsupervised encoder-decoder translation model like that proposed by (Artetxe et al. 2018) as a Conditional Variational Autoencoder (CVAE) (Klys, Snell, and Zemel 2018) with the ability to define and train the hidden latent representation after encoding. Although traditional CVAEs are frequently more suited for most output-aware generation tasks, this new scheme supports the direct influence of the latent representations of the encoder instead of using an additional input to both the encoder and decoder to influence such representations, like in traditional CVAEs. This difference is significant for as it creates the where dimensional projection is needed but the content of the latent representation itself is also relevant to the study.\nOf course, the short-term result also includes the direct result of the second tested hypothesis: a systemic, lexicon-wide evaluation of the feasibility of reductive paraphrasing. The study is to develop a computational protocol for lexicon-wide reductive paraphrasing by creating a lossless mapping between a linear combination of the primes\u0026rsquo; latent embeddings to the word in lexicon space.\nIf both initial metrics succeeds and the third, final reduction step with actual semantic primes fail, the result would indicate an inability to create such a lossless mapping, and therefore raise concerns about the lexicon-wide applicability of the reductive paraphrasing on the set of published semantic primes. That, there is not even a locally convergent linear combination of primes that will generally describe all of the lexicon, despite the hypothesis by NSM theorists. This result will be highly impactful for NSM theory in general which necessitates the possibilty of reductive paraphrase (Geeraerts 2009) (Vanhatalo, Tissari, and Idström, n.d.).\nOn the long term, demonstrations of reductive paraphrasing has wide-reaching implications into NSM theory is general (Heine, Narrog, and Goddard 2015; Geeraerts 2009), and the field of language learning. The paraphrasing capacity of the proposed embedding would hypothetically be able to create a semantic mapping between a set of words to one other word; in this way, it is not infeasible to create a language-learning tool with continually larger embedding size to slowly create a larger lexicon in the target user. Early results (Sharma and Goyal 2021) have shown a possible application of such an approach, using supervised machine translation techniques.\nLearning and Teaching One to two students, along with a facilitator, would be an ideal size for this experiment. Primarily, the three main roles will include model engineering, training and validation, and model ablation and testing. The last role requires the most amount of traditional linguistics knowledge as the student\u0026rsquo;s role would be to connect the weights in the model to the applicable theories being tested.\nThe study proposed is an extremely conventional empirical Machine Learning/NLP study. From a pedagogical standpoint for XRT, this study will be a diversion from the traditional wet-lab sciences or survey-based educational/social sciences commonly produced by the lab and lead a new avenue for the Lab\u0026rsquo;s expansion. Within Nueva, empirical research into machine learning is frequently done through independent study or the Intro/Advance machine learning courses\u0026mdash;which were recently expanded due to widening interest at the Upper School.\nParticipation in this project provides its constituent students an opportunity to practice publish-quality ML/NLP in a longer-term and multi-stage project previously not possible through semester-long courses. Students are trained to perform model construction, data selection and cleaning, collection of model validation metrics, as well as model ablation and interpretation: important concepts in ML operations taught but not formalized in the Machine Learning course as the course exercises, while open-ended, isolate only one skill and have expected outcomes.\nGiven the demand and rate of student progression between Intro/Advanced courses in ML each year, developing a suitable approach to propagate true machine-learning research will be relevant to upwards of 30 students each year.\nIncidentally, students also get an exposure to the practice of conventional linguistics and the new trend of applying empirical research NLP back against classic semantics; however, the demand for this exact skill is likely small at Nueva.\nThough the tool used and expanded upon by this experiment is applicable to the NLP research community, it is unfortunately difficult to predict its future applications to XRT or Nueva students without seeing more expansion into the area of ML and NLP by the XRT lab.\nSafety and Ethics The following are the responses to the safety and ethics checklist.\nThis project does not satisfy any triggers of the second-expert protocol. All data needed is from a dictionary (for the English lexicon, e.g. (Fellbaum 2010)) as well as the semantic primes listed in a figure on the article (Heine, Narrog, and Goddard 2015). The data is being generated during compute. The actual compute hardware will need to be stored in either in the cloud (not on-prem), physically in the iLab, or (for personal compute hardware), in students\u0026rsquo; homes. An internet connection and a model training acceleration scheme (such as the free Google Colab) would suffice. None foreseeable See below The experiment is done on the English lexicon. It is difficult to imagine a tangible harm from the experiment. This study provides students with an opportunity to conduct a full research study in ML; XRT has not had this from of projects before and approval would result in a new avenue of research being conducted with XRT. However, if the project is not approved, other ML projects may subsequently surface and students can leverage those opportunities to learn about the practice of empirical ML instead. As with most machine-learning projects, it is customary and appropriate to end with a statement on ML ethics and its implications. This study is a linguistics, lexicon-scale study, and the data sourced is available generally and not subject to copyright or any known data-protection laws. The inputs to the model are combinations of English words, and the model produces singular English words. The benefits of this model involves generating new knowledge about the English lexicon and semantic theories. The only known harm of the model involves the mis-intepretation of its results, creating overreaching generalizations to semantic primality analysis or NSM theories. The model and source code can be released to the general public without broad impact.\nAcknowledgments I would like to thank Brandon Cho at Princeton University and Ted Theodosopoulos at The Nueva School for the very interesting discussion/argument that resulted in this proposal almost a year ago. I would like to thank Klint Kanopka at Stanford University for his mentorship and discussion of the overall feasibility of the approach and pointing out the path that lead to the proposed model\u0026rsquo;s basis in machine translation. Finally, I would like to thank Prof. Brian MacWhinney at Carnegie Mellon University for pointing out discourse between structuralism/functionalism during our exchanges and for his mentorship in my exploration of computational linguistics.\nReferences Artetxe, Mikel, Gorka Labaka, Eneko Agirre, and Kyunghyun Cho. 2018. “Unsupervised Neural Machine Translation,” 12. Bohnemeyer, Jurgen. 1998. “Temporal Reference from a Radical Pragmatics Perspective: Why Yucatec Does Not Need to Express ’after’ and ’before’.” Walter de Gruyter, Berlin/New York Berlin, New York. Chappell, Hilary. 2002. “5. The Universal Syntax of Semantic Primes in Mandarin Chinese.” In Studies in Language Companion Series, 243–322. Studies in Language Companion Series. John Benjamins Publishing Company. doi:10.1075/slcs.60.12cha. Conneau, Alexis, and Guillaume Lample. 2019. “Cross-Lingual Language Model Pretraining,” 11. Divjak, Dagmar, Natalia Levshina, and Jane Klavan. 2016. Cognitive Linguistics 27 (4): 447–63. doi:doi:10.1515/cog-2016-0095. Fellbaum, Christiane. 2010. “Wordnet.” In Theory and Applications of Ontology: Computer Applications, 231–43. Springer. Geeraerts, Dirk. 2009. “Neostructuralist Semantics.” In Theories of Lexical Semantics, 124–78. Theories of Lexical Semantics. Oxford University Press. doi:10.1093/acprof:oso/9780198700302.003.0004. Goddard, Cliff. 2002. “The Search for the Shared Semantic Core of All Languages.” In Meaning and Universal Grammar: Theory and Empirical Findings. John Benjamins Publishing Company. ———. 2012. “Semantic Primes, Semantic Molecules, Semantic Templates: Key Concepts in the NSM Approach to Lexical Typology.” Linguistics 50 (3). doi:10.1515/ling-2012-0022. Harris, Randy Allen. 2021. The Linguistics Wars: Chomsky, Lakoff, and the Battle over Deep Structure. Oxford University Press. Heine, Bernd, Heiko Narrog, and Cliff Goddard. 2015. “The Natural Semantic Metalanguage Approach.” In The Oxford Handbook of Linguistic Analysis, edited by Bernd Heine and Heiko Narrog. Oxford University Press. doi:10.1093/oxfordhb/9780199677078.013.0018. Klys, Jack, Jake Snell, and Richard Zemel. 2018. “Learning Latent Subspaces in Variational Autoencoders,” 11. Niu, Zhaoyang, Guoqiang Zhong, and Hui Yu. 2021. “A Review on the Attention Mechanism of Deep Learning.” Neurocomputing 452 (September): 48–62. doi:10.1016/j.neucom.2021.03.091. Peeters, Bert. 1994. “16 Semantic and Lexical Universals in French.” In Studies in Language Companion Series, 423. Studies in Language Companion Series. John Benjamins Publishing Company. doi:10.1075/slcs.25.20pee. Sharma, Prawaal, and Navneet Goyal. 2021. “Zero-Shot Reductive Paraphrasing for Digitally Semi-Literate.” In Forum for Information Retrieval Evaluation, 91–98. Travis, Catherine E. 2002. “4. La Metalengua Semántica Natural.” In Studies in Language Companion Series, 173–242. Studies in Language Companion Series. John Benjamins Publishing Company. doi:10.1075/slcs.60.11tra. Vanhatalo, Ulla, Heli Tissari, and Anna Idström. n.d. “Revisiting the Universality of Natural Semantic Metalanguage: A View through Finnish,” 28. Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. “Attention Is All You Need,” 11. Webb, Geoffrey I., Claude Sammut, Claudia Perlich, Tamás Horváth, Stefan Wrobel, Kevin B. Korb, William Stafford Noble, et al. 2011. “Leave-One-Out Cross-Validation.” In Encyclopedia of Machine Learning, edited by Claude Sammut and Geoffrey I. Webb, 600–601. Boston, MA: Springer US. doi:10.1007/978-0-387-30164-8_469. Wierzbicka, Anna. 1974. “Semantic Primitives.” Lingua 34 (4): 365–69. doi:10.1016/0024-3841(74)90004-7. ———. 2007. “Bodies and Their Parts: An NSM Approach to Semantic Typology.” Language Sciences 29 (1): 14–65. doi:10.1016/j.langsci.2006.07.002. NO_ITEM_DATA:goddard1998bad. ","permalink":"https://www.jemoka.com/posts/kbhnsm_proposal/","tags":null,"title":"NSM Proposal"},{"categories":null,"contents":"NUS Secondary School Other Duties AP Statistics Index AP Phys C Mech Index Tuning Forks bioinformatics NUS-MATH580 QIC Date Topic \u0026lt;2022-04-05 Tue\u0026gt; physical qubits, manipulating physical qubits \u0026lt;2022-04-08 Fri\u0026gt; making qubits interact \u0026lt;2022-05-10 Tue\u0026gt; Chiara Marletto \u0026lt;2022-05-24 Tue\u0026gt; Strong Free Will NUS-CS223 Algorithms Backlog: Finite State Machine\nDate Topic \u0026lt;2022-04-07 Thu\u0026gt; stable matching problem, stable matching algorithm \u0026lt;2022-05-02 Mon\u0026gt; dynamic programming, relaxation \u0026lt;2022-05-23 Mon\u0026gt; distributed algorithum, randomized algorithum, complexity theory NUS-HIST301 American History Backlog: New Deal, Franklin D. Roosevelt (FDR), Works Progress Administration, effects of the New Deal, Great Depression, Herber Hoover, disinformation\nDate Topic \u0026lt;2022-04-07 Thu\u0026gt; WWII, propaganda \u0026lt;2022-05-02 Mon\u0026gt; cold war \u0026lt;2022-05-09 Mon\u0026gt; civil rights \u0026lt;2022-05-26 Thu\u0026gt; Richard Nixon \u0026lt;2022-06-01 Wed\u0026gt; Ronald Raegan NUS-PHYS301 Mech Date Topic \u0026lt;2022-04-12 Tue\u0026gt; String Yo-Yo Problem, rotational energy \u0026lt;2022-05-24 Tue\u0026gt; Gyroscopes NUS-ENG301 English Date Topic \u0026lt;2022-04-15 Fri\u0026gt; secondary source comparison activity Essays Bluest Eye Essay Planning NUS-MATH530 Please refer to Linear Algebra Index\nNUS-ECON320 Financial Econometrics Date Topic \u0026lt;2022-08-25 Thu\u0026gt; Financial Markets Intro, ECON320 Architecture NUS-CS350 Software Studio Date Topic \u0026lt;2022-08-25 Thu\u0026gt; User Interviews NUS-MATH570 DiffEq Date Topic \u0026lt;2022-08-26 Fri\u0026gt; DiffEq Intro ","permalink":"https://www.jemoka.com/posts/kbhnueva_courses_index/","tags":["index"],"title":"Nueva Courses Index"},{"categories":null,"contents":"A number can be any of\u0026hellip;\n\\(\\mathbb{N}\\): natural number \\(\\mathbb{Z}\\): integer \\(\\mathbb{Q}\\): rational number \\(\\mathbb{R}\\): real number \\(\\mathbb{P}\\): irrational number \\(\\mathbb{C}\\): complex number ","permalink":"https://www.jemoka.com/posts/kbhnumber/","tags":null,"title":"number"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhobjects/","tags":null,"title":"object"},{"categories":null,"contents":"The Open Voice Brain Model is a audio processing architecture proposed by Laguarta 2021 for audio/biomarker correlation work.\nHere\u0026rsquo;s a fairly self-explanatory figure:\nThe model outputs an AD diagnoses as well as a longitudinal correlation with Memory, Mood, and Respiratory biomarkers.\nThis is then the embedding that they are proposing for use by other tasks.\n","permalink":"https://www.jemoka.com/posts/kbhopen_voice_brain_model/","tags":null,"title":"Open Voice Brain Model"},{"categories":null,"contents":"OpenSMILE is a proprietary audio feature exaction tool.\nSite.\n","permalink":"https://www.jemoka.com/posts/kbhopensmile/","tags":null,"title":"OpenSMILE"},{"categories":null,"contents":" adding multiplying This is object dependent.\n","permalink":"https://www.jemoka.com/posts/kbhoperation/","tags":null,"title":"operation"},{"categories":null,"contents":"Richard Nixon bombs Vietnam for 13 days to beat the VietCong into submission after the Vietnam War.\n","permalink":"https://www.jemoka.com/posts/kbhoperation_linebacker/","tags":null,"title":"Operation Linebacker"},{"categories":null,"contents":"oral lexical retrival is a class of discourse tasks which asks the subject to convert some semantic understanding (\u0026ldquo;concept\u0026rdquo;) into lexical expressions (\u0026ldquo;words\u0026rdquo;)\n\u0026ldquo;ask a patient to describe a thing.\u0026rdquo;\nExamples of oral lexical retrieval:\nSVF BNT Source: CambridgeCore\n","permalink":"https://www.jemoka.com/posts/kbhoral_lexical_retrival/","tags":null,"title":"oral lexical retrieval"},{"categories":null,"contents":"Reading notes conservatives in America make less sense because America is supposed to be liberal/new For most Europeans who came to America, the whole purpose of their difficult and dis- ruptive journey to the New World was not to conserve European institutions but to leave them behind and to create something new, often an entirely new life\nThree splits of conservatism in America those who are most concerned about economic or fiscal issues, that is, pro-business or “free-enterprise” conservatives those most concerned with religious or social issues, that is, pro-church or “traditional-values” conservatives those most concerned with national-security or defense issues, that is, pro-military or “patriotic” conservatives Ronald Reagan unified the three conservatism It was the achievement of Ronald Reagan that he was able in the late 1970s to unite these three different kinds of conservatism into one grand coalition.\nThree-in-one conservatism is a part of American \u0026ldquo;fusionist strategy\u0026rdquo; This was the culmination of a “fusionist strategy” that had been developing amongst American conservatives since the early 1960s.\nBusiness and social conservatism should contradict each other, though However, as we shall see, pro-business conservatism has always included a tendency toward the disruption and even dissolution of religious ideals and social practices.\nExtreme pro-business should also include globalization and erasure of national identities And in recent decades, pro-business conservatism has also included a tendency toward the dismantling of national boundaries and even dissolution of national identities\n\u0026ldquo;conservatism\u0026rdquo; actually conserved American revolutionary force economically this means that the conservative party in America has always sought to conserve a revolutionary force.\nExtreme economic \u0026ldquo;conservatism\u0026rdquo; should destry social and moral arrangements It destroys religious, social, and ultimately moral arrangements as well.\nReligions conservatism founds on the \u0026ldquo;open-market\u0026rdquo; of protestanism This open market in religious matters, so nicely isomorphic with the open market in economic matters, was a powerful factor gen- erating both a reality and an ideology of free choice in the United States.\nBecause the \u0026ldquo;new\u0026rdquo; became new protestanism, religious conservatism is the re-take over of traditional religions Since these churches were continually being left behind, religious conservatism was associated with once-dominant churches that were now dwindling into a minority, and would later dwindle into marginality\nBecause of mass economic benifit, religous conservatism became subordinated to economic conservatism Even ordinary middle-class Protestants benefited from cheaper labor, in the form of domestic servants. And of course it was the businessmen and middle-class Protestants who controlled the political parties, particularly that party which was supposed to be the more conservative one\nBecause there is nothing to conserve about current system, the thing that\u0026rsquo;s conserved is free choice If something were going to be conserved, it would normally be the no-conscription and low-taxation (and free-choice) system.\nEconomic systems propergated the source of American patriotism This meant that people who thought of themselves as American patriots or nationalists, and who sought to conserve the American nation and to promote American national interests\nAmerican conservatism is actually a form of European liberalism we have seen that, from a European perspective, American conservatism was not conservative at all, but actually was a kind of classical lib- eralism.\nwartime strengthened American values and liberalism Moreover, the wartime experience seemed decisively to vindicate and even enhance the strengths of both the traditional American economic system and traditional American moral principles.\n","permalink":"https://www.jemoka.com/posts/kbhrise_of_american_conservatism/","tags":null,"title":"Origins of American Conservatism"},{"categories":null,"contents":"DOI: 10.3389/fnagi.2020.605317\nOne-Liner An excercize scheme has had some measured effect on theta/alpha ratio and Brain wave frequency on AD patients; prognosis of AD not controlled for.\nNovelty Leveraged physical training scheme and measured EEG effects by quantifying theta/alpha ratio Notable Methods Used theta/alpha ratio as assay for improvement, and found the exercise scheme did so p\u0026lt;0.05 Only tested patients with AD w/o a control for stage Key Figs Figure 1 This figure tells us th N number of participants through the study\nFigure 2 This figure shows us that the excercize intervention has statistically significant results to both Brain Oscillation frequency and Theta/Alpha ratio. The x-axis shows us the pre-and-post bars for TG (treatment) and CG (control); the y-axis quantifies the value measured in a box plot. The subplots are brain oscelation and theta/alpha ratio respectively.\nNew Concepts theta/alpha ratio Notes ","permalink":"https://www.jemoka.com/posts/kbhparvin_2020/","tags":["ntj"],"title":"Parvin 2020"},{"categories":null,"contents":" No Demo Day TODO Email need statement template Needfinding Not all patients want to be treated the same way Attitudes towards heathcare system Fostering strong interaction; facilitate interaction Problem: patients have attitudes that physicians can\u0026rsquo;t effectively communicate.\nAction item: interview doctors and patients\nNeed two need statement.\n","permalink":"https://www.jemoka.com/posts/kbhpcp_april_checkin/","tags":null,"title":"PCP April Checkin"},{"categories":null,"contents":"We will leverage atoms as qubits. So, how do we isolate a qubit from an atom? We will leverage electrons.\nWe will select the lowest energy state as the base state; as there maybe multiple ground states, we will choose \\(|u\\big\u0026gt;\\) and \\(|d\\big\u0026gt;\\) from two of the states.\n","permalink":"https://www.jemoka.com/posts/kbhphysical_qubits/","tags":null,"title":"physical qubits"},{"categories":null,"contents":"physics is the act of explaining what we see in terms of solving for the \u0026ldquo;unseen\u0026rdquo;. For an explanation to be good, it needs to be testable.\nHow exactly does physics work? \u0026ldquo;classical results\u0026rdquo;\nNewton\u0026rsquo;s laws Maxwell\u0026rsquo;s equations General relativity \u0026ldquo;quantum theory\u0026rdquo;\nA new model that actually allows particle inference.\n","permalink":"https://www.jemoka.com/posts/kbhphysics/","tags":null,"title":"physics"},{"categories":null,"contents":"User Story\nSejin, during a main brunt of her job of scheduling inter or intra-admin meetings, need a solution to schedule many executives at once with attention to their priority/authority/importance to a meeting as well as the possible fluidity of their schedules.\nSejin spends most of her day scheduling people, of which, the largest time drawn is spent convincing people to move their schedules \u0026ldquo;in favor\u0026rdquo; of that of another person (i.e. manually). The reason why this is done is because her approach to scheduling is one-shot: emailing everybody for general availability, noting in her mind who the high-priority attendees are (say, Liza), and if no times match asking/convincing those in lower priority to move their schedules.\nFurthermore, there is an inherit fluidity to scheduling as a master-planner of a few admin\u0026rsquo;s schedules: in that, if needed, she has authority to move entire meetings as long as they are swapped for equivalent times of availability. Hence, a previously bad time may suddenly become available if enough scheduling conflicts is generated, thereby creating the incentive for swapping another meeting away for the one being scheduled and rescheduling other attendees of lower priority.\nCurrent scheduling software does not account for either types of fluidity. Tools like Doodle/When2Meet can accommodate for inherent \u0026ldquo;priority\u0026rdquo;\u0026mdash;with Sejin choosing the time-slot that would have the most, highest priority individuals scheduled\u0026mdash;but are one-shot planning tools which do not provide space for swapping entire meetings out to make scheduling work better. Other tools like Calendly or simple iCal does not provide any semblance of priority or \u0026ldquo;multi-possibility\u0026rdquo; for meetings, though does indeed provide the time-blocking capability to swap two meetings at will. These problems result in Sejin needing to just create large email chains to resolve scheduling problems.\nAlso, no scheduling tools provide an opportunity to manually \u0026ldquo;convince\u0026rdquo; or request someone to make time due to the constraints that presented during first-round scheduling.\nLastly, scheduling software does not space-block. Sometimes there is a physical capacity/de-duplication limit to spaces, which cannot be accounted for.\nMost importantly, however, Sejin wishes that scheduling response participation was higher; that, due to the busy schedules and often back-and-forth emails, response rates to complicated scheduling problems are low.\nProposal\nFundamentally, this is a fractional knapsack problem. \u0026ldquo;How do we maximize the maximum amount of attendance of maximum amounts of important people?\u0026rdquo;\nFrom a target market, I think a good target would be medium organization assistants: Sejin\u0026rsquo;s concerns really only become a problem when you are scheduling for a one (or few) vs. many situation where there is a stable group of people you are scheduling for, who wants to meet with each other or other people outside.\nAs far as UX, this tool should not require log-in except for the master planner (i.e. our user.) Participants in meeting should be able to freely enter their schedules or create evergreen accounts to manage their scheduling. (This is not as well thought out at the moment.)\nLastly, for the tech stack, I don\u0026rsquo;t think I have the ability to finish the entire stack by myself. From a MVP perspective (if we are trying to satisfy all needs), there needs to be a system optimizing a constantly shifting fractional knapsack, a way to put and store availability information, and a way to automate the requesting/convincing of scheduling change (e.g.. \u0026ldquo;MyApp Notification! Liza is not available at the one time you selected, but everyone else is available at this different time. Can you make this time? Y/N\u0026rdquo;) . Ideally, we would also send iCal invites in the end.\n","permalink":"https://www.jemoka.com/posts/kbhpitch_a_project/","tags":null,"title":"Pitch a Project"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhpolio/","tags":null,"title":"Polio"},{"categories":null,"contents":"For some \\(a \\in \\mathbb{F}\\), we define \\(a^m\\) to be \\(a\\) multiplied with itself \\(m\\) times.\nadditional information \\((a^m)^n = a^{mn}\\) \\((ab)^m = a^mb^m\\) ","permalink":"https://www.jemoka.com/posts/kbhpower_math/","tags":null,"title":"power (math)"},{"categories":null,"contents":"gravity sucks.\ngeneral relativity claims that our best theory of how gravity work does not work with non-\n","permalink":"https://www.jemoka.com/posts/kbhproblem_with_gravity/","tags":null,"title":"problem with gravity"},{"categories":null,"contents":"This is a work-in-progress page listing all of my production projects.\nYappin: Podcast https://anchor.fm/yappin/\n20MinuteRants: Blog https://20mr.substack.com/\nProject80: Podcast See Project80.\nNorman Stories: Fiction https://hidonipothan.substack.com/\n(left) Director - Hillview Broadcasting: Production Studio https://hillview.tv/\n","permalink":"https://www.jemoka.com/posts/kbhproduction_index/","tags":["index"],"title":"Production Index"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhprof_xin_liu/","tags":null,"title":"Prof. Xin Liu"},{"categories":null,"contents":"Project80 is a podcast hosted by Houjun Liu, Anoushka Krishnan, Micah Brown, Mia Tavares, among others.\nCollege Application w.r.t. Project80 Cheese mission statement: Project80 is a good way of creating a self-propegating set of learning that would serve to benefit and educate future generations in hopes of creating a more equitable planet.\n","permalink":"https://www.jemoka.com/posts/kbhproject80/","tags":null,"title":"Project80"},{"categories":null,"contents":"Natural science education resources traditionally teach only codified theory. While theory education is crucial, much of academic science takes place via scrutinizing contested scientific discourse. Due to such resources’ content complexity, high school students are rarely exposed to current, debatable, and relevant science. In response, we introduce Project80: a systemic, student-run protocol to synthesize the latest primary literature in a sub-field into approachable, produced multimedia educational content. The protocol is run by a team of 7 students over the course of 1 month. Students running the protocol consume complex scientific literature, distill relevant data and findings, and synthesize a culminating product of audiovisual content to supplement existing biology and chemistry pedagogy. The system runs independently with limited faculty involvement. Our analysis indicates that the multimedia content created by this protocol will be relevant to roughly 30 courses locally at our institution and will have further extensions in secondary education beyond.\n","permalink":"https://www.jemoka.com/posts/kbhproject80_abstract/","tags":null,"title":"Project80 Abstract"},{"categories":null,"contents":"Projects Index is a index that contains a list of almost all projects for which I have ever worked on. Major categories are highlighted from chapter titles.\nThis index does not include my jobs; it is meant to be a list of endeavors for which I had key designing or founding impact\u0026mdash;not including many paid-jobs with an existing structure but including small one-off scripts and utilities.\nResearch Projects I have spent the last 6 years or so working as an actively-publishing data science researcher; my research interests are mainly in textual data mining, semantic analysis, L2 learning, and science education. As a part of my work with Professor Brian Macwinney, I have also recently taken up interest in acoustic modeling.\nFor a list of my recent research, please head to the Research Index.\nMedia Production Projects I produce a lot of media (videos, podcasts, blogs, live events/talks) as a part of publicizing my work or for other purposes. For those types of projects, head on over to Production Index.\nLarge-Scale Endeavors Condution An open-source task management app. Website.\nMotivation: I got really tired with most other to-do apps after swapping them out over and over again, until I got fed up and built one with some friends.\nRole: Co-Founder, Lead Developer. Technologies: React, Ionic, Firebase, Typescript, Swift, PostgreSQL Key facts: 10,000+ users, 8-person team, featured in the Bay Area almanac, praised by Asana’s head of developer relations for “open-source advocacy” MODAP A R\u0026amp;D team for fireline safety during emergency fires. Repository.\nMotivation: a friend approached me with an opportunity to help our local community, especially with the increased influx of fires.\nRole: Team Lead Technologies: Rust, Torch, ARM, electronics (i2C, UART, messaging protocols, etc.) Key facts: coordinated 5 engineers in developing new technology, supported by Dr. Robert G. Gann, Deputy Director, Center of Excellence for Advanced Technology Aerial Firefighting at the state of Colorado as well as Captain Mason of CalFire CMU batchalign A pipeline for the automated preparation of annotated CHAT transcripts from raw audio. Repository.\nMotivation: my work over the summer.\nRole: Author Technologies: Torch, Huggingface, NLTK, CLAN, computational linguistics Key facts: work developed with and maintained under Prof. Brian MacWhinney at CMU\u0026rsquo;s psycolinguistics department. AIBridge A bootcamp for non-CS students in data science. Website\nMotivation:\nRole: Co-Founder, Lecturer Technologies: Python, ScyPy, Scikit-learn, Pandas Key facts: worked with Prof. Xin Liu at UC Davis to develop an introductary one-week bootcamp in ML. We piloted the program this summer at Davis to an in-person group of 20 PhD students in food science sponsored by AIFS. Full-Stack Projects tractotato CommonLisp macroset for time tracking. Repo.\nMotivation: I wanted to learn CommonLisp macros syntax after reading the Land of Lisp book.\nRole: author Technologies: CommonLisp Scratchathon Portal Portal to submit projects for a scratch hackathon I hosted. Repo.\nMotivation: my friends McGuy and fuelvin, both content creators on Scratch on YouTube, put together a Scratch hackathon summer of 2020. This is the submission portal.\nRole: author Technologies: React, Vercel, Firebase syzygy Library rethinking to-do list dating to be more flexible and powerful. Repo.\nMotivation: a friend and I wanted to innovate beyond the scope of Condution to see how we can abstract away a to-do list system to its bare minimum.\nRole: co-founder, co-author Technologies: Rust positron Library for building lightweight native apps using web tech. Repo.\nMotivation: I wanted to re-make electron to be more lightweight using Suckless\u0026rsquo; Surf browser concept.\nRole: author Technologies: C++, GTK OS/Driver Development Broadcom Wifi/Bluetooth 4377 Chip Linux Driver A driver patchset to support cutting-edge Broadcom 4377 Wifi/Bluetooth chips. Repo.\nMotivation: I needed to be able to use Wifi on my laptop while running Arch Linux.\nRole: author Technologies: C, (small amounts of) Assembly Key facts: integrated into the t2linux pipeline used to make WiFi possible on Linux for most MacBooks released after 2018 Distributed Algorithms and Parallel Computing coveather An encrypted, anonymized system for protected health information verification. Preprint, Repo, and internal note.\nMotivation: I wanted to be able to make vaccine passports more feasible because the current COVID testing/vaccine verification scheme is really bad.\nRole: author Technologies: Clojure, core.async concurrency, Monte-Carlo simulations, blockchain, PGP Key facts: project won first place at the California STEM Fair, and got special recognition from the Yale Science and Engineering assoc. Total award $3000. multischedule A multiple-asynchronous scheduling and delegation algorithm. Repo.\nMotivation: (didn\u0026rsquo;t even come close to getting there) I wanted to create a way to solve or simplify debugging loop overrun problems in robotics codebases.\nRole: author Technologies: Clojure, core.async concurrency rotifer A work-in-progress distributed algorithm for taproot. Repo.\nMotivation: I wanted to make taproot even more distributed if possible.\nRole: author Technologies: Clojure, XML, UDP, ICE simian Exploring OT/CRDT and collaborative text editing for taproot. Repo.\nMotivation: I wanted to learn about how apps like Google Docs work, and explore Operational Transformation/CRDT, in hopes of putting it into taproot.\nRole: author Technologies: Clojure, OT, CRDT aron A distributed multi-dimensional optimization tool. Repo.\nMotivation: Nueva\u0026rsquo;s course scheduling was quite a mess, and I wanted to help. It is a very complex problem and this project is in the freezer at the moment.\nRole: author Technologies: CommonLisp mitte Easy UDP sockets. Repo, Docs.\nMotivation: a friend and I wanted to explore UDP.\nRole: co-author Technologies: Rust, UDP, ICE (connection) Cryptography and security See also: coveather.\njrainbow An implementation of a MD5 rainbow table. Repo, Crate.\nMotivation: I wanted to understand how Rainbow Tables worked.\nRole: author Technologies: Rust, MD5 Note-taking Systems and \\(\\LaTeX\\) improvements taproot A shared zettlekasten of notes and learning resources put together by some friends and I. there has been a few iterations. Current Repo, Current Site, Legacy Site, Even More Legacy Site.\nMotivation: I started writing nice \\(\\LaTeX\\) PDFs of my homework, and some friends wanted to have access to it. Later when I mentioned it, another friend had a similar need; so we asked many people to pool our notes and work together to share.\nRole: co-founder, co-lead, developer Technologies: Next.JS, XeLaTeX, GNU Make, Firn, Hugo, Emacs Org, Org-Publish, Markdown blag The zettlekasten you are currently in! My currently maintained personal knowledgebase. Repo, Site.\nMotivation: I wanted to experiment with more advanced note-taking techniques after developing taproot, and it ended up superseeding the note-taking abilities of taproot.\nRole: author Technologies: Next.js, Emacs Org, Hugo gdoc.el A utility to enable GNU Emacs to edit Google Doc documents based on the gdrive utility. Repo.\nMotivation: I wanted to edit Google Docs in Emacs!\nRole: author Technologies: GNU Emacs, elisp interesting Things that my friends and I find interesting, chucked on the web and builds itself. Repo, Site. No longer maintained.\nMotivation: many text channels were too clogged with stuff my friend group found interesting, so I wanted to take initiative to collect them.\nRole: co-founder, author Technologies: Next.js, Vercel, remark, CommonMark Markdown Public Configurations borg Automatically configure terminals. Repo.\nMotivation: I needed a way to copy my system terminal config onto a system quickly.\nRole: author Technologies: Bash, Zsh, OhMyZsh .config A group of sane configuration files. Repo.\nMotivation: some Redditors asked for my Config, and I thought I\u0026rsquo;d share it to benefit the community; also for personal backup.\nRole: author, maintainer Technologies: Unix administration, Perl, Ruby, LISP .emacs.d Simple, powerful, and semantic GNU Emacs configuration for personal use. Repo.\nMotivation: I wanted to track my progress in developing a working Emacs config.\nRole: author, maintainer Technologies: GNU Emacs, elisp ","permalink":"https://www.jemoka.com/posts/kbhprojects/","tags":["index"],"title":"Projects Index"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhproof/","tags":null,"title":"proof"},{"categories":null,"contents":"Based on the wise words of a crab, I will start writing down some Proof Design Patterns I saw over Axler.\ninheriting properties (splitting, doing, merging) \u0026ldquo;complex numbers inherit commutativity via real numbers\u0026rdquo; construct then generalize for uniqueness and existence try to remember to go backwards to prove IFF ","permalink":"https://www.jemoka.com/posts/kbhproof_design_patterns/","tags":null,"title":"Proof Design Patterns"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhproof_of_work/","tags":null,"title":"proof of work"},{"categories":null,"contents":"propaganda is a form of advertising which:\npropaganda persuades people into believe in a cause often defies reason to reach into ?? See examples:\nUS WWII Propaganda techniques for propaganda Name calling Generalities Transferring of authority Public testimonial Attachment to plane folks Bandwagoning (FOMO) Fear Bad logic Unwanted extrapolation ","permalink":"https://www.jemoka.com/posts/kbhpropaganda/","tags":null,"title":"propaganda"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhcorrelation/","tags":null,"title":"quantum correlation"},{"categories":null,"contents":"The computation model behind quantum theory. It proposes quantum computers, proposed during the 80s. Theoretically, quantum computers have quantum supremacy, which is exciting. It is a theory that works with counterfactual information.\nquantum computer A quantum computer is a computer that uses quantum effects to perform Turing-like computations\nquantum supremacy That a quantum computer outperforms all classical computers\nuniversal computer \u0026ldquo;a programmable system whose repertoire includes all physically possible computations\u0026rdquo; \u0026mdash; Turing.\nYou will realize that modern computers are not actually capable of all computations\u0026mdash;apparently, they can\u0026rsquo;t make itself.\nTherefore, to actually achieve this, we have to make a more general type of computer: a constructor \u0026mdash; a universal quantum constructor.\n","permalink":"https://www.jemoka.com/posts/kbhquantum_information_theory/","tags":null,"title":"quantum information theory"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhquantum_supremecy/","tags":null,"title":"quantum supremecy"},{"categories":null,"contents":"quantum theory allows us to understand physics; it reconciliations the classical world with the quantum world.\nClassical particles, in the double slit experiment, would just straight go through and bounce off Actual particles (quantum) like light, under quantum theory, would actually exhibit interference via wave-like hebahior The measurement of quantum theory is done via quantum information theory.\n","permalink":"https://www.jemoka.com/posts/kbhquantum_theory/","tags":null,"title":"quantum theory"},{"categories":null,"contents":"A qubit is a two-layer quantum theory system.\nA classical bit is something that can be set between two values, a qubit between a much higher dimension.\n","permalink":"https://www.jemoka.com/posts/kbhqubits/","tags":null,"title":"qubit"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhr_n_meeting_with_angi/","tags":null,"title":"R@N Meeting with Angi"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhrandom/","tags":null,"title":"random"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhrandom_variables/","tags":null,"title":"random variable"},{"categories":null,"contents":"randomized algorithm is a type of algorithm, similar to relaxation.\nMake a hard problem easier by changing the problem What if, instead of guaranteeing we find the best/correct answer, we only provide some chance of finding the best/correct answer? primality testing primality testing is very important for modern crypto systems; we need to be able to find large prime numbers, and be able to generate them quickly.\ntraditional primality testing We can divide every prime number below \\(\\sqrt x\\). In theory, this is pretty fast, but we need to know all the primes we need to test.\nThis would therefore take \\(O(\\sqrt{x})\\) time.\nmiller-rabin primality testing miller-rabin primality testing is a primality testing randomized algorithm.\nConstruct a set of equations, each one requiring an exponentiation and a division If any of them is false, the number is composite If they are all true, the probability that the number is composite is reduced to \\(\\frac{1}{4}\\). If we run miller-rabin 10 times \\(O(10)=O(1)\\), the number is \\(1-\\left(\\frac{1}{4}\\right)^{10}\\) chance of being prime.\nThis is of course much much faster than traditional primality testing.\nModern cryptographic system uses this.\n","permalink":"https://www.jemoka.com/posts/kbhrandomized_algorithum/","tags":null,"title":"randomized algorithm"},{"categories":null,"contents":"rational numbers are ratios:\n\\begin{equation} \\mathbb{Q} = \\left\\{\\frac{a}{b} \\middle| a,b\\in \\mathbb{Z}, b\\neq 0\\right\\} \\end{equation}\n","permalink":"https://www.jemoka.com/posts/kbhrational_number/","tags":null,"title":"rational number"},{"categories":null,"contents":"\\(\\mathbb{R}\\) real numbers are numbers generatable by a possibly infinite sum of powers of 10.\n","permalink":"https://www.jemoka.com/posts/kbhreal_number/","tags":null,"title":"real number"},{"categories":null,"contents":"in NSM, reductive paraphrase is the act of reducing all utterances in a language into semantic primes.\nThis is usually done with the application of an inherent, universal grammar: the conceptual grammar of semantic primes.\nproblems with reductive paraphrasing In the experiment conducted by (Labov 1973), Labov (according to (Geeraerts 2009), manuscript not found) showed that the boundaries of cup vs. mug are not clearly delineated.\n","permalink":"https://www.jemoka.com/posts/kbhreductive_paraphrase/","tags":null,"title":"reductive paraphrase"},{"categories":null,"contents":"Thanks for opening Jack\u0026rsquo;s long rambly PDF. Please read all of it; I wanted to get this out there before anything else so I apologize in advance for a letter that\u0026rsquo;s on the longer side and I didn\u0026rsquo;t have time to write a shorter one.\nBefore you begin, please read Michael\u0026rsquo;s AMAZING notes on our pitch to get the context. It\u0026rsquo;s amazing. I will not repeat here anything mentioned there.\nPat yourself on the back Oh god was that a difficult semester. We got through many a challenges and worked together to solve most of them. That\u0026rsquo;s cool. We also built a thing that the XRT team liked; so that\u0026rsquo;s cool too.\nSome of you (in the meeting) will already have known, but we are greenlit to go into phase -1! What does that mean? What changes? How can you help? Will meetings finally end on time? When will Jack finish asking silly questions? Find out more\u0026hellip; below.\nBut not too hard Just to reiterate our master deliverable as a team (like how this pitch is culminating the deliverable assigned to us on 1/6), we have until July 8th, 2022 to pitch, again:\nWhat exactly are we doing, in one line, in laymen\u0026rsquo;s terms? Why is it helpful? Clarify the roles and responsibilities for the \u0026ldquo;master faculty member\u0026rdquo;, what time commitments and value they add, and what they have to drop to support the program How can we derive legitimacy for what we are doing? (see below) For me, he also added the derivable of talking more slowly. Presumably, De wants us to come with a glossy pitch too.\nBe legit Why do we need \u0026ldquo;legitimacy\u0026rdquo;? We need motivation for kids to do this, and Nueva\u0026rsquo;s rubber stamp would be a good way to do so. this is the focus of how we are asking Lisa to greenlight phase 2 (see below)\nA valid answer for \u0026ldquo;legitimacy\u0026rdquo; is \u0026ldquo;adding the list of skills students achieved on their transcript.\u0026rdquo; Is this a good answer? Not at the moment. Its very unmotivated (this response does not pass the \u0026ldquo;why is that helpful?\u0026rdquo; test).\nAnd follow the yellow-brick road There is going to be a three stage roadmap.\nPhase -1: developing answers to PREPARE to pitch to Liza the idea, asking her to give feedback WITHOUT any of the \u0026ldquo;asks\u0026rdquo; (legitimacy, faculty time, etc.) Phase 1: building a down-scaled version of the program somewhere. Ted has mentioned interest in this, so we maybe able to co-opt some or all of his classes. Developing details and proof-of-feasibility to pitch to Liza again, this time WITH the asks to roll out to the whole school Phase 2: roll out to the whole school and prey to the Research Gods But not the leader I can\u0026rsquo;t be around forever. We are in phase -1; I will probably be gone in the middle of phase 1. We will probably have to have a faculty supporting this program unofficially for sometime, which will be a big ask.\nThis means we have to make some program changes in anticipation\u0026mdash;\nSeek a corpus callosotomy \u0026ldquo;R@N\u0026rdquo; is now separated form \u0026ldquo;Nueva Research Program.\u0026rdquo; \u0026ldquo;R@N\u0026rdquo;\u0026rsquo;s purpose is a working group to build the \u0026ldquo;Nueva Research Program.\u0026rdquo;\nWe need to separate the two as soon as possible, so that means soon. As soon as after the 7/8 deadline, I hope to make this happen. This means changes changes to our leadership structure.\nAs node A.2 outlines, \u0026ldquo;Nueva Research Program\u0026rdquo; meetings have three stable positions.\nTeams’ Stable — Responsible for managing the count, content, and quality of active Research at Nueva projects, as well as the proces of matching team members to teams. (2-3 hrs/wk) Content Stable — Responsible for managing the content of the training program and review teams. Responsible for updating nodes. Runs meetings. (1-2 hrs/wk) Participant Stable — Responsible for managing the count and recruitment of new students into the program, and identifying key experts and mentors to help build new nodes or support the program. Responsible for participant sheet (1-2 hrs/wk) As well as three review teams\nHypothesis Sciences (key mentor: TBD) Non-Hypothesis Sciences (key mentor: Ted) Literacy, Soft Skills, and Development (key mentor: TBD) In a meeting (TBD) before 7/8, we will organize ourselves into three pairs again. Each pair will choose one \u0026ldquo;stable\u0026rdquo; role and one \u0026ldquo;review team\u0026rdquo; role\u0026mdash;essentially acting as a joint-power head for the new program and a review team in itself.\nWe will split our meetings from then on in half; the first bit dealing with R@N, which I will run; the second, ACTUALLY DOING Nueva Research Programs\u0026rsquo; work, lead by the \u0026ldquo;content stable\u0026rdquo; team. This also means that we will separate the two work docs.\nOh, yeah, also, if you have gotten this far; the headings of this document forms a pretty bad poem. Please send this poem to me privately on a direct message. Thank you.\nPresumably, much of the early \u0026ldquo;nueva research program\u0026rdquo; meetings will be solely the participant stable thinking about recruiting metrics and content stable voting on new nodes. That\u0026rsquo;s OK. The protocol\u0026rsquo;s there to be changed if needed.\nBut not without your consent Although we want each and every one of you on the team (evidenced by the fact that we will be pretty screwed if anyone leaves), your main academics comes first. Please talk to me privately if you have any concerns, no harm no foul.\nAlrighty. Let\u0026rsquo;s find a time to meet.\nhttps://www.when2meet.com/?15887080-XHXI8\nI kinda want to meet y\u0026rsquo;all physically over coffee if you want; but if not virtual is all good.\nThanks again for everything!\n\u0026mdash;Jack\n","permalink":"https://www.jemoka.com/posts/kbhresearch_at_nueva_notes_06_09_2022/","tags":null,"title":"Regarding R@N"},{"categories":null,"contents":"background info Recall asymtotic analysis. We remember that:\nconstant time \u0026lt; logarithmic time \u0026lt; linear time \u0026lt; polynomial time \u0026lt; exponential time The question? What happens if dynamic programming is too slow/not good enough for the problem? What if dynamic programming is not needed; instead, why don\u0026rsquo;t we just settle for a pretty good solution?\nTake, for instance, Nueva Courses. The optimal solution is \u0026ldquo;most students get their highest possible preferences.\u0026rdquo; However, this is impractical and pretty much impossible. Instead, what if we endeavor to figure a schedule that generally maximize happiness?\nrelaxation methods constraint relaxation constraint relaxation is a relaxation method to remove extra constraints.\nMotivating problem: traveling salesman problem\nVisit all towns in a given location Travel the minimal distance to do so Cannot visit any town more than once Calculating the basic, naive solution to find all roads is \\(O(n!)\\). Best known solution is \\(O(2^nn^2)\\), which is still slow. Its also an \\(NP\\) hard problem.\nHence, to actually solve it in a reasonable time, we are going to make two relaxations.\nThe salesmen can visit a town more than once The salesmen can teleport to visited towns By these two relations, we convert traveling salesmen to the minimum spanning tree problem.\nWe now (how?) that solving MST is no worse than optimal TSP. We will solve MST, then use that problem as the upper bound of solution to TSP.\ncontinuous relaxation continuous relaxation is a relaxation method to convert difficult discrete problems into continuous ones.\nMotivating problem: set cover\nYou are having a party, and you want your friends to get a nice paper invite.\nyou will send invitations to some subsets of your friends tell them to send invitations to all your mutual friends with them What\u0026rsquo;s the minimum number of friends to invite, and who?\nSet-cover is also hard, and also NP hard. The problem is that sending invitation is discrete.\nHence, to solve, we make it possible to solve for fractions of invitations. Hence, we can prove that our solution is guaranteed to be within bounds\nLagrangian relaxation Lagrangian relaxation is a relaxation method to convert hard-limit constrains into flexible penalization (negative values).\nMotivating problem: shortest paths problem with a constraint.\nYou need to drive the shortest number of miles as well as doing it in a hard constraint to complete the solution in a certain time.\nWe can instead relax the problem into overtime driving being a negative value in the solution.\n","permalink":"https://www.jemoka.com/posts/kbhrelaxation_algorithums/","tags":null,"title":"relaxation (algorithms)"},{"categories":null,"contents":"In this experiment, a model was devised, trained, and evaluated to automate psychotherapist/client text conversations through the use of state-of-the-art, Seq2Seq Transformer-based Natural Language Generation (NLG) systems. Through training the model upon a mix of the Cornell Movie Dialogue Corpus for language understanding and an open-source, anonymized, and public licensed psychotherapeutic dataset, the model achieved statistically significant performance in published, standardized qualitative benchmarks against human-written validation data - meeting or exceeding human-written responses\u0026rsquo; performance in 59.7% and 67.1% of the test set for two independent test methods respectively. Although the model cannot replace the work of psychotherapists entirely, its ability to synthesize human-appearing utterances for the majority of the test set serves as a promising step towards communizing and easing stigma at the psychotherapeutic point-of-care.\n","permalink":"https://www.jemoka.com/posts/kbhreplier_abstract/","tags":null,"title":"Replier Abstract"},{"categories":null,"contents":"I have done various published academic research projects in the fields of natural language processing and science education. Specifically, I have an interest in textual data mining, semantic analysis, L2 acquisition, and science education.\nComputational Linguistics ConDef/Dictembed Wikipedia is a surprisingly good dictionary, and so we can mine it for building context-aware dictionary. Repository, Paper.\nTitle: ConDef: Automated Context-Aware Lexicography Using Large Online Encyclopedias\nCollaborators: Zachary Sayyah - Nueva School\nStatus: Accepted for Oral Presentation and Publication\nVenue: SAI 2022 Computing Conference\nAbstract: ConDef Abstract\nReplier Using a logistic-increase mechanism to slowly blend data to fine-tune a transformer for psychotherapy. Repo, Link.\nTitle: Towards Automated Psychotherapy via Language ModelingTowards Automated Psychotherapy via Language Modeling\nCollaborators: solo project\nStatus: Pre-Print\nVenue: Cornell ArXiV\nAbstract: Replier Abstract\nGregarious Using BPE over a huge convolutional neural network with skip connections for highly-accurate identification of chat-bots on the internet. Repo, Link.\nTitle: Byte-Pair and N-Gram Convolutional Methods of Analysing Automatically Disseminated Content on Social Platforms\nCollaborators: solo project\nStatus: Pre-Print\nVenue: Open Science Foundation Preprints\nAbstract: Gregarious Abstract\nBRANDON/nsm Investigating into the Natural Semantic Metalanguage theory, and how we can use deep-learning methods to deal with prooving/disprooving the Lexicalist Hypothesis. Repo.\nCollaborators: Brandon Cho - Nueva School/Princeton\nWork-in-progress.\npolitisort Sorting and generating politically-motivated utterances. Repo.\nCollaborators: Zachary Sayyah - Nueva School\nWork-in-progress.\ndementia A task similar to ADReSS Challenge, training on acoustic and possibly linguistic features. internal link\nCollaborators: solo project\nPI: Prof. Brian Macwinney - CMU\nWork-in-progress.\nScience Education Project80 A student-driven podcast protocol which trains students to digest scientific research. Link, Internal Link.\nTitle: Project 80: a reproducible, student-driven framework for creating multimedia educational resources from primary literature\nCollaborators: Anoushka Krishnan, Micah Brown - Nueva School\nLab: Paul Hauser - Nueva School\nPI: Luke De - Nueva School\nStatus: Published\nVenue: EB2022/FASEB Journal\nAbstract: Project80 Abstract\nResearch@Nueva A student-lead, student-taught independent program that trains high-school students as researchers and facilitates publish-quality student research.\nCollaborators: Michael, Flint, Kian, Vinca, Oliver - Nueva School\nWork-in-progress.\nParallel Computing/Blockchain Coveather See also coveather. Link.\nTitle: Encrypted, Anonymized System for Protected Health Information Verification Built via Proof of Stake\nCollaborators: solo project\nStatus: Pre-Print and Oral Presentation at the California STEM Fair\nVenue: Cornell ArXiV\nAbstract: Coveather Abstract\n","permalink":"https://www.jemoka.com/posts/kbhresearch_index/","tags":["index"],"title":"Research Index"},{"categories":null,"contents":"A reticle is a photomask/template for a lithography system (like a negative). KLA was the first company to automatically inspect wafers and reticles.\n","permalink":"https://www.jemoka.com/posts/kbhreticle/","tags":null,"title":"reticle"},{"categories":null,"contents":"Richard Nixon is an American president, but pretty much is the watergate guy.\nServed in House and Senate Eisenhower\u0026rsquo;s VP for 8 years Lost first to JFK Richard Nixon is a pragmatist; he pushes economy out of presession via Keynsian Politics.\nRichard Nixon also realized that the large southern population can be motivated via racist policies, so he shifted the .\npolitical positions of Richard Nixon Richard Nixon\u0026rsquo;s Treatment against the Vietnam War Richard Nixon\u0026rsquo;s Foreign Policy ","permalink":"https://www.jemoka.com/posts/kbhrichard_nixon/","tags":null,"title":"Richard Nixon"},{"categories":null,"contents":"Richard Nixon\u0026rsquo;s foreign policy is marked by the \u0026ldquo;Nixon Doctrine\u0026rdquo;: shifting the burden of military containment to allies.\nSupports China as a means against USSR Negotiate with the USSR to lower tension Shifts focus into building and supporting allies ","permalink":"https://www.jemoka.com/posts/kbhrichard_nixon_s_foreign_policy/","tags":null,"title":"Richard Nixon's Foreign Policy"},{"categories":null,"contents":"Richard Nixon proposed the strategy of vietnamization as a treatment to the Vietnam War. He also expanded to Cambodia. To beat the Viet Cong into submission, he initialized the Operation Linebacker campaign.\n","permalink":"https://www.jemoka.com/posts/kbhrichard_nixon_s_treatment_against_the_vietnam_war/","tags":null,"title":"Richard Nixon's Treatment against the Vietnam War"},{"categories":null,"contents":"Rick Wallace is the CEO of KLA.\n","permalink":"https://www.jemoka.com/posts/kbhrick_wallace/","tags":null,"title":"Rick Wallace"},{"categories":null,"contents":"Ronald Reagan is a president of the United States. He rises a wave of the New Right.\nComes out of Hollywood and was CA governor Reagan was a democrat, but McCarthyism lead him Reagan was an FBI informer for McCarthyism investigations Reagan was the first two-term president since 1961, was able to maintain more power compared to others \u0026ldquo;The Great Communicator\u0026rdquo; Reagan politics \u0026ldquo;Government isn\u0026rsquo;t the solution to the problem, its the problem.\u0026rdquo;\nwished for limited politics states rights condemned welfare and \u0026ldquo;welfare cheats\u0026rdquo; (the undertone of racist appeal) Evangelical undertones, family values, moral majority Against affirmative action Supply-side economics: \u0026ldquo;getting rid of taxes will allow more people to spend\u0026rdquo; Anti-Soviet rhetoric Creates the largest increase in welfare spending, gutting about $1.5Bn.\nReagan policy changes Lowering taxes: 70% of tax to 28% of taxes Increase defense budget: 1 trillion to 3 trillion Rising inequality, 1% controlled 40% of wealth (double from the 1970s) Reagan Foreign Policy Ronald Reagan creates the largest military build-up in history (larger than Korea and Vietnam.)\nReasserted Command-in-Chief abilities Creates the National Security Council (for whom the ) Comitted the US to supporting the anti-Marxist insurrections around the world Credited with falling the USSR Supreme Court Interview Process A new interview process for the supreme court designed by Ronald Reagan, creating an extensive process to vet conservative. Reagan swapped out 50% of the Federal judicial process.\nReagan\u0026rsquo;s Legacy Inflation dropped\nUSSR Collapse\nMilitary complex expanded\nIncomes rose\nInequality widened\nWelfare slashed\nDebt\nConcentrated power in the white house\nCentralized conservative agenda\n","permalink":"https://www.jemoka.com/posts/kbhronald_raegan/","tags":null,"title":"Ronald Reagan"},{"categories":null,"contents":"The Rosa Parks bus incident is the instigator which needed to act on an issue to challenge the civil rights movement.\nShe participated in many civil rights agitations, and became the instigator .\n","permalink":"https://www.jemoka.com/posts/kbhrosa_parks/","tags":null,"title":"Rosa Parks"},{"categories":null,"contents":"total kinetic energy \\begin{equation} KE_{rigid} = \\frac{1}{2} M{V_{cm}}^2 + \\frac{1}{2} I_{CM}{\\omega_{CM}}^2 \\end{equation}\ntorque from gravity For even non rigid bodies, the following follows:\n\\begin{equation} \\vec{\\tau}_g = \\vec{R}_{CM} \\times M\\vec{g} \\end{equation}\nActually, this follows for any \\(f\\) (like \\(g\\)) evenly applied across point masses.\npotential energy \\begin{equation} \\Delta PE_g = mg\\Delta h \\end{equation}\nwhere, \\(\\Delta h\\) is the travel of center of mass. Regardless of whether or not its point.\n","permalink":"https://www.jemoka.com/posts/kbhrotational_energy/","tags":null,"title":"rotational energy theorem"},{"categories":null,"contents":"Rural Electrification Administration create electrification throughout cities. Most of American infrastructure still 1930s.\n","permalink":"https://www.jemoka.com/posts/kbhrural_electrification_administration/","tags":null,"title":"Rural Electrification Administration"},{"categories":null,"contents":"Observations from studying the comedian Russel Howard.\nStretching analogies Using language/motion/figure do describe something on the opposite end of the spectrum Take, for instance, age: 5Y/O: \u0026ldquo;cheers mum, wasen\u0026rsquo;t on my to-do list\u0026rdquo; A surprisingly sentimental dog: \u0026ldquo;because when I wake up tomorrow I want to see you, and I want to go for a lovely walk\u0026rdquo; Large motions + deadpan after Endless extrapolations of a normal setup: setup: Russian hackers were controlling people\u0026rsquo;s toys; punchline: \u0026ldquo;5 men were dildo\u0026rsquo;d to death, we don\u0026rsquo;t have a recording but here are their final words \u0026mdash; \u0026lsquo;oh yeaaah\u0026rsquo;, \u0026lsquo;oh fuck yeaaah\u0026rsquo;\u0026rdquo; Setup: gweneth paltro Punchline: \u0026ldquo;put an egg up there, you will feel more femenine. no! you will feel like a chicken\u0026rdquo;\nMultiple use of setups: \u0026ldquo;happy birthday too you\u0026rdquo; Peach ","permalink":"https://www.jemoka.com/posts/kbhrussel_howard/","tags":null,"title":"Russel Howard"},{"categories":null,"contents":"DOI: 10.3389/fcomp.2021.624594\nOne-Liner Using a genetic algorithm, picked features to optimize fore; achieved \\(94\\%\\) with just MMSE data alone. Developed ASR tool to aid.\nNovelty Developed an ASR methodology for speech, complete with punctuations Used a genetic algorithm to do feature selection; NNs performed worse because \u0026ldquo;space is smaller???\u0026rdquo; Notable Methods Used a GRU to insert punctuations The paper leveraged the nuke that is a bidirectional GRU, ATTENTION,\nKey Figs Fully automated ANN transcript does pretty well in terms of classifier AD/NL.\nNew Concepts fusion genetic algorithm MMSE Notes very confusing (too many things going on at once)\n","permalink":"https://www.jemoka.com/posts/kbhsadeghian_2021/","tags":["ntj"],"title":"Sadeghian 2021"},{"categories":null,"contents":"Demo day No value add for demo-day winner Competition makes you want to prepare more \u0026ldquo;this much budget for an enriching experience\u0026rdquo; Mentor Conversations None yet\nIntegration Integration into soundscape Hiring Need help designing a PCB\n","permalink":"https://www.jemoka.com/posts/kbhsalus_april_checkin/","tags":null,"title":"Salus April Checkin"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\n","permalink":"https://www.jemoka.com/search/","tags":null,"title":"Search Results"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhselective_service_system/","tags":null,"title":"Selective Service System"},{"categories":null,"contents":"In NSM, semantic primes are the most fundimental \u0026ldquo;lexical units\u0026rdquo; (so they can be words, or morphemes, etc. the size doesn\u0026rsquo;t matter) across languages.\nThey are the \u0026ldquo;core of a universal mental lexicon\u0026rdquo;.\nThere are\u0026hellip;\nguidelines for identifying semantic primes A semantic prime has to be found in every(ish?) natural language A semantic prime has to be indefinable by other primes proof for the existence of semantic primes Proof: given if the Strong Lexicalization Hypothesis holds, semantic primes must exist.\nAssume for the sake of contradiction no semantic primes exist.\nBecause Strong Lexicalization Hypothesis holds, there does not exist syntactic transformations which can take original single words and transform them into newly lexicalized words to express a different meaning.\nAt the same time, again because of the Strong Lexicalization Hypothesis, one must only leverage syntactic transformation on syntatic constituents when forming ideas.\nTherefore, given a word to lexicalize, it has to be defined by an syntatic transformation on a set of previously lexicalized words.\n(by definition) there are no words lexicalizable from the empty set of words.\nTherefore, there exists some word that needs to be lexicalized by words that are not previously defined, which is absurd. (instead, these words are lexicalized via semantic primes.)\nQED\nproblems with semantic primes the list has grown over time the problem of allolexy: formal restrictions of a language resulting in the same concept needing to be radicalized multiple times (I vs. me) finding semantic primes According to (Geeraerts 2009), (Goddard 2009) provides a \u0026ldquo;practical\u0026rdquo; (though flawed) way of establishing primes. Something to do with large-scale comparisons in \u0026ldquo;whole metalanguage studies\u0026rdquo;, which requires pairwise language comparison\nLocating primes are seen as an enforcement of NSM theories (Vanhatalo, Tissari, and Idström, n.d.). Recent prime locations: in Amharic (Amberber 2008), East Cree (Junker 2008), French (Peeters 1994), Japanese (Onishi 1994), Korean (Yoon 2008), Lao (Enfield 2002), Mandarin (Chappell 2002), Mangaaba-Mbula (Bugenhagen 2002), Malay (Goddard 2002), Polish (Wierzbicka 2002), Russian (Gladkova 2010, for the latest set, see the NSM home page), Spanish (Travis 2002), and Thai (Diller 1994).\n","permalink":"https://www.jemoka.com/posts/kbhsemantic_primes/","tags":null,"title":"semantic prime"},{"categories":null,"contents":"SVF is a standardized Discourse-Completion Task for verbal recall and fluency. It is administered by asking the participant to recall a bunch of words from within a category within 60 seconds.\n","permalink":"https://www.jemoka.com/posts/kbhsemantic_verbal_fluency/","tags":null,"title":"Semantic Verbal Fluency"},{"categories":null,"contents":"The semiconductor industry is a growing industry, the beginning of the semiconductor industry was actually in the silicon valley.\nWe are now taking a look at a reticle.\nalgorithms used in the semiconductor industry Per KLA \u0026mdash;\nClassification Random forest Boosted decision trees MLPs CNNs Reference generation GANs (WAT) VAEs Natural Grouping and Clustering auto-encoders manual feature extractors ","permalink":"https://www.jemoka.com/posts/kbhsemiconductor/","tags":null,"title":"semiconductor"},{"categories":null,"contents":"A set is an unordered collection of objects, which maybe infinitely long. It is generated with \\(\\{, \\}\\). For instance, most numbers are sets.\nconstituents a collection of objects requirements repetition does not matter order does not matter additional information ","permalink":"https://www.jemoka.com/posts/kbhset/","tags":null,"title":"set"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhsets/","tags":null,"title":"sets"},{"categories":null,"contents":"DOI: 10.3389/fcomp.2021.624659\nOne-Liner Multi-feature late fusion of NLP results (by normalizing text and n-gram processing) with OpenSMILE embedding results.\nNovelty NLP transcript normalization (see methods) and OpenSMILE; otherwise similar to Martinc 2021. Same gist but different data-prep.\nNotable Methods N-gram processed the input features Used WordNet to replace words with roots Key Figs New Concepts OpenSMILE ","permalink":"https://www.jemoka.com/posts/kbhshah_2021/","tags":["ntj"],"title":"Shah 2021"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhsingle_party_control/","tags":null,"title":"single party control"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhslopes/","tags":null,"title":"slope (statistics)"},{"categories":null,"contents":"Social Security Administration is a welfare program to directly give cash to those who are in need.\n","permalink":"https://www.jemoka.com/posts/kbhsocial_security_administration/","tags":null,"title":"Social Security Administration"},{"categories":null,"contents":"Here\u0026rsquo;s a bit of a guide to start in software development. It is mostly links to other resources that would help.\nIntroductory Remarks Nobody \u0026ldquo;learns\u0026rdquo; software development. Even in job interviews, people expect you to have \u0026ldquo;worked\u0026rdquo; in software development. The industry, as a whole, drives via \u0026ldquo;learn-by-doing\u0026rdquo;, so its best to start thinking about what you want to achieve with software dev in terms of projects, then look specifically for resources to help you achieve those. Once you Google enough, et viola! You will have the skills needed to tackle another project.\nCommon Tooling There are some common tooling that is standard across all of software development.\nGoogle Google it! 99.98% of programming skills center around google-fu. Learn to Google unknown terms and get a better sense of the picture. The same rule applies through this guide as well.\nStackExchange A group of very mean people put together a very helpful family of websites which are essentially vicious forum boards. They are the StackExchange family of boards.\nThe most famous of which, and the one focused on programming, is called StackOverflow. StackOverflow (\u0026ldquo;SO\u0026rdquo;) is an extremely helpful resource for browsing any question you may have. For instance, if your code crashes with a stack trace, Googling the error and set site:stackoverflow.com will get you pretty far.\nIf you ask a question, though, be prepared to get yelled at though, the likely reason is that your question is already answered.\nmacOS Get a macBook. Even the cheapest one.\nDevelopment on Windows is like cooking on campfire. Doable, useful for specific things, but not great overall. If you must use a PC, put Debian/Ubuntu/some easy to use Linux on it. Windows is just terrible.\nI should add that Microsoft started doing Windows Subsystem for Linux: https://docs.microsoft.com/en-us/windows/wsl/install, which apparently have been pretty good. So worth taking a shot if you are stuck on Windows.\n*nix Terminal BSD/UNIX terminal is a tool that essentially skips the fancy user interface (UI) which your operating system draws and directly runs things \u0026ldquo;organically.\u0026rdquo; If you see something in a guide that says like:\n\u0026ldquo;please execute\u0026rdquo;\npython3 test.py or perhaps\nwget https://wandb.ai/jemoka \u0026gt;\u0026gt; test they are probably asking you to type it (\u0026ldquo;execute it\u0026rdquo;) into the Terminal and hit enter.\nRead this guide put together by the Ubuntu people, it\u0026rsquo;s very good. To open the terminal on your macOS device, open an app called Terminal.app. On Ubuntu, I believe its also an app called terminal.\nIDE An \u0026ldquo;IDE\u0026rdquo; is an Integrated Development Environment. It is where code is written. Fortunately, this is an easy one: use VSCode. There is literally no better tool out there for beginners and advanced users; no wonder it has 70% market share.\nSidenote: But Jack? What do you use? I use something called emacs for very specific reasons. Please don\u0026rsquo;t unless you really want misery and to learn a whole language to configure it.\nComputer Language Architecture This is how an idea turns into \u0026ldquo;stuff\u0026rdquo; on your screen.\nHuman programming languages (\u0026ldquo;Python\u0026rdquo;), are a very readable sort of code. No computers can actually read it. Usually, code you write goes through a three-step process before its able to be ran.\nFirst, the language you write gets converted by a \u0026ldquo;compiler\u0026rdquo; or \u0026ldquo;interpreter\u0026rdquo;, specialized pieces of code that takes human programming languages into a more machine-readable form of code named \u0026ldquo;assembly\u0026rdquo; or \u0026ldquo;byte code\u0026rdquo; respectively, called the \u0026ldquo;intermediate\u0026rdquo;.\nFor now, think of the difference between compilers and interpreters as translating code either all-at-once (compilers) or line-by-line (interpreters). Because the former has a grander view of the whole, languages that use a compiler (\u0026ldquo;compiled languages\u0026rdquo;) are faster. Although, many programmers find languages that use in interpreter (\u0026ldquo;interpreted language\u0026rdquo;) easier because they can spot problems line by line.\nBut wait! There\u0026rsquo;s more. Assembly and byte-code (what compilers and interpreters generate) are not actually runnable by a computer. Yet another piece of software called a \u0026ldquo;runtime\u0026rdquo; takes the reasonably-machine-readable code and actually performs the required operations.\nSome runtimes for languages like C++ uses the raw x86 CPU, which is the stereotypical \u0026ldquo;binary\u0026rdquo; zeros-and-ones. Some other languages, say Java, uses horribly complex runtimes that amounts to a whole virtual machine.\nHere\u0026rsquo;s a bit of a table.\nLanguage C/I Compiler/Interpreter Intermediate Runtime Python I python python bytecode python Java C javac java object java VM JavaScript I V8 (literally) js bytecode web browser! C/C++ C gcc/clang x86 asm x86 cpu Wonder what the runtimes for languages like Java are built in? C/C++. Eventually it all becomes x86 cpu instructions but its like a layer cake. This is why Python and friends are called a \u0026ldquo;higher level language\u0026rdquo;.\ngit Git is where all the code is!\nGit is a decentralized \u0026ldquo;version-control\u0026rdquo; system. It is basically a timestamp-backup system of code with messages and branching.\nGitHub is a website where people like to back up their code. Here\u0026rsquo;s my profile on GitHub.\nManaging Git is pretty\u0026hellip; Involved. It, for instance, assumes familiarity with the Terminal as described above. I suggest learning it, though: learn git and learn GitHub.\nIndustry-Specific Skills What you start with doesn\u0026rsquo;t matter, but start with something Its easiest to learn programming if you have a project in mind. So, find a project in mind\u0026mdash;what it is, though, doesn\u0026rsquo;t matter. The concepts across programming are highly transferable, but the actual skill is easiest to learn if you are learning w.r.t. a project.\nData science, prototyping, and machine learning Python would be your friend for all things of programming where the act of programming is a means to an end. That is: if you are writing code to do something that\u0026rsquo;s not inherently software (data science, machine learning, heck, also manipulating quantum qubits), Python is your friend.\nIts a language that\u0026rsquo;s designed to be easy to write: is a very do-as-I-say language that sacrifices efficiency and elegance for getting crap done. This is how I started programming. This is the book I started with. It teaches Python through programming a series of small projects that are mostly Terminal games.\nTo learn data science, Nueva\u0026rsquo;s very own data science course give very good conceptual framework. A typical first project is to recognize pictures of handwritten digits, for which there is a good guide. I also started something called AIBridge with AIFS, so if we ever publish the recordings I will put them here.\nGoogle also: pip, ipython, Jupyter.\nBackend engineering Backend engineering is the science of dealing with databases and writing API (application programming interfaces). I don\u0026rsquo;t suggest starting with this, but if you are particularly interested in databases, you could!\nTo master backend engineering, first learn a database manipulation language. For 99.98% of the industry, this means mysql. The link directs to a pretty good guide.\nFurthermore, the language with which backend is written is Java. I hate to say it, but despite Java\u0026rsquo;s terribleness (don\u0026rsquo;t worry about it ;)) its very dependable. Here\u0026rsquo;s a book on Java. In general, I really like all of the books from no starch press.\nFrontend and Web engineering Do you like making stuff move? Do you like drawing buttons? Front end maybe for you. The most basic type of front-end engineering is making websites.\nStart by making a \u0026ldquo;vanilla website\u0026rdquo;: HTML (what\u0026rsquo;s on the page), CSS (what colours and sizes), JavaScript (how it moves) is the standard trio of languages to start. freeCodeCamp (a great Medium blog, check their stuff out) has a good guide on the matter.\nHowever, as you progress in your journey, you will find these tools woefully inadequate. Hence, most people writing web front end move on to something called a \u0026ldquo;JavaScript Framework\u0026rdquo;, a tool to generate a \u0026ldquo;vanilla\u0026rdquo; website from some more easily manipulable JS (changing the text on the page moves from a four line operation (indexing, selecting, grabbing, changing) to a one-liner (state.text=new text)).\nA popular JS framework is ReactJS. Check them out.\nFullstack Engineering Frontend + Backend.\nGame development Game development is honestly one of the most horribly complicated and richly science-y part of CS. I am not super experience in game development but learning C++ and mastering Unity, the game engine. Oh, right, game dev is the only, and I repeat only (with invisible footnotes and qualifications) reason why you should be writing code on Windows.\nA friend is good at game dev, I can make an intro if needed.\nGood Luck! Remember: Google-fu and project-based curiosity is your friend. Let me know if you have questions.\n","permalink":"https://www.jemoka.com/posts/kbhsoftware_dev_starter_pack/","tags":null,"title":"software dev starter pack"},{"categories":null,"contents":" \u0026ldquo;laws.als\u0026rdquo;: \u0026ldquo;drumuomup\u0026rdquo; \u0026ldquo;ping.als\u0026rdquo;: \u0026ldquo;walking down the street, eating children\u0026rdquo;\u0026quot;\u0026quot; \u0026ldquo;planets.als\u0026rdquo;: \u0026ldquo;sing a song among the starlight\u0026rdquo; \u0026ldquo;songs.als\u0026rdquo;: \u0026ldquo;thank you klint for your discussion\u0026rdquo; Other things I have to finish \u0026ldquo;Tunel2.als\u0026rdquo; ","permalink":"https://www.jemoka.com/posts/kbhsongs_that_need_lyrics/","tags":null,"title":"Songs that need Lyrics"},{"categories":null,"contents":"Reading notes Because feeling for self-endowment, they wish to build socialist society As Communists considered themselves as a vanguard of the revolutionary proletariat – their “aim” was to build socialist society in the whole world.\nSocialist had necesity against capitalist aggression The Soviet approaches towards historical descriptions of the twentieth century showed that with the emergence of the new type of state – socialist one – it became a target for capitalist aggression.\nSocialist revolution requires the creation of socialist society against the world It was first positive move towards realization of the Soviet foreign policy main idea: the world socialist revolution and creation of the socialist society in the whole world.\nThe Soviets believe that the US wants to take over world The US had plans to dominate in the entire world.\nThat the US was intentionally sturggling with socialism All US post-war foreign policy doctrines were aimed on the struggle with socialism\nthat soviets believed that US was exclusivly fighting socialism We can summarize – that on Soviet point of view all American presidents of Cold War period were creating their own doctrines, and all of them were anti-communist and anti-Soviet\nSoviets believes that the US made the first move Soviet concept first vivid steps, which signalized about the start of the confrontation between East and West, were steps made by the West.\nbelieves its a fight against imperialism bipolar confrontation had western roots and the Cold War was the policy of the US and other imperialistic countries against socialist countries.\ncommunism is working towards revolution mankind is a process of revolutionary changes\nthe soviet union believes only it can stop American aggression the Soviet Union was the only power in the world able to stop American ambitions of superpower.\nUSSR believes that itself was the only defender The Soviet Union considered itself as the only defender of the interests of the working class all over the world because it was the first socialist state in history.\nDefinding US and defending imperialism The Imperialistic was the system of capitalist countries: they had a lot of contradictions in their “camp” where each wanted to solve their problems and to defend their own interests by using the others.\nBlack and white view of the world prevailed USSR The entire world was separated into two main categories: friends and enemies. Such black and white world-view was a distinctive feature of Stalin’s way of seeing the world (outside as well as inside the USSR), but even after his death,\n","permalink":"https://www.jemoka.com/posts/kbhsoviet_perspective_on_cold_war/","tags":null,"title":"Soviet Perspective on Cold War"},{"categories":null,"contents":"A spinal tap is a medical procedure whereby cerebralspinal fluid is collected by puncturing the lumbar; used to diagnose problems where biomakers from the brain are needed.\n","permalink":"https://www.jemoka.com/posts/kbhspinal_tap/","tags":null,"title":"spinal tap"},{"categories":null,"contents":"A stack trace is the output of failing code by the runtime to indicate the location of the fault. For instance, in Python:\n--------------------------------------------------------------------------- TypeError Traceback (most recent call last) \u0026lt;ipython-input-1-0b766d7d4bc7\u0026gt; in \u0026lt;module\u0026gt; ----\u0026gt; 1 0+\u0026#34;\u0026#34; TypeError: unsupported operand type(s) for +: \u0026#39;int\u0026#39; and \u0026#39;str\u0026#39; ","permalink":"https://www.jemoka.com/posts/kbhstack_trace/","tags":null,"title":"stack trace"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhstandard_error/","tags":null,"title":"standard error"},{"categories":null,"contents":"Everyone and their dog has a blog at this point. Why not me? You see, I don\u0026rsquo;t really like the idea of blogging, but I do enjoy taking notes. I take a crap tonnes of notes, and sometimes people want to see a copy of them.\nIn order to facilitate this, some friends and I created taproot, a collective note-taking effort which also automatically compiled pretty cool previews and an internet site. I still am one of the primary maintainers of taproot.\nWhile working on the project, however, we noticed that the loop-based architecture (instead of being based on events/triggers), lack of duplicity, and requirement of a central build server made it difficult.\nIn this vein, quantumish (also with his own lovely set of notes, tap on the link!) and I were discussing if the essentials of taproot can be built into a static site generator. Hence, this is an experiment (to hopefully be merged with the taproot group) to facilitate this.\n","permalink":"https://www.jemoka.com/posts/kbhstarting_with_why_the_knowledgebase/","tags":null,"title":"Starting With Why: The Knowledgebase"},{"categories":null,"contents":"A statistic is a measure of something\n","permalink":"https://www.jemoka.com/posts/kbhstastistic/","tags":null,"title":"statistic"},{"categories":null,"contents":"Reading Notes Strong Free Will vs. Weak Free Will \u0026mdash; \u0026ldquo;will\u0026rdquo; and \u0026ldquo;bells inequality\u0026rdquo; is a demonstration of indeterminism/randomness between particles \u0026mdash; but indeterminism and randomness a demonstration of will.\nThat if humans have free will, it should be spawened from the indeterminism of elementary particles It asserts, roughly, that if indeed we humans have free will, then elementary particles already have their own small share of this valuable commodity.\nSPIN Axiom SPIN Axiom: Measurements of the squared (components of) spin of a spin 1 particle in three orthogonal directions always give the answers 1, 0, 1 in some order.\nTWIN Axiom Paired particles will come up with same measurements if measured in the same way\nThe TWIN Axiom: For twinned spin 1 particles, suppose experimenter A performs a triple experiment of measuring the squared spin component of particle a in three orthogonal directions x, y, z, while experimenter B measures the twinned par- ticle b in one direction, w . Then if w happens to be in the same direction as one of x, y, z, experimenter B’s measurement will necessarily yield the same answer as the corresponding measurement by A.\nFree as something that cannot be an uncurried function of previous states To say that A’s choice of x, y, z is free means more precisely that it is not determined by (i.e., is not a function of) what has happened at earlier times (in any inertial frame).\nMIN Axiom Choice of direction of measurement of one twinned qubit does not influence the results of the current qubit (unless they happen to align.)\nThe MIN Axiom: Assume that the experiments performed by A and B are space-like separated. Then experimenter B can freely choose any one of the 33 particular directions w , and a’s response is independent of this choice. Similarly and inde- pendently, A can freely choose any one of the 40 triples x, y, z, and b’s response is independent of that choice.\n","permalink":"https://www.jemoka.com/posts/kbhstrong_free_will/","tags":null,"title":"Strong Free Will"},{"categories":null,"contents":"confidence intervals, a review:\n\\begin{equation} statistic \\pm z^*\\sigma_{statistic} \\end{equation}\nFrequently, we don\u0026rsquo;t have access to \\(\\sigma\\) and hence have to guestimate. When we have a sample means and a proportion, we have ways of guestimating it from the standard error (available on the single-sample section of the AP Statistics formula sheet.)\nHowever, for means, the standard error involves! \\(\\sigma\\). How do we figure \\(\\sigma\\) when we don\u0026rsquo;t know it? We could use \\(s\\), sample standard deviation, but then we have to adjust \\(z^*\\) otherwise we will have underestimation. Hence, we have to use a statistic called \\(t^*\\).\nWe can use t-values to perform t-test, a hypothesis test of means.\n","permalink":"https://www.jemoka.com/posts/kbht_statistics/","tags":null,"title":"t-statistics"},{"categories":null,"contents":"A t-test is a hypothesis test for statistical significance between two sample means based on t-statistics. Before it can be conducted, it must meet the conditions for inference.\nconditions for inference (t-test) To use t-statistics, you have to meet three conditions just like the conditions for inference used in z-score.\nrandom sampling normal (sample size larger than 30, or if original distribution is confirmed as roughly symmetric about the mean) Independence use a z-statistic to find a p-value Begin by finding a \\(t\\) statistic. Remember that:\n\\begin{equation} t = \\frac{statistic-parameter}{std\\ err} \\end{equation}\nIn this case, when we are dealing with sample means, then, we have:\n\\begin{equation} t = \\frac{\\bar{x}-\\mu_0}{\\frac{S_x}{\\sqrt{n}}} \\end{equation}\nwhere \\(\\bar{x}\\) is the measured mean, \\(\\mu_0\\) is the null hypothesis mean, and \\(S_x\\) the sample\u0026rsquo;s sample standard deviation.\nQuick note:\n\\(SE = \\frac{S}{\\sqrt{n}}\\) because the central limit theorem states that sample means for their own distribution, whose variance equals the original variance divided by the sample size. Hence, the standard deviation of the means would be the sample standard deviation divided by the square root of the sample size.\nOnce you have a \\(t\\) value, you look at the test and what its asking (above the mean? below the mean? etc.) and add up the tail probabilities.\npaired vs two-sample tests A paired t-test looks at pairs of values as statistic in itself (i.e. substracts directly, etc.) Think about it as a compound statistic, so you are doing a \\(t\\) test on one value, it just happened to be composed/calculated by a pair of values. (for instance, \u0026ldquo;difference between mother-father glucose levels.\u0026rdquo;)\nA two-staple t-test looks at two independent events and compares them. Hence, they are two random variables and should be manipulated as such.\nt-tests for regression lines regression lines can be imbibed with predictive power and confidence intervals:\n\\begin{equation} m \\pm t^* SE_b \\end{equation}\nwhere \\(m\\) is the slope and \\(SE_b\\) is the standard error of the regression line.\nNote that the degrees of freedom used for \\(t^*\\) is the number of data points, minus two.\nconditions for inference (slops) Acronym: LINEAR\nLinear Independent (observations are independent or \\(\u0026lt;10\\%\\)) Normal (for a given \\(x\\), \\(y\\) is normally distributed) Equal variance (for any given \\(x\\), it should have a roughly equal standard deviation in \\(y\\)) Random ","permalink":"https://www.jemoka.com/posts/kbht_test/","tags":null,"title":"t-test"},{"categories":null,"contents":"Andrew\u0026rsquo;s Features Collapse two PAR tiers down Checkpoint per file One corpus prompt per run Handle empty tiers I/P selection crashes! contingency preview the LONGEST segment instead of the top one -i kill in the middle fixes \u0026ldquo;my mom\u0026rsquo;s cryin(g)\u0026rdquo; [\u0026lt;] mm [l648] (also themmm after) \u0026ldquo;made her a nice dress\u0026rdquo; [\u0026lt;] mhm [l1086] \u0026ldquo;when I was a kid I\u0026rdquo; \u0026amp;=laughs [l1278] Others chstring (for uh, mm-hmm)\nretrace (asr\u0026amp;fa folder)\nlowcase (caps)\nrep-join.cut (fixes/)\nnumbers \u0026lt;affirmative\u0026gt; \u0026lsquo;mo data! CallFriend/CallHome (ca-data) ISL? SBCSAE Aphasia + MICASE TBI data Providing a Two-Pass Solution Writing Big description of the pipeline Notion of the pipeline Better tokenization? 8/18 Initial segment repetition Extracting studdering Gramatically problematic mar mar has done a thing and its phoneme level We did it, now automated LEAP data next actions Aphasia (-apraxia?): classification Child data (EllisWeismer) Dementia a ~Multiple @Begin/CHECK problem~\n~Placement of @Options~\n~Strange, missing period~\n~Bracket comments should FOLLOW words instead of PRECEEDING them~\n~%xwor: line~\nSTICK TO DASHES WHEN DISTRIBUTING BATCHALIGN\nend the utterance when it ends (incl. inter-utterance pauses)\n\u0026ldquo;I\u0026rdquo; need to be capitalized\n11005 (LT)\nAlign EllisWeismer\nAlso cool to align:\nfluency IISRP/*\nhttps://en.wikipedia.org/wiki/Speaker_diarisation\nhttps://universaldependencies.org/\nAlzheimer\u0026rsquo;s Project https://dementia.talkbank.org/\nhttps://luzs.gitlab.io/adresso-2021/\nSpecifically: https://dementia.talkbank.org/access/English/Pitt.html\nReview Kathleen Fraser: https://drive.google.com/drive/u/1/folders/1lYTIzzXLXw3LlDG9ZQ7k4RayDiP6eLs1\nHere are the review papers: https://drive.google.com/drive/u/1/folders/1pokU75aKt6vNdeSMpc-HfN9fkLvRyutt\nRead this first: https://drive.google.com/drive/u/1/folders/0B3XZtiQwQW4XMnlFN0ZGUndUamM?resourcekey=0-AlOCZb4q9TyG4KpaMQpeoA\nSome PITT data have 3-4 recordings\nThe best way to diagnosing alzhimers\u0026rsquo; is from language.\nWhy this field is needed: to analyze a pre-post test metric.\nDesired output: existence of dementia (a.k.a alzheimer\u0026rsquo;s\u0026rsquo;).\nOther research to read:\nPenn (julia parish something but they don\u0026rsquo;t stare their data but they smile and things with Mark Libermann type of thing) Learning more about speech text https://my.clevelandclinic.org/health/diagnostics/22327-differential-diagnosis python3 ~/mfa_data/batchalign-dist/batchalign.py ~/mfa_data/my_corpus ~/mfa_data/my_corpus_aligned\nchristan marr paper on MFA on child data\n","permalink":"https://www.jemoka.com/posts/kbhtalkbank/","tags":null,"title":"talkbank"},{"categories":null,"contents":"Lit Survey Pipeline Segmentation ","permalink":"https://www.jemoka.com/posts/kbhtalkbank_pipeline_project/","tags":null,"title":"TalkBank Pipeline Project"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhtariffs/","tags":null,"title":"tariffs"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhteddy_roosevelt/","tags":null,"title":"Teddy Roosevelt"},{"categories":null,"contents":"Given what you claim as a normal distribution, we can test for its normality. Any distribution you claim as normal has to follow that:\n\\begin{equation} np \\geq 10 \u0026amp; n(1-p) \\geq 10 \\end{equation}\nthat number of successes and failures need both be greater than or equal to ten.\n","permalink":"https://www.jemoka.com/posts/kbhtest_for_normality/","tags":null,"title":"test for normality (statistics)"},{"categories":null,"contents":"The Unreasonable Effectiveness of Mathematics in the Natural Sciences is an article by the famous mathematician Eugene Wigner. (Wigner 1990)\nReflection What I found most peculiarly interesting is the focus on many mathematical/physics texts on the idea of the \u0026ldquo;beauty\u0026rdquo; of the expressions; and, it seems, the clear pleasure that Wigner gets from analyzing the systems with the aforementioned \u0026ldquo;beauty.\u0026rdquo;\nSetting aside whether or not this beauty is \u0026ldquo;deserved\u0026rdquo;/appropriate, I love that my attraction to physics is somewhat similar to what Wigner describes. Under the appropriate conditions, with constraints, it is possible to build a solution to physics problems simply through the evolution of mathematics.\nIt is not to say that the models mathematics provides is correct. I like that Winger ended on the note about how \u0026ldquo;false\u0026rdquo; theories, even despite their falseness, provided shockingly accurate estimations of physical phenomena. Perhaps mathematics provides an almost-fully solid foundation to creating physical systems, but then the entire \u0026ldquo;flaw\u0026rdquo; we see with mathematical modeling is in our (in)ability to provide the limitations to scope.\nFor instance, Bohr\u0026rsquo;s model, an example of \u0026ldquo;falsehood\u0026rdquo; modeled, is an over-limitation to scope which\u0026mdash;thought reducing mathematical complexity\u0026mdash;resulted in a \u0026ldquo;wrong\u0026rdquo; theory. However, the mathematics behind the theory remains to be solid despite the scope limitation, making the result work in a reasonable manner (except for the pitfalls).\nThe inherent concern behind this statement, then, is that there is a case where we can build a perfectly reasonable system to model something, but it turns out that the system is correct only in the limited scope which we are used to operating; when suddenly the scope becomes broken, we are so used to the mathematical tools that we have came to rely on that we don\u0026rsquo;t notice their failures.\nI like that this entire point is brought up before our start in DiffEq, perhaps as a \u0026ldquo;with great power comes great responsibility\u0026rdquo; type of caution to us in terms of how our modeling may go awry while at the same time acting as a preview of the usefulness of the principles provided taken as a whole.\nReading notes Maths show up at entirely random places The first point is that mathematical concepts turn up in entirely unexpected connections. Moreover, they often permit an unexpectedly close and accurate description of the phenomena in these connections.\nWondering whether or not the theory is unique due to its applicability He became skeptical concerning the uniqueness of the coordination between keys and doors.\nThat math is really useful, its weird The first point is that the enormous usefulness of mathematics in the natural sciences is something bordering on the mysterious and that there is no rational explanation for it.\nIt also raises the question of how actually unique our theories are given they are all so applicable Second, it is just this uncanny usefulness of mathematical concepts that raises the question of the uniqueness of our physical theories.\nThe goal of mathematics is maximize the space of usefulness The great mathematician fully, almost ruthlessly, exploits the domain of permissible reasoning and skirts the impermissible.\nRegularity is suprising because its\u0026hellip; regularly found, which is unique The second surprising feature is that the regularity which we are discussing is independent of so many conditions which could have an effect on it.\nLaws of Nature are all highly conditional The principal purpose of the preceding discussion is to point out that the laws of nature are all conditional statements and they relate only to a very small part of our knowledge of the world.\nThat maths is just a fallback for \u0026ldquo;beatiful\u0026rdquo; physics happening the connection is that discussed in mathematics simply because he does not know of any other similar connection.\nApart from invarients, we just scope-limit ourselves to get the remaining bits that we need to make stuff work \u0026ldquo;beautifully\u0026rdquo; propose to refer to the observation which these examples illustrate as the empirical law of epistemology. Together with the laws of invariance of physical theories, it is an indispensable foundation of these theories.\n","permalink":"https://www.jemoka.com/posts/kbhthe_unreasonable_effectiveness_of_mathematics_in_the_natural_sciences/","tags":null,"title":"The Unreasonable Effectiveness of Mathematics in the Natural Sciences"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhtherma/","tags":null,"title":"therma"},{"categories":null,"contents":"The theta/alpha ratio is the ratio between two oscillations measurable by an EEG that is shown to be a possible indicator for AD development.\n","permalink":"https://www.jemoka.com/posts/kbhtheta_alpha_ratio/","tags":null,"title":"theta/alpha ratio"},{"categories":null,"contents":"the transformational generative syntax is a linguistical precept proposed by Noam Chomsky which has the interesting conclusion that meaning is supported by structure, rather than the other way around as generative semantics suggests.\nThis means that you can first come up with generic, independent structure to a sentence, then fill in the sentence with meaning.\nFor instance, \u0026ldquo;colorless green ideas sleep furiously\u0026rdquo; is a sentence Noam Chomsky proposes to have perfect structure but failes to be filled with meaning, supporting the transformational generative syntax theory.\nThis supports the Lexicalist Hypothesis, which is the theory that lexicalization transformations are independent of structural transformations. This would therefore support the proof for the existence of semantic primes.\n","permalink":"https://www.jemoka.com/posts/kbhtransformational_generative_syntax/","tags":null,"title":"transformational generative syntax"},{"categories":null,"contents":"Tuning Forks (funing torks!) is a Tuning Fork. You smack it and it goes \u0026ldquo;biiing!\u0026rdquo;\nLet\u0026rsquo;s figure out how it works. For us to be one same page, let\u0026rsquo;s define some vocab:\nVocab \u0026ldquo;Tine\u0026rdquo;: one of the two prongs of the fork A Cursory Explanation Source: here and here. Both are not very scientific but a good first step.\nFrom a very basic perspective, hiting a tuning fork creates a transverse wave on the tine you hit, which vibrates and then compresses the air around it in a longitudinal fashion at a set frequency, which we hear as a sound.\nOk but then this raises the question of why there\u0026rsquo;s two tines. The explanation this website gives is essentially that the actual mechanism of the Tuning Fork is in squishing the air immediately around the fork, so\u0026hellip;\nif the tines are push towards together, it creates a void in the space it just was; this creates a low pressure rarefaction area if the tines snap back apart, it compresses the air creating compression by squishing the air around it And therefore, the air around the funing tork is essentially being played like a two-way slingy. To adjust the pitch of the Tuning Fork, you lengthen or shorten it: longer tuning forks have larger tines, which vibrate more slowly.\nOk but now many, many questions why does smacking one side of the Tuning Fork make both sides vibrate presumably the base is not vibrating; hence, how does the downward-bendy vibration cause perpendicular oscillation (does it?) A Detour on Rigid Body Harmonic Motion Ok we can probably\nA Detour on the Temperature We are really worried about two different things here.\nMetal expands/contracts based on the temperature Temperature affects speed of sound A Detour on Material Science Why are our Tuning Forks out of tune? Fun, Relevant Factoids About the World The range of human hearing from a youngen is about 20Hz to 20,000Hz. ","permalink":"https://www.jemoka.com/posts/kbhtuning_forks/","tags":null,"title":"Tuning Fork"},{"categories":null,"contents":"A constructor built out of quantum theory which can replicate itself. It is considered a universal computer.\n","permalink":"https://www.jemoka.com/posts/kbhuniversal_quantum_constructor/","tags":null,"title":"universal quantum constructor"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhuniversity_of_georgia/","tags":null,"title":"University of Georgia"},{"categories":null,"contents":" Investment: Paid for 50% of war bonds Production: ships, tanks, airplanes, etc. \u0026mdash; encourages production Conservation: 5% of the world\u0026rsquo;s population production, 50% of the world\u0026rsquo;s manufactured goods \u0026mdash; rationing, grow goods, etc. ","permalink":"https://www.jemoka.com/posts/kbhus_wwii_propaganda/","tags":null,"title":"US WWII Propaganda"},{"categories":null,"contents":"Goal: understand the user.\nFind out\u0026hellip;\nMotivation Context Deeper need? The goal of user interviews is to understand the user even if they know what they want!\nGood User Interviews Make person feel welcome/safe/appreciated\nAsk open-ended \u0026ldquo;questions\u0026rdquo;\nDescribe a time that\u0026hellip; Tell me more about.. Leave space: awkward silences (not too awkward)\nReally listen!; repress the urge to think of what you want to say next\nRepeat statements back to people\nAsk about examples, context, etc.\nA roadmap 1: create a comfortable entry point 2: go wide, deep into more personal and complex questions 3: focus on the problem, not the solution 4: focus on feelings\u0026mdash;feelings matter, how nice matters 5: end with conclusions and statements for what you User Story A context A motivation A need ","permalink":"https://www.jemoka.com/posts/kbhuser_interviews/","tags":null,"title":"User Interviews"},{"categories":null,"contents":" Secrets of Silicon Valley - Horowitz Looking for people who have feel for the problem: people need to believe in the problem Team: can people come with execution? people that are good at startups which are usually not good at later stage stuff Buy a startup and kick out the founders This is very typical Team and idea are easy to decouple Vetting problems Lack of market Technically insatiability \u0026ldquo;Unbelievable stupidity\u0026rdquo;: calcium is so cheap Idea goes through many morphs; getting the credit back People wiling to have a meeting? Decoupling value proposition =\u0026gt; iStudio as a service\nRandom Need: Nueva Alumni Network Maybe set up a Nueva alumni network? What could we do to facilitate the Nueva alumni network; extraction of mutual value from the next work.\nNueva alumni as a service.\nInnovation consultants Ideas are no longer valuable, which ideas to peruse is better. \u0026ldquo;helping people along in their relationship with the idea or with each other.\u0026rdquo; Decoupling solution with the customer with the most value.\n","permalink":"https://www.jemoka.com/posts/kbhvc_thing/","tags":null,"title":"vc thing"},{"categories":null,"contents":"Bad statement: a vector is an object with a direction and a magnitude.\nwhy our understanding of vectors is bad \u0026hellip;this is an Algebra: so its a study of symbols.\n","permalink":"https://www.jemoka.com/posts/kbhvector/","tags":null,"title":"vector"},{"categories":null,"contents":"this is worse ","permalink":"https://www.jemoka.com/posts/kbhcraintech/","tags":null,"title":"VFUA"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhvgg/","tags":null,"title":"VGG"},{"categories":null,"contents":"VGGish is VGG, ish. VGGish is a network based on VGG which is pretrained on the audio-feature-extraction task.\n","permalink":"https://www.jemoka.com/posts/kbhvggish/","tags":null,"title":"VGGish"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhvietnam/","tags":null,"title":"Vietnam"},{"categories":null,"contents":"vietnamization is a political position held by Richard Nixon which is characterized by the slow replacement of American troops with Vietnamese ones.\n","permalink":"https://www.jemoka.com/posts/kbhvietnamization/","tags":null,"title":"vietnamization"},{"categories":null,"contents":"DOI: 10.21437/Interspeech.2019-2414\n","permalink":"https://www.jemoka.com/posts/kbhwang_2019/","tags":null,"title":"Wang 2019"},{"categories":null,"contents":"Richard Nixon does not like democratic policies. Therefore, he had 5 operatives break into the DNC. Woodward and Berstein reports on the issue. Nixon rebounds and fires his investigator.\nThen, he released the \u0026ldquo;smoking gun\u0026rdquo; tape with the middle missing\n","permalink":"https://www.jemoka.com/posts/kbhwatergate/","tags":null,"title":"watergate"},{"categories":null,"contents":"A study with the goal of identifying semantic primes.\n","permalink":"https://www.jemoka.com/posts/kbhwhole_metalanguage_study/","tags":null,"title":"whole metalanguage study"},{"categories":null,"contents":"WPA is the largest relief program ever in the Great Depression New Deal, to promote public infrastructure and create artistic murals. It helped unskilled men to carry out public works infrastructure.\nThe project started 5/1935 and dissolved 6/1943.\n","permalink":"https://www.jemoka.com/posts/kbhwpa/","tags":null,"title":"Works Progress Administration"},{"categories":null,"contents":"","permalink":"https://www.jemoka.com/posts/kbhwriting_index/","tags":null,"title":"Writing Index"},{"categories":null,"contents":"DOI: 10.3389/fcomp.2020.624488\nOne-Liner Used an ERNIE trained on transcripts for classification; inclusion of pause encoding made results better.\nNovelty Instead of just looking at actual speech content, look at pauses specific as a feature engineering task \\(89.6\\%\\) on the ADReSS Challenge dataset Notable Methods Applied FA with pause encoding with standard .cha semantics (short pauses, medium pauses, long pauses). Shoved all of this into an ERNIE.\nAssay for performance was LOO\nKey Figs Fig 1 This figure motivates the point that subjects with AD says oh and um more often; which prompted Table 1\nTable 1 Subjects with AD says uh a lot more often; no significance level calculations but ok.\nFigure 5 This figure is the result of a LOO study on the proposed model and presumably others before. X axis is the validation accuracy in question, Y is the density by which the score in X appears in an \\(N=35\\) LOO measurement.\nThis figure tells us that either way the ERNIE model is better than state of the art; furthermore, transcripts with pause encoding did better and did it better more of the time; that\u0026rsquo;s where the 89.6% came from.\nNew Concepts Leave-One-Out cross validation Notes Glorious.\n","permalink":"https://www.jemoka.com/posts/kbhyuan_2021/","tags":["ntj"],"title":"Yuan 2021"},{"categories":null,"contents":"A z-test is a hypothesis test for statistical significance between two sample proportions. Before it can be conducted, it must meet the conditions for inference for a z-test.\nconditions for inference (z-test) has to be random has to be reasonably normal (vis a vi test for normality) each sample has to be independent (or 10% rule) use a z-statistic to find p-value Given a sample proportion, calculate the sample proportion standard deviation (given on the formula sheet) Then, divide the difference between measured and null proportions to figure \\(z\\) that is,\n\\begin{equation} z = \\frac{\\hat{p}-p_0}{\\sqrt{\\frac{p_0(1-p_0)}{n}}} \\end{equation}\nLook up the probability of \\(z\\) taking place on a \\(z\\) table. Then, \\(1-z\\) would yield the \\(p\\) vaule.\n","permalink":"https://www.jemoka.com/posts/kbhz_test/","tags":null,"title":"z-test"},{"categories":null,"contents":"\\(0\\) is a list of length \\(n\\) whose coordinates are all zero\nFormally\u0026mdash;\n\\begin{equation} 0 = (0,\\ldots,0) \\end{equation}\n","permalink":"https://www.jemoka.com/posts/kbhzero/","tags":null,"title":"zero"},{"categories":null,"contents":"A zettlekasten is an atomic notetaking system.\n","permalink":"https://www.jemoka.com/posts/kbhzettlekasten/","tags":null,"title":"zettlekasten"},{"categories":null,"contents":"a zettlekasten index is an index in a zettlekasten file format; it keeps track of all lists of notes. Head to Index Index for an index of indexes in this particular zettlekasten.\n","permalink":"https://www.jemoka.com/posts/kbhzettlekasten_index/","tags":null,"title":"zettlekasten index"},{"categories":null,"contents":"DOI: 10.3389/fcomp.2021.624683\nOne-Liner late fusion of multimodal signal on the CTP task using transformers, mobilnet, yamnet, and mockingjay\nNovelty Similar to Martinc 2021 and Shah 2021 but actually used the the current Neural-Network state of the art Used late fusion again after the base model training Proposed that inconsistency in the diagnoses of MMSE scores could be a great contributing factor to multi-task learning performance hindrance Notable Methods Proposed base model for transfer learning from text based on MobileNet (image), YAMNet (audio), Mockingjay (speech) and BERT (text) Data all sourced from recording/transcribing/recognizing CTP task Key Figs Figure 3 and 4 This figure tells us the late fusion architecture used\nTable 2 Pre-training with an existing dataset had (not statistically quantified) improvement against a randomly seeded model.\nTable 3 Concat/Add fusion methods between audio and text provided even better results; confirms Martinc 2021 on newer data\n","permalink":"https://www.jemoka.com/posts/kbhzhu_2021/","tags":["ntj"],"title":"Zhu 2021"}]