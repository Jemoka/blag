<!doctype html><html lang=en-us><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Commissioner:wght@100;300;400;500;700&family=IBM+Plex+Sans:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css integrity="sha512-KfkfwYDsLkIlwQp6LFnl8zNdLGxu9YAA1QvwINks4PhcElQSvqcyVLLD9aMhXd13uQjoXtEKNosOWaZqXgel0g==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Jost:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>window.MathJax={loader:{load:["[tex]/physics"]},tex:{packages:{"[+]":["physics"]}}}</script><title>Ntj</title><meta name=author content="Houjun Liu"><link rel=stylesheet href=/css/global.css><link rel=stylesheet href=/css/syntax.css></head><body><div class=center-clearfix><header><span id=header-name onclick='window.location.href="/"' style=cursor:pointer>Houjun Liu</span><div id=socialpanel><a href=https://www.jemoka.com/search/ class=header-social id=header-search><i class="ic fa-solid fa-magnifying-glass"></i></i></a>
<a href=https://github.com/Jemoka/ class=header-social id=header-github><i class="ic fa-brands fa-github"></i></a>
<a href=https://maly.io/@jemoka class=header-social id=header-twitter><i class="ic fa-brands fa-mastodon"></i></a>
<a href=https://www.reddit.com/user/Jemoka/ class=header-social id=header-reddit><i class="ic fa-brands fa-reddit"></i></a></div></header><main><div id=title><h1><span class=listhash>#</span>Ntj</h1></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhsadeghian_2021/"'><span class=top><h1><a class=noannot>Sadeghian 2021</a></h1><span class="modbox right">Last edited: <span class=moddate>September 9, 2022</span></span>
</span><span class=summary><p>DOI: 10.3389/fcomp.2021.624594</p><p>(<a href=#citeproc_bib_item_1>Sadeghian, Schaffer, and Zahorian 2021</a>)</p><h2 id=one-liner>One-Liner</h2><p>Using a <a href=/posts/kbhgenetic_algorithum/>genetic algorithm</a>, picked features to optimize fore; achieved \(94\%\) with just <a href=/posts/kbhmmse/>MMSE</a> data alone (ok like duh me too). Developed <a href=/posts/kbhasr/>ASR</a> tool to aid.</p><h2 id=novelty>Novelty</h2><ul><li>Developed an <a href=/posts/kbhasr/>ASR</a> methodology for speech, complete with punctuations</li><li>Used a <a href=/posts/kbhgenetic_algorithum/>genetic algorithm</a> to do feature selection; NNs performed worse because &ldquo;space is smaller???&rdquo;</li></ul><h2 id=notable-methods>Notable Methods</h2><h3 id=used-a-gru-to-insert-punctuations>Used a GRU to insert punctuations</h3><figure><img src=/ox-hugo/2022-06-23_23-44-59_screenshot.png></figure><p>The paper leveraged the nuke that is a bidirectional GRU, ATTENTION,</p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhluz_2021/"'><span class=top><h1><a class=noannot>Luz 2021</a></h1><span class="modbox right">Last edited: <span class=moddate>June 6, 2022</span></span>
</span><span class=summary><p>DOI: 10.1101/2021.03.24.21254263</p><h2 id=one-liner>One-Liner</h2><p>Review paper presenting the \(ADReSS_o\) challenge and current baselines for three tasks</p><h2 id=notes>Notes</h2><p>Three tasks + state of the art:</p><ul><li>Classification of AD: accuracy \(78.87\%\)</li><li>Prediction of <a href=/posts/kbhmmse/>MMSE</a> score: RMSE \(5.28\)</li><li>Prediction of cognitive decline: accuracy \(68.75\%\)</li></ul><h3 id=task-1>Task 1</h3><p>AD classification baseline established by decision tree with <a href=/posts/kbhfusion/#late-fusion>late fusion</a></p><figure><img src=/ox-hugo/2022-06-25_22-57-05_screenshot.png></figure><p>(<a href=/posts/kbhloo/>LOOCV</a> and test)</p><h3 id=task-2>Task 2</h3><p><a href=/posts/kbhmmse/>MMSE</a> score prediction baseline established by <a href=/posts/kbhgrid_search/>grid search</a> on parameters.</p><figure><img src=/ox-hugo/2022-06-25_22-58-42_screenshot.png></figure><p>SVR did best on both counts; results from either model are averaged for prediction.</p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhmahajan_2021/"'><span class=top><h1><a class=noannot>Mahajan 2021</a></h1><span class="modbox right">Last edited: <span class=moddate>June 6, 2022</span></span>
</span><span class=summary><p>DOI: 10.3389/fnagi.2021.623607</p><h2 id=one-liner>One-Liner</h2><p>Trained a bimodal model on speech/text with GRU on speech and CNN-LSTM on text.</p><h2 id=novelty>Novelty</h2><ul><li>A post-2019 NLP paper that doesn&rsquo;t use transformers! (so <del>faster</del> (they used CNN-LSTM) lighter easier)</li><li>&ldquo;Our work sheds light on why the accuracy of these models drops to 72.92% on the ADReSS dataset, whereas, they gave state of the art results on the DementiaBank dataset.&rdquo;</li></ul><h2 id=notable-methods>Notable Methods</h2><p>Bi-Modal audio and transcript processing vis a vi <a href=/posts/kbhshah_2021/>Shah 2021</a>, but with a CNN-LSTM and GRU on the other side.</p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhbalagopalan_2021/"'><span class=top><h1><a class=noannot>Balagopalan 2021</a></h1><span class="modbox right">Last edited: <span class=moddate>June 6, 2022</span></span>
</span><span class=summary><p>DOI: 10.3389/fnagi.2021.635945</p><h2 id=one-liner>One-Liner</h2><p>extracted lexicographic and syntactical features from <a href=/posts/kbhadress_challenge/>ADReSS Challenge</a> data and trained it on various models, with BERT performing the best.</p><h2 id=novelty>Novelty</h2><p>???????</p><p>Seems like results here are a strict subset of <a href=/posts/kbhzhu_2021/>Zhu 2021</a>. Same sets of dataprep of <a href=/posts/kbhantonsson_2021/>Antonsson 2021</a> but trained on a BERT now. Seem to do worse than <a href=/posts/kbhantonsson_2021/>Antonsson 2021</a> too.</p><h2 id=notable-methods>Notable Methods</h2><p>Essentially <a href=/posts/kbhantonsson_2021/>Antonsson 2021</a></p><ul><li>Also performed <a href=/posts/kbhmmse/>MMSE</a> score regression.</li></ul><h2 id=key-figs>Key Figs</h2><h3 id=table-7-training-result>Table 7 training result</h3><figure><img src=/ox-hugo/2022-06-25_11-47-38_screenshot.png></figure><p>This figure shows us that the results attained by training on extracted feature is past the state-of-the-art at the time.</p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhguo_2021/"'><span class=top><h1><a class=noannot>Guo 2021</a></h1><span class="modbox right">Last edited: <span class=moddate>June 6, 2022</span></span>
</span><span class=summary><p>DOI: 10.3389/fcomp.2021.642517</p><h2 id=one-liner>One-Liner</h2><p>Used WLS data to augment <a href=/posts/kbhctp/>CTP</a> from <a href=/posts/kbhadress_challenge/>ADReSS Challenge</a> and trained it on a BERT with good results.</p><h2 id=novelty>Novelty</h2><ul><li>Used WLS data with <a href=/posts/kbhctp/>CTP</a> task to augment ADReSS <a href=/posts/kbhdementiabank/>DementiaBank</a> data</li></ul><h2 id=notable-methods>Notable Methods</h2><p>WLS data is not labeled, so authors used <a href=/posts/kbhsemantic_verbal_fluency/>Semantic Verbal Fluency</a> tests that come with WLS to make a presumed conservative diagnoses. Therefore, control data is more interesting:</p><h2 id=key-figs>Key Figs</h2><h3 id=table-2>Table 2</h3><figure><img src=/ox-hugo/2022-06-25_11-27-14_screenshot.png></figure><p>Data-aug of <a href=/posts/kbhadress_challenge/>ADReSS Challenge</a> data with WSL controls (no presumed AD) trained with a BERT. As expected the conservative control data results in better ferf</p></span></div><ul class="pagination pagination-default"><li class="page-item disabled"><a aria-disabled=true aria-label=First class=page-link role=button tabindex=-1><span aria-hidden=true>⟸</span></a></li><li class="page-item disabled"><a aria-disabled=true aria-label=Previous class=page-link role=button tabindex=-1><span aria-hidden=true>⟵</span></a></li><li class="page-item active"><a aria-current=page aria-label="Page 1" class=page-link role=button>1</a></li><li class=page-item><a href=/tags/ntj/page/2/ aria-label="Page 2" class=page-link role=button>2</a></li><li class=page-item><a href=/tags/ntj/page/3/ aria-label="Page 3" class=page-link role=button>3</a></li><li class=page-item><a href=/tags/ntj/page/4/ aria-label="Page 4" class=page-link role=button>4</a></li><li class=page-item><a href=/tags/ntj/page/2/ aria-label=Next class=page-link role=button><span aria-hidden=true>⟶</span></a></li><li class=page-item><a href=/tags/ntj/page/4/ aria-label=Last class=page-link role=button><span aria-hidden=true>⟹</span></a></li></ul></main><footer><p id=footer>&copy; 2019-2024 Houjun Liu. Licensed CC BY-NC-SA 4.0.</p></footer></div></body></html>