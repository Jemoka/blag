<!doctype html><html lang=en-us><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Commissioner:wght@100;300;400;500;700&family=IBM+Plex+Sans:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css integrity="sha512-KfkfwYDsLkIlwQp6LFnl8zNdLGxu9YAA1QvwINks4PhcElQSvqcyVLLD9aMhXd13uQjoXtEKNosOWaZqXgel0g==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Jost:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>window.MathJax={loader:{load:["[tex]/physics"]},tex:{packages:{"[+]":["physics"]}}}</script><title>Ntj</title>
<meta name=author content="Houjun Liu"><link rel=stylesheet href=/css/global.css><link rel=stylesheet href=/css/syntax.css></head><body><div class=center-clearfix><header><span id=header-name onclick='window.location.href="/"' style=cursor:pointer>Houjun Liu</span><div id=socialpanel><a href=https://www.jemoka.com/search/ class=header-social id=header-search><i class="ic fa-solid fa-magnifying-glass"></i></i></a>
<a href=https://github.com/Jemoka/ class=header-social id=header-github><i class="ic fa-brands fa-github"></i></a>
<a href=https://maly.io/@jemoka class=header-social id=header-twitter><i class="ic fa-brands fa-mastodon"></i></a>
<a href=https://www.reddit.com/user/Jemoka/ class=header-social id=header-reddit><i class="ic fa-brands fa-reddit"></i></a></div></header><main><div id=title><h1><span class=listhash>#</span>Ntj</h1></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhparvin_2020/"'><span class=top><h1><a class=noannot>Parvin 2020</a></h1><span class="modbox right">Last edited: <span class=moddate>June 6, 2022</span></span>
</span><span class=summary><p>DOI: 10.3389/fnagi.2020.605317</p><h2 id=one-liner>One-Liner</h2><p>An excercize scheme has had some measured effect on <a href=/posts/kbhtheta_alpha_ratio/>theta/alpha ratio</a> and Brain wave frequency on AD patients; prognosis of AD not controlled for.</p><h2 id=novelty>Novelty</h2><ul><li>Leveraged physical training scheme and measured EEG effects by quantifying <a href=/posts/kbhtheta_alpha_ratio/>theta/alpha ratio</a></li></ul><h2 id=notable-methods>Notable Methods</h2><ul><li>Used <a href=/posts/kbhtheta_alpha_ratio/>theta/alpha ratio</a> as assay for improvement, and found the exercise scheme did so p&lt;0.05</li><li>Only tested patients with AD w/o a control for stage</li></ul><h2 id=key-figs>Key Figs</h2><h3 id=figure-1>Figure 1</h3><figure><img src=/ox-hugo/2022-06-25_11-13-14_screenshot.png></figure><p>This figure tells us th N number of participants through the study</p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhzhu_2021/"'><span class=top><h1><a class=noannot>Zhu 2021</a></h1><span class="modbox right">Last edited: <span class=moddate>June 6, 2022</span></span>
</span><span class=summary><p>DOI: 10.3389/fcomp.2021.624683</p><h2 id=one-liner>One-Liner</h2><p><a href=/posts/kbhfusion/#late-fusion>late fusion</a> of multimodal signal on the <a href=/posts/kbhctp/>CTP</a> task using transformers, mobilnet, yamnet, and mockingjay</p><h2 id=novelty>Novelty</h2><ul><li>Similar to <a href=/posts/kbhmartinc_2021/>Martinc 2021</a> and <a href=/posts/kbhshah_2021/>Shah 2021</a> but actually used the the current Neural-Network state of the art</li><li>Used <a href=/posts/kbhfusion/#late-fusion>late fusion</a> again after the base model training</li><li>Proposed that inconsistency in the diagnoses of <a href=/posts/kbhmmse/>MMSE</a> scores could be a great contributing factor to multi-task learning performance hindrance</li></ul><h2 id=notable-methods>Notable Methods</h2><ul><li>Proposed base model for transfer learning from text based on MobileNet (image), YAMNet (audio), Mockingjay (speech) and BERT (text)</li><li>Data all sourced from recording/transcribing/recognizing <a href=/posts/kbhctp/>CTP</a> task</li></ul><h2 id=key-figs>Key Figs</h2><h3 id=figure-3-and-4>Figure 3 and 4</h3><figure><img src=/ox-hugo/2022-06-25_10-54-21_screenshot.png></figure><p>This figure tells us the <a href=/posts/kbhfusion/#late-fusion>late fusion</a> architecture used</p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhlindsay_2021/"'><span class=top><h1><a class=noannot>Lindsay 2021</a></h1><span class="modbox right">Last edited: <span class=moddate>June 6, 2022</span></span>
</span><span class=summary><p>DOI: 10.3389/fnagi.2021.642033</p><h2 id=one-liner>One-Liner</h2><p>Proposed cross-linguistic markers shared for AD patients between English and French; evaluated features found with standard ML.</p><h2 id=novelty>Novelty</h2><p>Multi-lingual, cross-linguistic analysis.</p><h2 id=notable-methods>Notable Methods</h2><ul><li>Looked at common patters between the two languages</li><li>Linguistic results scored by <a href=/posts/kbhiu/>IU</a>s on <a href=/posts/kbhctp/>CTP</a> task</li><li></li></ul><h2 id=key-figs>Key Figs</h2><h3 id=figure-1>Figure 1</h3><figure><img src=/ox-hugo/2022-06-24_23-26-39_screenshot.png></figure><p>This figure tells us the various approaches measured.</p><h3 id=table-2>Table 2</h3><figure><img src=/ox-hugo/2022-06-24_23-31-43_screenshot.png></figure><p>Here&rsquo;s a list of semantic features extracted</p><h3 id=table-3>Table 3</h3><figure><img src=/ox-hugo/2022-06-24_23-32-18_screenshot.png></figure><p>Here&rsquo;s a list of NLP features extracted. Bolded items represent P &lt;0.001 correlation for AD/NonAD difference between English and French.</p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhantonsson_2021/"'><span class=top><h1><a class=noannot>Antonsson 2021</a></h1><span class="modbox right">Last edited: <span class=moddate>June 6, 2022</span></span>
</span><span class=summary><p>DOI: 10.3389/fnagi.2020.607449</p><h2 id=one-liner>One-Liner</h2><p><a href=/posts/kbhoral_lexical_retrival/>oral lexical retrieval</a> works better than qualitative narrative analysis to classify dementia; and semantic fluency + Disfluency features chucked on an SVM returns pretty good results.</p><h2 id=novelty>Novelty</h2><p>Tried two different assays of measuring linguistic ability: <a href=/posts/kbhoral_lexical_retrival/>oral lexical retrieval</a> metrics, and qualitative <a href=/posts/kbhdiscourse_features/>discourse features</a> analysis of speech.</p><h2 id=notable-methods>Notable Methods</h2><ul><li><p>Subjects divided into three groups</p><ul><li>Great cog. decline</li><li>Impaired but stable</li><li>Healthy controls</li></ul></li><li><p>Administered <a href=/posts/kbhboston_naming_test/>BNT</a> and <a href=/posts/kbhsemantic_verbal_fluency/>SVF</a> tests as baseline</p><figure><img src=/ox-hugo/2022-06-23_23-23-08_screenshot.png></figure></li></ul><h2 id=key-figs>Key Figs</h2><h3 id=table-3>Table 3</h3><figure><img src=/ox-hugo/2022-06-23_23-02-14_screenshot.png></figure><p>This figure tells us that the percentages of unrelated utterances was a <a href=/posts/kbhhypothesis_testing/#significance-level>statistically significant</a> metric to figure differences between the three experimental groups.</p></span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhchlasta_2021/"'><span class=top><h1><a class=noannot>Chlasta 2021</a></h1><span class="modbox right">Last edited: <span class=moddate>June 6, 2022</span></span>
</span><span class=summary><p>DOI: 10.3389/fpsyg.2020.623237</p><h2 id=one-liner--thrice>One-Liner (thrice)</h2><ol><li>Used features extracted by <a href=/posts/kbhvggish/>VGGish</a> from raw acoustic audio against a SVM, Perceptron, 1NN; got \(59.1\%\) classif. accuracy for dementia</li><li>Then, trained a CNN on raw wave-forms and got \(63.6\%\) accuracy</li><li>Then, they fine-tuned a <a href=/posts/kbhvggish/>VGGish</a> on the raw wave-forms and didn&rsquo;t report their results and just said &ldquo;we discovered that audio transfer learning with a pretrained VGGish feature extractor performs better&rdquo; Gah!</li></ol><h2 id=novelty>Novelty</h2><p>Threw the kitchen sink to process only raw acoustic input, most of it missed; wanted 0 human involvement. It seems like last method is promising.</p></span></div><ul class="pagination pagination-default"><li class=page-item><a href=/tags/ntj/ aria-label=First class=page-link role=button><span aria-hidden=true>⟸</span></a></li><li class=page-item><a href=/tags/ntj/ aria-label=Previous class=page-link role=button><span aria-hidden=true>⟵</span></a></li><li class=page-item><a href=/tags/ntj/ aria-label="Page 1" class=page-link role=button>1</a></li><li class="page-item active"><a aria-current=page aria-label="Page 2" class=page-link role=button>2</a></li><li class=page-item><a href=/tags/ntj/page/3/ aria-label="Page 3" class=page-link role=button>3</a></li><li class=page-item><a href=/tags/ntj/page/4/ aria-label="Page 4" class=page-link role=button>4</a></li><li class=page-item><a href=/tags/ntj/page/3/ aria-label=Next class=page-link role=button><span aria-hidden=true>⟶</span></a></li><li class=page-item><a href=/tags/ntj/page/4/ aria-label=Last class=page-link role=button><span aria-hidden=true>⟹</span></a></li></ul></main><footer><p id=footer>&copy; 2019-2024 Houjun Liu. Licensed CC BY-NC-SA 4.0.</p></footer></div></body></html>