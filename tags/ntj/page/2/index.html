<!doctype html><html lang=en-us><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Commissioner:wght@100;300;400;500;700&family=IBM+Plex+Sans:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css integrity="sha512-KfkfwYDsLkIlwQp6LFnl8zNdLGxu9YAA1QvwINks4PhcElQSvqcyVLLD9aMhXd13uQjoXtEKNosOWaZqXgel0g==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Jost:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>window.MathJax={loader:{load:["[tex]/physics"]},tex:{packages:{"[+]":["physics"]}}}</script><title>ntj</title>
<meta name=author content="Houjun Liu"><link rel=stylesheet href=/css/global.css><link rel=stylesheet href=/css/syntax.css></head><body><div class=center-clearfix><header><span id=header-name onclick='window.location.href="/"' style=cursor:pointer>Houjun Liu</span><div id=socialpanel><a href=https://www.jemoka.com/search/ class=header-social id=header-search><i class="ic fa-solid fa-magnifying-glass"></i></i></a>
<a href=https://github.com/Jemoka/ class=header-social id=header-github><i class="ic fa-brands fa-github"></i></a>
<a href=https://maly.io/@jemoka class=header-social id=header-twitter><i class="ic fa-brands fa-mastodon"></i></a>
<a href=https://www.reddit.com/user/Jemoka/ class=header-social id=header-reddit><i class="ic fa-brands fa-reddit"></i></a></div></header><main><div id=title><h1><span class=listhash>#</span>ntj</h1></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhparvin_2020/"'><span class=top><h1><a class=noannot>Parvin 2020</a></h1><span class="modbox right">Last edited: <span class=moddate>June 6, 2022</span></span>
</span><span class=summary>DOI: 10.3389/fnagi.2020.605317
One-Liner An excercize scheme has had some measured effect on theta/alpha ratio and Brain wave frequency on AD patients; prognosis of AD not controlled for.
Novelty Leveraged physical training scheme and measured EEG effects by quantifying theta/alpha ratio Notable Methods Used theta/alpha ratio as assay for improvement, and found the exercise scheme did so p&lt;0.05 Only tested patients with AD w/o a control for stage Key Figs Figure 1 This figure tells us th N number of participants through the study</span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhzhu_2021/"'><span class=top><h1><a class=noannot>Zhu 2021</a></h1><span class="modbox right">Last edited: <span class=moddate>June 6, 2022</span></span>
</span><span class=summary>DOI: 10.3389/fcomp.2021.624683
One-Liner late fusion of multimodal signal on the CTP task using transformers, mobilnet, yamnet, and mockingjay
Novelty Similar to Martinc 2021 and Shah 2021 but actually used the the current Neural-Network state of the art Used late fusion again after the base model training Proposed that inconsistency in the diagnoses of MMSE scores could be a great contributing factor to multi-task learning performance hindrance Notable Methods Proposed base model for transfer learning from text based on MobileNet (image), YAMNet (audio), Mockingjay (speech) and BERT (text) Data all sourced from recording/transcribing/recognizing CTP task Key Figs Figure 3 and 4 This figure tells us the late fusion architecture used</span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhlindsay_2021/"'><span class=top><h1><a class=noannot>Lindsay 2021</a></h1><span class="modbox right">Last edited: <span class=moddate>June 6, 2022</span></span>
</span><span class=summary>DOI: 10.3389/fnagi.2021.642033
One-Liner Proposed cross-linguistic markers shared for AD patients between English and French; evaluated features found with standard ML.
Novelty Multi-lingual, cross-linguistic analysis.
Notable Methods Looked at common patters between the two languages Linguistic results scored by IUs on CTP task Key Figs Figure 1 This figure tells us the various approaches measured.
Table 2 Here&rsquo;s a list of semantic features extracted
Table 3 Here&rsquo;s a list of NLP features extracted.</span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhantonsson_2021/"'><span class=top><h1><a class=noannot>Antonsson 2021</a></h1><span class="modbox right">Last edited: <span class=moddate>June 6, 2022</span></span>
</span><span class=summary>DOI: 10.3389/fnagi.2020.607449
One-Liner oral lexical retrieval works better than qualitative narrative analysis to classify dementia; and semantic fluency + Disfluency features chucked on an SVM returns pretty good results.
Novelty Tried two different assays of measuring linguistic ability: oral lexical retrieval metrics, and qualitative discourse features analysis of speech.
Notable Methods Subjects divided into three groups
Great cog. decline Impaired but stable Healthy controls Administered BNT and SVF tests as baseline</span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhchlasta_2021/"'><span class=top><h1><a class=noannot>Chlasta 2021</a></h1><span class="modbox right">Last edited: <span class=moddate>June 6, 2022</span></span>
</span><span class=summary>DOI: 10.3389/fpsyg.2020.623237
One-Liner (thrice) Used features extracted by VGGish from raw acoustic audio against a SVM, Perceptron, 1NN; got \(59.1\%\) classif. accuracy for dementia Then, trained a CNN on raw wave-forms and got \(63.6\%\) accuracy Then, they fine-tuned a VGGish on the raw wave-forms and didn&rsquo;t report their results and just said &ldquo;we discovered that audio transfer learning with a pretrained VGGish feature extractor performs better&rdquo; Gah! Novelty Threw the kitchen sink to process only raw acoustic input, most of it missed; wanted 0 human involvement.</span></div><ul class="pagination pagination-default"><li class=page-item><a href=/tags/ntj/ aria-label=First class=page-link role=button><span aria-hidden=true>⟸</span></a></li><li class=page-item><a href=/tags/ntj/ aria-label=Previous class=page-link role=button><span aria-hidden=true>⟵</span></a></li><li class=page-item><a href=/tags/ntj/ aria-label="Page 1" class=page-link role=button>1</a></li><li class="page-item active"><a aria-current=page aria-label="Page 2" class=page-link role=button>2</a></li><li class=page-item><a href=/tags/ntj/page/3/ aria-label="Page 3" class=page-link role=button>3</a></li><li class=page-item><a href=/tags/ntj/page/4/ aria-label="Page 4" class=page-link role=button>4</a></li><li class=page-item><a href=/tags/ntj/page/3/ aria-label=Next class=page-link role=button><span aria-hidden=true>⟶</span></a></li><li class=page-item><a href=/tags/ntj/page/4/ aria-label=Last class=page-link role=button><span aria-hidden=true>⟹</span></a></li></ul></main><footer><p id=footer>&copy; 2019-2024 Houjun Liu. Licensed CC BY-NC-SA 4.0.</p></footer></div></body></html>