<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>ntj on jemoka.com</title><link>https://www.jemoka.com/tags/ntj/</link><description>Recent content in ntj on jemoka.com</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://www.jemoka.com/tags/ntj/index.xml" rel="self" type="application/rss+xml"/><item><title>Antonsson 2021</title><link>https://www.jemoka.com/posts/kbhantonsson_2021/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.jemoka.com/posts/kbhantonsson_2021/</guid><description>DOI: 10.3389/fnagi.2020.607449
One-Liner oral lexical retrieval works better than qualitative narrative analysis to classify dementia; and semantic fluency + Disfluency features chucked on an SVM returns pretty good results.
Novelty Tried two different assays of measuring linguistic ability: oral lexical retrieval metrics, and qualitative discourse features analysis of speech.
Notable Methods Subjects divided into three groups
Great cog. decline Impaired but stable Healthy controls Administered BNT and SVF tests as baseline</description></item><item><title>Chlasta 2021</title><link>https://www.jemoka.com/posts/kbhchlasta_2021/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.jemoka.com/posts/kbhchlasta_2021/</guid><description>DOI: 10.3389/fpsyg.2020.623237
One-Liner (thrice) Used features extracted by VGGish from raw acoustic audio against a SVM, Perceptron, 1NN; got \(59.1\%\) classif. accuracy for dementia Then, trained a CNN on raw wave-forms and got \(63.6\%\) accuracy Then, they fine-tuned a VGGish on the raw wave-forms and didn&amp;rsquo;t report their results and just said &amp;ldquo;we discovered that audio transfer learning with a pretrained VGGish feature extractor performs better&amp;rdquo; Gah! Novelty Threw the kitchen sink to process only raw acoustic input, most of it missed; wanted 0 human involvement.</description></item><item><title>Jonell 2021</title><link>https://www.jemoka.com/posts/kbhjonell_2021/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.jemoka.com/posts/kbhjonell_2021/</guid><description>DOI: 10.3389/fcomp.2021.642633
One-Liner Developed a kitchen sink of diagnoses tools and correlated it with biomarkers.
Novelty The kitchen sink of data collection (phones, tablet, eye tracker, microphone, wristband) and the kitchen sink of noninvasive data imaging, psych, speech assesment, clinical metadata.
Notable Methods Here&amp;rsquo;s their kitchen sink
I have no idea why a thermal camera is needed
Key Figs Here are the features they extracted
Developed the features collected via a method similar to action research, did two passes and refined/added information after preliminary analysis.</description></item><item><title>Laguarta 2021</title><link>https://www.jemoka.com/posts/kbhlaguarta_2021/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.jemoka.com/posts/kbhlaguarta_2021/</guid><description>DOI: 10.3389/fcomp.2021.624694
One-Liner Proposed a large multimodal approach to embed auditory info + biomarkers for baseline classification.
Novelty Developed a massively multimodal audio-to-embedding correlation system that maps audio to biomarker information collected (mood, memory, respiratory) and demonstrated its ability to discriminate cough results for COVID. (they were looking for AD; whoopsies)
Notable Methods Developed a feature extraction model for AD detection named Open Voice Brain Model Collected a dataset on people coughing and correlated it with biomarkers Key Figs Figure 2 This is MULTI-MODAL as heck</description></item><item><title>Lindsay 2021</title><link>https://www.jemoka.com/posts/kbhlindsay_2021/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.jemoka.com/posts/kbhlindsay_2021/</guid><description>DOI: 10.3389/fnagi.2021.642033
One-Liner Proposed cross-linguistic markers shared for AD patients between English and French; evaluated features found with standard ML.
Novelty Multi-lingual, cross-linguistic analysis.
Notable Methods Looked at common patters between the two languages Linguistic results scored by IUs on CTP task Key Figs Figure 1 This figure tells us the various approaches measured.
Table 2 Here&amp;rsquo;s a list of semantic features extracted
Table 3 Here&amp;rsquo;s a list of NLP features extracted.</description></item><item><title>Martinc 2021</title><link>https://www.jemoka.com/posts/kbhmartinc_2021/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.jemoka.com/posts/kbhmartinc_2021/</guid><description>DOI: 10.3389/fnagi.2021.642647
One-Liner Combined bag-of-words on transcript + ADR on audio to various classifiers for AD; ablated BERT&amp;rsquo;s decesion space for attention to make more easy models in the future.
Novelty Pre-processed each of the two modalities before fusing it (late fusion) Archieved \(93.75\%\) accuracy on AD detection The data being forced-aligned and fed with late fusion allows one to see what sounds/words the BERT model was focusing on by just focusing on the attention on the words Notable Methods Used classic cookie theft data bag of words to do ADR but for words multimodality but late fusion with one (hot-swappable) classifier Key Figs How they did it This is how the combined the forced aligned (:tada:) audio and transcript together.</description></item><item><title>Meghanani 2021</title><link>https://www.jemoka.com/posts/kbhmeghanani_2021/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.jemoka.com/posts/kbhmeghanani_2021/</guid><description>DOI: 10.3389/fcomp.2021.624558
One-Liner analyzed spontaneous speech transcripts (only!) from TD and AD patients with fastText and CNN; best was \(83.33\%\) acc.
Novelty threw the NLP kitchen sink to transcripts fastText CNN (with vary n-gram kernel 2,3,4,5 sizes) Notable Methods embeddings seaded by GloVe fastText are much faster, but CNN won out Key Figs the qual results PAR (participant), INV (investigator)
Notes Hey look a review of the field:</description></item><item><title>Sadeghian 2021</title><link>https://www.jemoka.com/posts/kbhsadeghian_2021/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.jemoka.com/posts/kbhsadeghian_2021/</guid><description>DOI: 10.3389/fcomp.2021.624594
One-Liner Using a genetic algorithm, picked features to optimize fore; achieved \(94\%\) with just MMSE data alone. Developed ASR tool to aid.
Novelty Developed an ASR methodology for speech, complete with punctuations Used a genetic algorithm to do feature selection; NNs performed worse because &amp;ldquo;space is smaller???&amp;rdquo; Notable Methods Used a GRU to insert punctuations The paper leveraged the nuke that is a bidirectional GRU, ATTENTION,
Key Figs Fully automated ANN transcript does pretty well in terms of classifier AD/NL.</description></item><item><title>Shah 2021</title><link>https://www.jemoka.com/posts/kbhshah_2021/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.jemoka.com/posts/kbhshah_2021/</guid><description>DOI: 10.3389/fcomp.2021.624659
One-Liner Multi-feature late fusion of NLP results (by normalizing text and n-gram processing) with OpenSMILE embedding results.
Novelty NLP transcript normalization (see methods) and OpenSMILE; otherwise similar to Martinc 2021. Same gist but different data-prep.
Notable Methods N-gram processed the input features Used WordNet to replace words with roots Key Figs New Concepts OpenSMILE</description></item><item><title>Yuan 2021</title><link>https://www.jemoka.com/posts/kbhyuan_2021/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.jemoka.com/posts/kbhyuan_2021/</guid><description>DOI: 10.3389/fcomp.2020.624488
One-Liner Used an ERNIE trained on transcripts for classification; inclusion of pause encoding made results better.
Novelty Instead of just looking at actual speech content, look at pauses specific as a feature engineering task \(89.6\%\) on the ADReSS Challenge dataset Notable Methods Applied FA with pause encoding with standard .cha semantics (short pauses, medium pauses, long pauses). Shoved all of this into an ERNIE.
Assay for performance was LOO</description></item></channel></rss>