<!doctype html><html lang=en-us><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Commissioner:wght@100;300;400;500;700&family=IBM+Plex+Sans:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css integrity="sha512-Evv84Mr4kqVGRNSgIGL/F/aIDqQb7xQ2vcrdIwxfjThSH8CSR7PBEakCr51Ck+w+/U6swU2Im1vVX0SVk9ABhg==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Jost:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>window.MathJax={loader:{load:["[tex]/physics"]},tex:{packages:{"[+]":["physics"]}}}</script><title>Language Model Agents</title>
<meta name=description content="agents that uses the language to act on behave of another person or group.
Challenges
See Challenges of Language Model Agents
Methods
ReAct
See ReAct
Aguvis
Take the AgentNet dataset, and then tune a vison LM to roll out the rest of the sequence of actions given screenshots as input on top of a Qwen base model.
We can also add on top Chain of Thought to get more thinking as well.
Formulations
OSWorld
A unified task setup and evaluation."><meta name=author content="Houjun Liu"><link rel=stylesheet href=/css/global.css><link rel=stylesheet href=/css/syntax.css></head><body><div class=center-clearfix><header><span id=header-name onclick='window.location.href="/"' style=cursor:pointer>Houjun Liu</span><div id=socialpanel><a href=https://www.jemoka.com/search/ class=header-social id=header-search><i class="ic fa-solid fa-magnifying-glass"></i></i></a>
<a href=https://github.com/Jemoka/ class=header-social id=header-github><i class="ic fa-brands fa-github"></i></a>
<a href=https://bsky.app/profile/jemoka.com class=header-social id=header-twitter><i class="ic fa-brands fa-bluesky"></i></a>
<a href=https://www.reddit.com/user/Jemoka/ class=header-social id=header-reddit><i class="ic fa-brands fa-reddit"></i></a></div></header><div id=title><h1>Language Model Agents</h1><span class=tagbox></span></div><aside id=toc><h1 id=toc-title>table of contents</h1><nav id=TableOfContents><ul><li><a href=#challenges>Challenges</a></li><li><a href=#methods>Methods</a><ul><li><a href=#react>ReAct</a></li><li><a href=#aguvis>Aguvis</a></li></ul></li><li><a href=#formulations>Formulations</a><ul><li><a href=#osworld>OSWorld</a></li><li><a href=#interactive-agents>Interactive Agents</a></li></ul></li><li><a href=#evaluations>Evaluations</a><ul><li><a href=#computer-agent-arena>Computer Agent Arena</a></li></ul></li></ul></nav></aside><main><article><div><p>agents that uses the language to act on behave of another person or group.</p><h2 id=challenges>Challenges</h2><p>See <a href=/posts/kbhchallenges_of_language_model_agents/>Challenges of Language Model Agents</a></p><h2 id=methods>Methods</h2><h3 id=react>ReAct</h3><p>See <a href>ReAct</a></p><h3 id=aguvis>Aguvis</h3><p>Take the <a href=/posts/kbhagentnet/>AgentNet</a> dataset, and then tune a vison LM to roll out the rest of the sequence of actions given screenshots as input on top of a Qwen base model.</p><p>We can also add on top <a href=/posts/kbhchain_of_thought/>Chain of Thought</a> to get more thinking as well.</p><h2 id=formulations>Formulations</h2><h3 id=osworld>OSWorld</h3><p>A unified task setup and evaluation.</p><p>Motivation: Given language is a universal task specification, can we create a <strong>universal digital environment</strong>&mdash;with unified observation and action spaces?</p><h4 id=spec>spec</h4><ul><li><p>config</p><ul><li>initial state: how to setup, what to open, what files, etc.</li><li>evaluator: an evaluation script for task being done</li></ul></li></ul><ul><li><p>Obeservation</p><p>screen, screen shot, etc.</p><ul><li><p>Screenshot vs API Tradeoffs</p><ul><li>most websites/applications don&rsquo;t have them exposed</li><li>API outputs is very hard to verify quickly, whereas actual mouse action is easy to verify+stop</li></ul></li></ul></li></ul><ul><li><p>action</p><p>mouse keyboard controls, move, PyAutoGui style</p></li></ul><h4 id=dataset>dataset</h4><p>369 computer use task for evaluations</p><h4 id=evals>evals</h4><p>Claude, for one, is still really really bad at computer use. Claude computer use gets ~20% success rate versus humans&rsquo; ~70%.</p><h3 id=interactive-agents>Interactive Agents</h3><p>Big question: how to we align agents in an interactive, dynamic way (i.e. without instruction fine tuning which is hard). Language is information that helps agents <strong>predict the future</strong>; instructions is <strong>world modeling</strong></p><ul><li>instead of instructions => actions (executor)</li><li>instructions => updated belief (world model)</li></ul><p>User intent => action shouldn&rsquo;t have LLM language representation in the middle as a bottleneck.</p><p>There is an underlying representation of the user&rsquo;s preferences, you have to use language to coax it out of them.</p><h4 id=dynalang>Dynalang</h4><ol><li>build model that takes vision + language as a joint input</li><li>pass it through an auto-encoding representation</li><li>have the world model predict the next-encoding representation</li></ol><p>Main Idea: modeling language/tokens/images as a joint latent representation over time.</p><p>Training objective:</p><ol><li>reconstruction loss against the future presentation: using \(R_{i}\) to predict \(R_{i+1}\)</li><li>predict the reward over time</li><li>regularize?</li></ol><ul><li><p>Workflow</p><ol><li>take reward/preferences/behavior data</li><li><a href=/posts/kbhstructure_learning/>structure learning</a> to create the relationships between elements in the data structure</li></ol></li></ul><h2 id=evaluations>Evaluations</h2><h3 id=computer-agent-arena>Computer Agent Arena</h3><p><a href=https://arena.xlang.ai>https://arena.xlang.ai</a></p><ul><li>an open source platform for digital ai agents</li><li>users can preference-rank different agent performances</li></ul><h4 id=workflow>workflow</h4><ul><li>select OS environment (Windows, Ubuntu&mldr;) to create identical instances</li><li>configure computers in <strong>initial setup</strong> using preset scripts / click to have custom setup (why custom setups? to create diversity of senarios to help more generalization)</li><li>we automatically generate interaction scenarios given a user task prompt</li><li>finally, human perform scoring:<ol><li>Correct or Not?</li><li>Which one is Better?</li><li>Safe or not?</li></ol></li></ul><h4 id=goals>goals</h4><ul><li>for eval: evaluate + rank agents</li><li>training: data collection, RL, etc.</li></ul></div></article></main><footer><p id=footer>&copy; 2019-2025 Houjun Liu. Licensed CC BY-NC-SA 4.0.</p></footer></div></body></html>