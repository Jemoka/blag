<!doctype html><html lang=en-us><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Commissioner:wght@100;300;400;500;700&family=IBM+Plex+Sans:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css integrity="sha512-KfkfwYDsLkIlwQp6LFnl8zNdLGxu9YAA1QvwINks4PhcElQSvqcyVLLD9aMhXd13uQjoXtEKNosOWaZqXgel0g==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Jost:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>window.MathJax={loader:{load:["[tex]/physics"]},tex:{packages:{"[+]":["physics"]}}}</script><title>Chatbot</title>
<meta name=description content="Two main Dialogue Systems architectures:

frame based systems: talk to users + accomplish specific tasks
LLM: reasoning as agents

Dialogue Systems vs Chatbot
Previously, when we say Chatbot we mean task-based systems
humans and chat
humans tend to think of Dialogue Systems as human-like even if they know its not. this makes users more prone to share private information and worry less about its disclosure.
ELIZA
see ELIZA
LLM Chatbots
Training Corpus
C4: colossal clean crawled corpus"><meta name=author content="Houjun Liu"><link rel=stylesheet href=/css/global.css><link rel=stylesheet href=/css/syntax.css></head><body><div class=center-clearfix><header><span id=header-name onclick='window.location.href="/"' style=cursor:pointer>Houjun Liu</span><div id=socialpanel><a href=https://www.jemoka.com/search/ class=header-social id=header-search><i class="ic fa-solid fa-magnifying-glass"></i></i></a>
<a href=https://github.com/Jemoka/ class=header-social id=header-github><i class="ic fa-brands fa-github"></i></a>
<a href=https://maly.io/@jemoka class=header-social id=header-twitter><i class="ic fa-brands fa-mastodon"></i></a>
<a href=https://www.reddit.com/user/Jemoka/ class=header-social id=header-reddit><i class="ic fa-brands fa-reddit"></i></a></div></header><div id=title><h1>Chatbot</h1><span class=tagbox></span></div><aside id=toc><h1 id=toc-title>table of contents</h1><nav id=TableOfContents><ul><li><a href=#dialogue-systems--kbhchatbot-dot-md--vs-chatbot--kbhchatbot-dot-md><a href=HAHAHUGOSHORTCODE219s1HBHB>Dialogue Systems</a> vs <a href=HAHAHUGOSHORTCODE219s2HBHB>Chatbot</a></a></li><li><a href=#humans-and-chat>humans and chat</a></li><li><a href=#eliza--kbheliza-dot-md><a href=HAHAHUGOSHORTCODE219s5HBHB>ELIZA</a></a></li><li><a href=#llm-chatbots>LLM Chatbots</a><ul><li><a href=#training-corpus>Training Corpus</a></li><li><a href=#chatbots>Chatbots</a></li><li><a href=#fine-tuning>Fine-Tuning</a></li><li><a href=#retrieval-augmented-generation>Retrieval Augmented Generation</a></li></ul></li><li><a href=#evaluation>Evaluation</a><ul><li><a href=#participants-scoring>participants scoring</a></li><li><a href=#adversarial-evaluation>adversarial evaluation</a></li><li><a href=#task-evaluatino>task evaluatino</a></li></ul></li><li><a href=#design-system-design>design system design</a><ul><li><a href=#study-users-and-task>study users and task</a></li><li><a href=#build-simulations>build simulations</a></li><li><a href=#test-the-design>test the design</a></li><li><a href=#info-leakage>info leakage</a></li></ul></li></ul></nav></aside><main><article><div><p>Two main <a href=/posts/kbhchatbot/>Dialogue Systems</a> architectures:</p><ul><li><strong>frame based</strong> systems: talk to users + accomplish specific tasks</li><li><strong>LLM</strong>: reasoning as agents</li></ul><h2 id=dialogue-systems--kbhchatbot-dot-md--vs-chatbot--kbhchatbot-dot-md><a href=/posts/kbhchatbot/>Dialogue Systems</a> vs <a href=/posts/kbhchatbot/>Chatbot</a></h2><p>Previously, when we say <a href=/posts/kbhchatbot/>Chatbot</a> we mean task-based systems</p><h2 id=humans-and-chat>humans and chat</h2><p>humans tend to think of <a href=/posts/kbhchatbot/>Dialogue Systems</a> as human-like even if they know its not. this makes users more prone to share private information and worry less about its disclosure.</p><h2 id=eliza--kbheliza-dot-md><a href=/posts/kbheliza/>ELIZA</a></h2><p>see <a href=/posts/kbheliza/>ELIZA</a></p><h2 id=llm-chatbots>LLM Chatbots</h2><h3 id=training-corpus>Training Corpus</h3><p>C4: colossal clean crawled corpus</p><p>patent, wikipedia, news</p><h3 id=chatbots>Chatbots</h3><ul><li>EmphaticDialogues</li><li>SaFeRDialogues</li><li>Pseudo-conversations: reddit, twitter, weibo</li></ul><h3 id=fine-tuning>Fine-Tuning</h3><ul><li><strong>quality</strong>: improving sensible and interesting responses</li><li><strong>safety</strong>: prevention of suggesting harmful actions</li></ul><p><strong>IFT</strong>: perhaps you can add positive data as fine tuning as a part of instruction-finetuning step.</p><p><strong>Filtering</strong>: build a filter for whether something is safe/unsafe, etc.</p><h3 id=retrieval-augmented-generation>Retrieval Augmented Generation</h3><ol><li>call search engine</li><li>get back a retrieved passages</li><li>shove them into prompt</li><li>&ldquo;based on this tasks, answer:&rdquo;</li></ol><p>we can make <a href=/posts/kbhchatbot/>Chatbot</a>s use <a href=#retrieval-augmented-generation>RAG</a> by adding &ldquo;pseudo-participants&rdquo; to make the chat bots, which the system should add.</p><h2 id=evaluation>Evaluation</h2><ul><li><strong>task based systems</strong>: measure task performance</li><li><strong>chatbot</strong>: enjoyability by humans</li></ul><p>we evaluate chatbots by asking a human to assign a score, and observer is a third party that assigns a score via a transcript of a conversation.</p><h3 id=participants-scoring>participants scoring</h3><p>interact with 6 turns, then score:</p><ul><li>avoiding repetition</li><li>interestingness</li><li>sensemaking</li><li>fluency</li><li>listening</li><li>inquisitiveness</li><li>humanness</li><li>engagingness</li></ul><p>ACUTE-EVAL: <strong>choosing who you would like to speak to</strong></p><h3 id=adversarial-evaluation>adversarial evaluation</h3><p>train a human/robot classifier, use it, use the inverse of its score at the metric of the chat bot</p><h3 id=task-evaluatino>task evaluatino</h3><p>measure overall task success, or measure slot error rate</p><h2 id=design-system-design>design system design</h2><p>Don&rsquo;t build <strong>Frankenstein</strong>: safety (ensure people aren&rsquo;t crashing cars), limiting representation harm (don&rsquo;t demean social groups), privacy</p><h3 id=study-users-and-task>study users and task</h3><p>what are their values? how do they interact?</p><h3 id=build-simulations>build simulations</h3><p><strong>wizard of oz</strong> study: observe user interaction with a <strong>HUMAN</strong> pretending to be a chat bot</p><h3 id=test-the-design>test the design</h3><p>test on users</p><h3 id=info-leakage>info leakage</h3><ul><li>accidentally leaking information (microphone, etc.)</li><li>intentionally leaking information due to advertising, etc.</li></ul></div></article></main><footer><p id=footer>&copy; 2019-2024 Houjun Liu. Licensed CC BY-NC-SA 4.0.</p></footer></div></body></html>