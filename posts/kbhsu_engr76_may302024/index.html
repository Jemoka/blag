<!doctype html><html lang=en-us><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Commissioner:wght@100;300;400;500;700&family=IBM+Plex+Sans:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css integrity="sha512-KfkfwYDsLkIlwQp6LFnl8zNdLGxu9YAA1QvwINks4PhcElQSvqcyVLLD9aMhXd13uQjoXtEKNosOWaZqXgel0g==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Jost:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>window.MathJax={loader:{load:["[tex]/physics"]},tex:{packages:{"[+]":["physics"]}}}</script><title>SU-ENGR76 MAY302024</title>
<meta name=description content="Consider a mapping between \(X \in \{0,1\}\), and output \(Y \in \{0,1\}\), with a chance of error of probability \(p\). So we have four outcomes:
X Y p 0 0 1-p 1 1 1-p 0 1 p 1 0 p Writing this out:
\(P(y=1|x=0) = p\) \(P(y=0|x=1) = p\) \(P(y=0|x=0) = 1-p\) \(P(y=1|x=1) = 1-p\) Recall chain rule:
\begin{equation} P(X,Y|A) = P(X|Y,A) P(Y|A) \end{equation}
Consider some input output pair:
\begin{equation} p(y=10 | x = 00) = p(y_1=1 | x_1=0, x_2=0)p(y_2=0| y_1=1, x_1=0, x_2=0) \end{equation}"><meta name=author content="Houjun Liu"><link rel=stylesheet href=/css/global.css><link rel=stylesheet href=/css/syntax.css></head><body><div class=center-clearfix><header><span id=header-name onclick='window.location.href="/"' style=cursor:pointer>Houjun Liu</span><div id=socialpanel><a href=https://www.jemoka.com/search/ class=header-social id=header-search><i class="ic fa-solid fa-magnifying-glass"></i></i></a>
<a href=https://github.com/Jemoka/ class=header-social id=header-github><i class="ic fa-brands fa-github"></i></a>
<a href=https://maly.io/@jemoka class=header-social id=header-twitter><i class="ic fa-brands fa-mastodon"></i></a>
<a href=https://www.reddit.com/user/Jemoka/ class=header-social id=header-reddit><i class="ic fa-brands fa-reddit"></i></a></div></header><div id=title><h1>SU-ENGR76 MAY302024</h1><span class=tagbox></span></div><aside id=toc><h1 id=toc-title>table of contents</h1><nav id=TableOfContents><ul><li><a href=#shannon-s-channel-coding-theorem>Shannon&rsquo;s Channel-Coding Theorem</a></li><li><a href=#law-of-large-numbers>Law of Large Numbers</a></li></ul></nav></aside><main><article><div><p>Consider a mapping between \(X \in \{0,1\}\), and output \(Y \in \{0,1\}\), with a chance of error of probability \(p\). So we have four outcomes:</p><table><thead><tr><th>X</th><th>Y</th><th>p</th></tr></thead><tbody><tr><td>0</td><td>0</td><td>1-p</td></tr><tr><td>1</td><td>1</td><td>1-p</td></tr><tr><td>0</td><td>1</td><td>p</td></tr><tr><td>1</td><td>0</td><td>p</td></tr></tbody></table><p>Writing this out:</p><ul><li>\(P(y=1|x=0) = p\)</li><li>\(P(y=0|x=1) = p\)</li><li>\(P(y=0|x=0) = 1-p\)</li><li>\(P(y=1|x=1) = 1-p\)</li></ul><p>Recall chain rule:</p><p>\begin{equation}
P(X,Y|A) = P(X|Y,A) P(Y|A)
\end{equation}</p><hr><p>Consider some input output pair:</p><p>\begin{equation}
p(y=10 | x = 00) = p(y_1=1 | x_1=0, x_2=0)p(y_2=0| y_1=1, x_1=0, x_2=0)
\end{equation}</p><p>A memoryless channel becomes<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup></p><p>\begin{equation}
p(y_1=1 | x_1=0, x_2=0)p(y_2=0| y_1=1, x_1=0, x_2=0) = p(y_1=1 | x_1=0)p(y_2=0|x_2=0)
\end{equation}</p><p>This means<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup></p><p>\begin{equation}
p(y=r_1 \dots r_{n} | x = t_1 \dots t_{k}) = p(r_1|t_1) p(r_2|t_2) \dots p(r_{n}|t_{n})
\end{equation}</p><h2 id=shannon-s-channel-coding-theorem>Shannon&rsquo;s Channel-Coding Theorem</h2><p>For any communication channel (characterized by \(p(y|x)\), for a pair of input and output), there exists a way to construct an encoder/decoder pair that make it possible to send information over this channel at some rate \(R\) (bits/channel use) while making the probability of error arbitrarily small as long as \(R &lt; C\).</p><p>Conversely, trying to send information at rate \(R > C\) bits/channel use, errors are inevitable.</p><p>\begin{equation}
C = \max_{\text{dist}(X)} I (x:y)
\end{equation}</p><p>the capacity of a channel is the maximum mutual information that could be given any choice of input distribution. you should choose the input that induces the maximum mutual information between the input and output of a channel. where \(I\) is the <a href=/posts/kbhmutual_information/>mutual information</a>.</p><h2 id=law-of-large-numbers>Law of Large Numbers</h2><p>The average value of many, independent repeated trials is close to the true expectation.</p><p>Because the law of large numbers (<a href=#citeproc_bib_item_1>Wolf et al. 2020</a>), the we can transmit the number of bit flips over a binary substitution channel with probability \(Lp\).</p><p>So: design a code with very long codewords \(L \gg 0\) that can correct \(L(p+\epsilon)\) bitflips for some small choice of \(\epsilon > 0\).</p><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>test foonote&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p>its true though it may not&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div></article></main><footer><p id=footer>&copy; 2019-2024 Houjun Liu. Licensed CC BY-NC-SA 4.0.</p></footer></div></body></html>