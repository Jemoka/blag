<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Commissioner:wght@100;300;400;500;700&family=IBM+Plex+Sans:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css integrity="sha512-KfkfwYDsLkIlwQp6LFnl8zNdLGxu9YAA1QvwINks4PhcElQSvqcyVLLD9aMhXd13uQjoXtEKNosOWaZqXgel0g==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script>
<link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Jost:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><title>Yuan 2021</title><meta name=description content="DOI: 10.3389/fcomp.2020.624488
One-Liner Used an ERNIE trained on transcripts for classification; inclusion of pause encoding made results better.
Novelty Instead of just looking at actual speech content, look at pauses specific as a feature engineering task \(89.6\%\) on the ADReSS Challenge dataset Notable Methods Applied FA with pause encoding with standard .cha semantics (short pauses, medium pauses, long pauses). Shoved all of this into an ERNIE.
Assay for performance was LOO"><meta name=author content="Houjun Liu"><link rel=stylesheet href=/css/global.css><link rel=stylesheet href=/css/syntax.css></head><body><header><span id=header-name onclick='window.location.href="/"' style=cursor:pointer>Houjun Liu</span><div id=socialpanel><a href=https://www.jemoka.com/search/ class=header-social id=header-search><i class="ic fa-solid fa-magnifying-glass"></i></i></a>
<a href=https://github.com/Jemoka/ class=header-social id=header-github><i class="ic fa-brands fa-github"></i></a>
<a href=https://twitter.com/jemokajack class=header-social id=header-twitter><i class="ic fa-brands fa-twitter"></i></a>
<a href=https://www.reddit.com/user/Jemoka/ class=header-social id=header-reddit><i class="ic fa-brands fa-reddit"></i></a></div></header><div id=title><h1>Yuan 2021</h1></div><aside id=toc><h1 id=toc-title>table of contents</h1><nav id=TableOfContents><ul><li><a href=#one-liner>One-Liner</a></li><li><a href=#novelty>Novelty</a></li><li><a href=#notable-methods>Notable Methods</a></li><li><a href=#key-figs>Key Figs</a><ul><li><a href=#fig-1>Fig 1</a></li><li><a href=#table-1>Table 1</a></li><li><a href=#figure-5>Figure 5</a></li></ul></li><li><a href=#new-concepts>New Concepts</a></li><li><a href=#notes>Notes</a></li></ul></nav></aside><main><article><div><p>DOI: 10.3389/fcomp.2020.624488</p><h2 id=one-liner>One-Liner</h2><p>Used an ERNIE trained on transcripts for classification; inclusion of pause encoding made results better.</p><h2 id=novelty>Novelty</h2><ul><li>Instead of just looking at actual speech content, look at pauses specific as a feature engineering task</li><li>\(89.6\%\) on the <a href=/posts/kbhadress_challenge/>ADReSS Challenge</a> dataset</li></ul><h2 id=notable-methods>Notable Methods</h2><figure><img src=/ox-hugo/2022-06-24_20-45-47_screenshot.png></figure><p>Applied FA with pause encoding with standard <code>.cha</code> semantics (short pauses, medium pauses, long pauses). Shoved all of this into an ERNIE.</p><p>Assay for performance was <a href=/posts/kbhloo/>LOO</a></p><h2 id=key-figs>Key Figs</h2><h3 id=fig-1>Fig 1</h3><figure><img src=/ox-hugo/2022-06-24_20-43-43_screenshot.png></figure><p>This figure motivates the point that subjects with AD says oh and um more often; which prompted Table 1</p><h3 id=table-1>Table 1</h3><figure><img src=/ox-hugo/2022-06-24_20-44-31_screenshot.png></figure><p>Subjects with AD says uh a lot more often; no <a href=/posts/kbhhypothesis_testing/#significance-level>significance level</a> calculations but ok.</p><h3 id=figure-5>Figure 5</h3><figure><img src=/ox-hugo/2022-06-24_20-55-10_screenshot.png></figure><p>This figure is the result of a <a href=/posts/kbhloo/>LOO</a> study on the proposed model and presumably others before. X axis is the validation accuracy in question, Y is the density by which the score in X appears in an \(N=35\) <a href=/posts/kbhloo/>LOO</a> measurement.</p><p>This figure tells us that either way the ERNIE model is better than state of the art; furthermore, transcripts with pause encoding did better and did it better more of the time; that&rsquo;s where the 89.6% came from.</p><h2 id=new-concepts>New Concepts</h2><ul><li><a href=/posts/kbhloo/>Leave-One-Out cross validation</a></li></ul><h2 id=notes>Notes</h2><p>Glorious.</p><figure><img src=/ox-hugo/2022-06-24_20-41-41_screenshot.png></figure></div></article></main><footer><p id=footer>&copy; 2019-2022 Houjun Liu. Licensed CC BY-NC-SA 4.0.</p></footer></body></html>