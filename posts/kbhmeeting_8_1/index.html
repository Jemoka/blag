<!doctype html><html lang=en-us><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Commissioner:wght@100;300;400;500;700&family=IBM+Plex+Sans:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css integrity="sha512-KfkfwYDsLkIlwQp6LFnl8zNdLGxu9YAA1QvwINks4PhcElQSvqcyVLLD9aMhXd13uQjoXtEKNosOWaZqXgel0g==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Jost:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>window.MathJax={loader:{load:["[tex]/physics"]},tex:{packages:{"[+]":["physics"]}}}</script><title>meeting 8/1</title>
<meta name=description content="Updates dropping dropout: https://proceedings.mlr.press/v202/geiping23a/geiping23a.pdf CAW-coref: revised! do we need more space for things such as a figure? stanza 1.9.0 staged! https://huggingface.co/stanfordnlp/stanza-en Yay mend works! .mean() vs. .sum() for the dW maps?
PPL Isn&rsquo;t the Only Possible Metric even if our model is better ppl, its worse at squad than Facebook (granted its been trained a lot less); will run with new pretraining model (expect that no dropout will be better (see paper above))."><meta name=author content="Houjun Liu"><link rel=stylesheet href=/css/global.css><link rel=stylesheet href=/css/syntax.css></head><body><div class=center-clearfix><header><span id=header-name onclick='window.location.href="/"' style=cursor:pointer>Houjun Liu</span><div id=socialpanel><a href=https://www.jemoka.com/search/ class=header-social id=header-search><i class="ic fa-solid fa-magnifying-glass"></i></i></a>
<a href=https://github.com/Jemoka/ class=header-social id=header-github><i class="ic fa-brands fa-github"></i></a>
<a href=https://maly.io/@jemoka class=header-social id=header-twitter><i class="ic fa-brands fa-mastodon"></i></a>
<a href=https://www.reddit.com/user/Jemoka/ class=header-social id=header-reddit><i class="ic fa-brands fa-reddit"></i></a></div></header><div id=title><h1>meeting 8/1</h1><span class=tagbox></span></div><aside id=toc><h1 id=toc-title>table of contents</h1><nav id=TableOfContents><ul><li><a href=#updates>Updates</a><ul><li><a href=#yay-mend-works>Yay mend works!</a></li><li><a href=#ppl-isn-t-the-only-possible-metric>PPL Isn&rsquo;t the Only Possible Metric</a></li><li><a href=#pretraining-updates--smaller-bert-which-dataset>Pretraining Updates (smaller Bert, which dataset?)</a></li><li><a href=#binary-masking-with-the-pretraining-above>Binary Masking with the Pretraining Above</a></li></ul></li><li><a href=#question>Question</a><ul><li><a href=#paper-plan>Paper Plan</a></li><li><a href=#casual-interventions>Casual Interventions</a></li></ul></li></ul></nav></aside><main><article><div><h2 id=updates>Updates</h2><ul><li>dropping dropout: <a href=https://proceedings.mlr.press/v202/geiping23a/geiping23a.pdf>https://proceedings.mlr.press/v202/geiping23a/geiping23a.pdf</a></li><li>CAW-coref: revised! do we need more space for things such as a figure?<ul><li>stanza 1.9.0 staged! <a href=https://huggingface.co/stanfordnlp/stanza-en>https://huggingface.co/stanfordnlp/stanza-en</a></li></ul></li></ul><h3 id=yay-mend-works>Yay mend works!</h3><figure><img src=/ox-hugo/2024-08-01_14-11-07_screenshot.png></figure><p>.mean() vs. .sum() for the dW maps?</p><h3 id=ppl-isn-t-the-only-possible-metric>PPL Isn&rsquo;t the Only Possible Metric</h3><figure><img src=/ox-hugo/2024-08-01_15-12-14_screenshot.png></figure><p>even if our model is better ppl, its worse at squad than Facebook (granted its been trained a lot less); will run with new pretraining model (expect that no dropout will be better (see paper above)).</p><h3 id=pretraining-updates--smaller-bert-which-dataset>Pretraining Updates (smaller Bert, which dataset?)</h3><p><a href="https://wandb.ai/jemoka/dropfree?nw=nwuserjemoka">https://wandb.ai/jemoka/dropfree?nw=nwuserjemoka</a></p><h3 id=binary-masking-with-the-pretraining-above>Binary Masking with the Pretraining Above</h3><p>Edit success</p><table><thead><tr><th></th><th>Our Bert (No Dropout)</th><th>Our Bert (Dropout)</th></tr></thead><tbody><tr><td>edit success</td><td>0.9709</td><td>0.9723</td></tr><tr><td>edit localization</td><td>0.8375</td><td>0.8452</td></tr><tr><td>mean activations</td><td>3853</td><td>22511</td></tr></tbody></table><p>Yay! (more seriously)</p><h2 id=question>Question</h2><h3 id=paper-plan>Paper Plan</h3><h4 id=part-1-skipping-dropout-isn-t-bad-and-may-even-be-good>Part 1: Skipping Dropout isn&rsquo;t bad, and may even be good</h4><ul><li>pretraining</li><li>squad</li><li>consistency (this is weak, hence theory maybe helpful, or we can skip)</li></ul><h4 id=part-3-emperics-dropout-has-knowledge-storage-consiquences>Part 3: Emperics: Dropout Has Knowledge Storage Consiquences</h4><ul><li>knowledge neurons</li><li>integrated gradients</li><li>binary masking</li></ul><h4 id=part-4-impact-look-editing-is-easier-without-dropout--no-data-yet>Part 4: Impact: look, editing is easier without dropout (no data yet)</h4><ul><li><p>MEND (just worked yay!)</p></li><li><p>Finetune (echo to squad)</p></li><li><p>LoRA</p><p>slowly reduce ReFT update rank, see how edit success drops</p></li></ul><p>(x verbs y)</p><ul><li>for each, train/(MEND infer) on 90%, test on the other 10%, see if it works<ul><li>&ldquo;correct&rdquo; to the {IID} example</li></ul></li></ul><h3 id=casual-interventions>Casual Interventions</h3><p>shall we? simple exchange interaction? how does it work for a bert? does it fit into this story?</p><p>(ottowa captial &lt;mask>)
=>
(DC capital &lt;mask>)</p></div></article></main><footer><p id=footer>&copy; 2019-2024 Houjun Liu. Licensed CC BY-NC-SA 4.0.</p></footer></div></body></html>