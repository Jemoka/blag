<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Commissioner:wght@100;300;400;500;700&family=IBM+Plex+Sans:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css integrity="sha512-KfkfwYDsLkIlwQp6LFnl8zNdLGxu9YAA1QvwINks4PhcElQSvqcyVLLD9aMhXd13uQjoXtEKNosOWaZqXgel0g==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script>
<link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Jost:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script>
<script>window.MathJax={loader:{load:["[tex]/physics"]},tex:{packages:{"[+]":["physics"]}}}</script><title>probability</title><meta name=description content="probability of an event is the proportion of times the event occurs in many repeated trials.
axiom of probability \(0 \leq P(E) \leq 1\) \(P(S) = 1\), where \(S\) is the sample space if \(E\) and \(F\) are mutually exclusive, \(P(E) + P(F) = P(E \cup F)\) This results in three correlaries:
\(P(E^{C}) = 1- P(E)\) \(P(E \cup F) = P(E) + P(F) - P(E \cap F)\) if \(E \subset F\), \(P(E) \leq P(F)\) conditional probability \begin{equation} P (X, Y ) = P(X\mid Y) \cdot P(Y) \end{equation}"><meta name=author content="Houjun Liu"><link rel=stylesheet href=/css/global.css><link rel=stylesheet href=/css/syntax.css></head><body><div class=center-clearfix><header><span id=header-name onclick='window.location.href="/"' style=cursor:pointer>Houjun Liu</span><div id=socialpanel><a href=https://www.jemoka.com/search/ class=header-social id=header-search><i class="ic fa-solid fa-magnifying-glass"></i></i></a>
<a href=https://github.com/Jemoka/ class=header-social id=header-github><i class="ic fa-brands fa-github"></i></a>
<a href=https://maly.io/@jemoka class=header-social id=header-twitter><i class="ic fa-brands fa-mastodon"></i></a>
<a href=https://www.reddit.com/user/Jemoka/ class=header-social id=header-reddit><i class="ic fa-brands fa-reddit"></i></a></div></header><div id=title><h1>probability</h1><span class=tagbox></span></div><aside id=toc><h1 id=toc-title>table of contents</h1><nav id=TableOfContents><ul><li><a href=#axiom-of-probability>axiom of probability</a></li><li><a href=#conditional-probability>conditional probability</a></li><li><a href=#law-of-total-probability>law of total probability</a></li><li><a href=#bayes-rule>Bayes rule</a></li><li><a href=#independence>independence</a></li></ul></nav></aside><main><article><div><p><a href=/posts/kbhprobability/>probability</a> of an event is the proportion of times the event occurs in many repeated trials.</p><h2 id=axiom-of-probability>axiom of probability</h2><ul><li>\(0 \leq P(E) \leq 1\)</li><li>\(P(S) = 1\), where \(S\) is the sample space</li><li>if \(E\) and \(F\) are mutually exclusive, \(P(E) + P(F) = P(E \cup F)\)</li></ul><hr><p>This results in three correlaries:</p><ul><li>\(P(E^{C}) = 1- P(E)\)</li><li>\(P(E \cup F) = P(E) + P(F) - P(E \cap F)\)</li><li>if \(E \subset F\), \(P(E) \leq P(F)\)</li></ul><h2 id=conditional-probability>conditional probability</h2><p>\begin{equation}
P (X, Y ) = P(X\mid Y) \cdot P(Y)
\end{equation}</p><p>In this case, we call \(Y\) the &ldquo;evidence&rdquo;. this allows us to find &ldquo;what is the chance of \(x\) given \(y\)&rdquo;.</p><p>\begin{equation}
\sum_{x}^{} p(x \mid y) = 1
\end{equation}</p><p>because this is <strong>still</strong> a probability over \(x\).</p><h2 id=law-of-total-probability>law of total probability</h2><p>say you have two variables \(x, y\).</p><p>&ldquo;what&rsquo;s the probablity of \(x\)&rdquo;</p><p>\begin{equation}
P(x) = \sum_{Y} P(x,y)
\end{equation}</p><p>a.k.a.:</p><p>\begin{equation}
p(x) = p(x|y_1)p(y_1) + \dots + p(x|y_{n})y_{n}
\end{equation}</p><p>by applying <a href=#conditional-probability>conditional probability</a> formula upon each term</p><h2 id=bayes-rule>Bayes rule</h2><p>See: <a href=/posts/kbhbayes_theorem/#bayes-theorem>Bayes Theorem</a></p><h2 id=independence>independence</h2><p>If \(X\) and \(Y\) are independent (written as \(X \perp Y\)), we know that \(P(x,y) = P(x)P(y)\) for all \(x, y\).</p></div></article></main><footer><p id=footer>&copy; 2019-2023 Houjun Liu. Licensed CC BY-NC-SA 4.0.</p></footer></div></body></html>