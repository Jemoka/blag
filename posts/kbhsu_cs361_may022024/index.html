<!doctype html><html lang=en-us><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Commissioner:wght@100;300;400;500;700&family=IBM+Plex+Sans:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css integrity="sha512-KfkfwYDsLkIlwQp6LFnl8zNdLGxu9YAA1QvwINks4PhcElQSvqcyVLLD9aMhXd13uQjoXtEKNosOWaZqXgel0g==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Jost:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>window.MathJax={loader:{load:["[tex]/physics"]},tex:{packages:{"[+]":["physics"]}}}</script><title>SU-CS361 MAY022024</title>
<meta name=description content="Preference Elicitation For the Weight Method, for instance, we need to figure a \(w\) such that:
\begin{equation} f = w^{\top}\mqty[f_1 \\ \dots\\f_{N}] \end{equation}
where weight \(w \in \triangle_{N}\).
To do this, we essentially infer the weighting scheme by asking &ldquo;do you like system \(a\) or system \(b\)&rdquo;.
first, we collect a series of design variables \((a_1, a_2, a_3 &mldr;)\) and \((b_1, b_2, b_3&mldr;)\) and we ask &ldquo;which one do you like better&rdquo; say our user WLOG chose \(b\) over \(a\) so we want to design a \(w\) such that \(w^{\top} a < w^{\top} b\) meaning, we solve for a \(w\) such that&mldr; \begin{align} \min_{w}&\ \sum_{i=1}^{n} (a_{i}-b_{i})w^{\top} \\ \text{such that}&\ \bold{1}^{\top} w = 1 \\ &\ w \geq 0 \end{align}"><meta name=author content="Houjun Liu"><link rel=stylesheet href=/css/global.css><link rel=stylesheet href=/css/syntax.css></head><body><div class=center-clearfix><header><span id=header-name onclick='window.location.href="/"' style=cursor:pointer>Houjun Liu</span><div id=socialpanel><a href=https://www.jemoka.com/search/ class=header-social id=header-search><i class="ic fa-solid fa-magnifying-glass"></i></i></a>
<a href=https://github.com/Jemoka/ class=header-social id=header-github><i class="ic fa-brands fa-github"></i></a>
<a href=https://maly.io/@jemoka class=header-social id=header-twitter><i class="ic fa-brands fa-mastodon"></i></a>
<a href=https://www.reddit.com/user/Jemoka/ class=header-social id=header-reddit><i class="ic fa-brands fa-reddit"></i></a></div></header><div id=title><h1>SU-CS361 MAY022024</h1><span class=tagbox></span></div><aside id=toc><h1 id=toc-title>table of contents</h1><nav id=TableOfContents><ul><li><a href=#preference-elicitation>Preference Elicitation</a></li><li><a href=#sampling-plans>Sampling Plans</a><ul><li><a href=#full-factorial>Full Factorial</a></li><li><a href=#random-sampling>Random Sampling</a></li><li><a href=#uniform-projection>Uniform Projection</a></li><li><a href=#stratified-sampling>Stratified Sampling</a></li></ul></li><li><a href=#space-filling-metrics>Space-Filling Metrics</a><ul><li><a href=#pairwise-distances>Pairwise Distances</a></li><li><a href=#morris-mitchell>Morris-Mitchell</a></li><li><a href=#space-filling-subset>Space-Filling Subset</a></li></ul></li><li><a href=#surrogate-models>Surrogate Models</a><ul><li><a href=#linear-model>Linear Model</a></li><li><a href=#basis-functions>Basis Functions</a></li><li><a href=#regularization--kbhsu-cs224n-apr162024-dot-md><a href=HAHAHUGOSHORTCODE1277s2HBHB>Regularization</a></a></li></ul></li></ul></nav></aside><main><article><div><h2 id=preference-elicitation>Preference Elicitation</h2><p>For the <a href=/posts/kbhsu_cs361_apr302024/#weight-method>Weight Method</a>, for instance, we need to figure a \(w\) such that:</p><p>\begin{equation}
f = w^{\top}\mqty[f_1 \\ \dots\\f_{N}]
\end{equation}</p><p>where weight \(w \in \triangle_{N}\).</p><p>To do this, we essentially infer the weighting scheme by asking &ldquo;do you like system \(a\) or system \(b\)&rdquo;.</p><ol><li>first, we collect a series of design variables \((a_1, a_2, a_3 &mldr;)\) and \((b_1, b_2, b_3&mldr;)\) and we ask &ldquo;which one do you like better&rdquo;</li><li>say our user WLOG chose \(b\) over \(a\)</li><li>so we want to design a \(w\) such that \(w^{\top} a &lt; w^{\top} b\)</li><li>meaning, we solve for a \(w\) such that&mldr;</li></ol><p>\begin{align}
\min_{w}&\ \sum_{i=1}^{n} (a_{i}-b_{i})w^{\top} \\
\text{such that}&\ \bold{1}^{\top} w = 1 \\
&\ w \geq 0
\end{align}</p><p><strong>unlike the rest of everything, we are MAXIMIZING here</strong> idk why</p><h2 id=sampling-plans>Sampling Plans</h2><p>Many methods requires knowing a series of samples of the objective value to calculate local model or population methods, so&mldr;</p><h3 id=full-factorial>Full Factorial</h3><p>Grid it up.</p><ul><li>easy to implement</li><li>good results</li><li>bad: sample count grows exponentially with dimension</li></ul><h3 id=random-sampling>Random Sampling</h3><p>Use a pseudorandom generator to pick points in your space.</p><ul><li>allows for any number of evaluations you specify</li><li>statistically, <strong>the points clump</strong> when you do this!</li><li>also need lots of samples to get good coverage</li></ul><h3 id=uniform-projection>Uniform Projection</h3><p>We take each point, and uniformly project it onto each dimension. To implement this, we grid up each dimension and shuffle the ordering of each dimension individually. Then, we read off the coordinates to create the points:</p><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># in d3...</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#111>seq</span> <span style=color:#f92672>=</span> <span style=color:#111>range</span><span style=color:#111>(</span><span style=color:#111>axis_min</span><span style=color:#111>,</span> <span style=color:#111>axis_max</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#111>d1</span> <span style=color:#f92672>=</span> <span style=color:#111>random</span><span style=color:#f92672>.</span><span style=color:#111>shuffle</span><span style=color:#111>(</span><span style=color:#111>seq</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span><span style=color:#111>d2</span> <span style=color:#f92672>=</span> <span style=color:#111>random</span><span style=color:#f92672>.</span><span style=color:#111>shuffle</span><span style=color:#111>(</span><span style=color:#111>seq</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span><span style=color:#111>d3</span> <span style=color:#f92672>=</span> <span style=color:#111>random</span><span style=color:#f92672>.</span><span style=color:#111>shuffle</span><span style=color:#111>(</span><span style=color:#111>seq</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#111>sampling_points</span> <span style=color:#f92672>=</span> <span style=color:#111>zip</span><span style=color:#111>(</span><span style=color:#111>d1</span><span style=color:#111>,</span> <span style=color:#111>d2</span><span style=color:#111>,</span> <span style=color:#111>d3</span><span style=color:#111>)</span>
</span></span></code></pre></div><h3 id=stratified-sampling>Stratified Sampling</h3><ul><li>perform <a href=#uniform-projection>Uniform Projection</a></li><li>within each grid, make smaller grids and perform within them <a href=#uniform-projection>Uniform Projection</a> again</li></ul><h2 id=space-filling-metrics>Space-Filling Metrics</h2><h3 id=pairwise-distances>Pairwise Distances</h3><p>This requires each set to have the <strong>same number of points</strong></p><ul><li>figure the euclidian distance between every pair of points</li><li>for each set of pairs, figure the closest together points, and call that the &ldquo;pairwise distance&rdquo; of the set</li></ul><p>Limitation: if there are just two points that are close together, this metric scores it worse. So maybe <a href=#morris-mitchell>Morris-Mitchell</a>.</p><h3 id=morris-mitchell>Morris-Mitchell</h3><p>We have a hype-parameter \(q\), which checks all of the possible norms to use between points. Consider \(d_{i}\) to be the ith-pairwise distance between the points with the <a href=/posts/kbhlp_norm/>Lp Norm</a> for your choice of \(p\). Then, for:</p><p>\begin{equation}
\Phi_{q}(X) = \qty(\sum_{i}^{}d_{i}^{-q})^{\frac{1}{q}}
\end{equation}</p><p>and we try to solve for our set of points \(X\) such that:</p><p>\begin{equation}
\min_{X} \max_{q \in \{1,2,5,10,20,50,100\}} \Phi_{q}(X)
\end{equation}</p><p>&ldquo;minimize the distance at the worst \(q\) possible norm&rdquo;</p><h3 id=space-filling-subset>Space-Filling Subset</h3><p>A <a href=#space-filling-subset>Space-Filling Subset</a> is a subset \(S\) of a point set \(X\) which <strong>minimizes the maximum distance</strong> between a point in \(S\) and its closest point in \(X\) (i.e. making \(S\) a good representative of \(X\)).</p><p>\begin{equation}
d_{\max}(X,S) = \max_{x \in X} \min_{s \in S} |s -x|_{p}
\end{equation}</p><p>we can choose any \(p\) norm you&rsquo;d like.</p><h4 id=greedy-local-search>greedy local search</h4><p>Choosing one best point to add to \(S\) which maximize \(d_{\max}\), and then choose another point, and another one, &mldr;</p><h4 id=exchange-algorithm>exchange algorithm</h4><p>randomly initialize \(S\), and swap points within \(S\) and only in \(X\)</p><h2 id=surrogate-models>Surrogate Models</h2><p>Once we finished sampling, we need to create a model parameterized by \(\theta\) which minimizes the error. In particular, we want to choose \(\theta\) such that:</p><p>\begin{equation}
\min_{\theta} |y - \hat{y}|_{p}
\end{equation}</p><p>for some model \(\hat{y}(x)\), with matching actual result \(y\).</p><h3 id=linear-model>Linear Model</h3><p>\begin{equation}
\hat{f} = w_0 + \bold{w}^{\top}\bold{x}
\end{equation}</p><p>whereby, we now want:</p><p>\begin{equation}
\min_{\theta} |y - X \theta|_{2}^{2}
\end{equation}</p><p>this is CLOSE FORM! by applying the pseudo-inverse:</p><p>\begin{equation}
\theta = X^{\dagger} y
\end{equation}</p><h3 id=basis-functions>Basis Functions</h3><p>We can make this slighlty non-linear by computing some non-zero \(B(x)\) where a set of these basis functions all taking \(x\) as input (for instance, terms of a polynomial) \(\bold{B}(\bold{x})\) is then used for optimization:</p><p>\begin{equation}
\min_{\theta} |y - B \theta|_{2}^{2}
\end{equation}</p><h4 id=radial-basis-functions>Radial Basis Functions</h4><p>\begin{equation}
\psi(x,c) = \psi(|x - c|)
\end{equation}</p><p>a radial basis function is a basis function that acts on the <em>distance</em> to a local point. You can choose any kernel \(\psi\) you&rsquo;d like.</p><h3 id=regularization--kbhsu-cs224n-apr162024-dot-md><a href=/posts/kbhsu_cs224n_apr162024/#regularization>Regularization</a></h3><p>Especially for noisy things, you ideally want some kind of regularization: see <a href=/posts/kbhsu_cs224n_apr162024/#regularization>Regularization</a></p><h4 id=l2-regularization>L2 Regularization</h4><p>\begin{equation}
\min_{\theta} || y - B(x)\theta ||_{2}^{2} + \lambda || \theta ||^{2}_{2}
\end{equation}</p><p>this is kind of a like a multi-objective <a href=/posts/kbhsu_cs361_apr302024/#weight-method>Weight Method</a>.</p></div></article></main><footer><p id=footer>&copy; 2019-2024 Houjun Liu. Licensed CC BY-NC-SA 4.0.</p></footer></div></body></html>