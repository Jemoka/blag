<!doctype html><html lang=en-us><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Commissioner:wght@100;300;400;500;700&family=IBM+Plex+Sans:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css integrity="sha512-Evv84Mr4kqVGRNSgIGL/F/aIDqQb7xQ2vcrdIwxfjThSH8CSR7PBEakCr51Ck+w+/U6swU2Im1vVX0SVk9ABhg==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Jost:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>window.MathJax={loader:{load:["[tex]/physics"]},tex:{packages:{"[+]":["physics"]}}}</script><title>probability distribution</title>
<meta name=description content="probability distributions &ldquo;assigns probability to outcomes&rdquo;
\(X\) follows distribution \(D\). \(X\) is a &ldquo;\(D\) random variable&rdquo;, where \(D\) is some distribution (normal, gaussian, etc.)
syntax: \(X \sim D\).
Each distribution has three properties:

variables (what is being modeled)
values (what values can they take on)
parameters (how many degrees of freedom do we have)

Types of Distribution
discrete distribution

described by PMF

continuous distribution

described by PDF

parametrized distribution
We often represent probability distribution using a set of parameters \(\theta_{j}\).  For instance, a normal distribution is given by \(\mu\) and \(\sigma\), and a PMF is by the probability mass for each."><meta name=author content="Houjun Liu"><link rel=stylesheet href=/css/global.css><link rel=stylesheet href=/css/syntax.css></head><body><div class=center-clearfix><header><span id=header-name onclick='window.location.href="/"' style=cursor:pointer>Houjun Liu</span><div id=socialpanel><a href=https://www.jemoka.com/search/ class=header-social id=header-search><i class="ic fa-solid fa-magnifying-glass"></i></i></a>
<a href=https://github.com/Jemoka/ class=header-social id=header-github><i class="ic fa-brands fa-github"></i></a>
<a href=https://bsky.app/profile/jemoka.com class=header-social id=header-twitter><i class="ic fa-brands fa-bluesky"></i></a>
<a href=https://www.reddit.com/user/Jemoka/ class=header-social id=header-reddit><i class="ic fa-brands fa-reddit"></i></a></div></header><div id=title><h1>probability distribution</h1><span class=tagbox></span></div><aside id=toc><h1 id=toc-title>table of contents</h1><nav id=TableOfContents><ul><li><a href=#types-of-distribution>Types of Distribution</a><ul><li><a href=#discrete-distribution--kbhdiscrete-distribution-dot-md><a href=HAHAHUGOSHORTCODE1131s2HBHB>discrete distribution</a></a></li><li><a href=#continuous-distribution--kbhcontinuous-distribution-dot-md><a href=HAHAHUGOSHORTCODE1131s4HBHB>continuous distribution</a></a></li></ul></li><li><a href=#parametrized-distribution>parametrized distribution</a></li><li><a href=#methods-of-compressing-the-parameters-of-a-distribution>Methods of Compressing the Parameters of a Distribution</a><ul><li><a href=#assuming-independence>assuming independence</a></li><li><a href=#decision-tree>decision tree</a></li><li><a href=#baysian-networks>Baysian networks</a></li></ul></li><li><a href=#types-of-probability-distributions>types of probability distributions</a></li><li><a href=#distribution-of-note>distribution of note</a><ul><li><a href=#uniform-distribution>uniform distribution</a></li><li><a href=#gaussian-things>Gaussian Things</a></li></ul></li><li><a href=#three-ways-of-analysis>three ways of analysis</a><ul><li><a href=#cumulative-distribution-function>cumulative distribution function</a></li><li><a href=#quantile-function>quantile function</a></li><li><a href=#adding-uniform-distribution--org6d62aae>adding <a href=#uniform-distribution>uniform distribution</a></a></li></ul></li></ul></nav></aside><main><article><div><p><a href=/posts/kbhprobability_distributions/>probability distributions</a> &ldquo;assigns probability to outcomes&rdquo;</p><p>\(X\) follows distribution \(D\). \(X\) is a &ldquo;\(D\) random variable&rdquo;, where \(D\) is some distribution (<a href=/posts/kbhaxler_7_a/#normal>normal</a>, gaussian, etc.)</p><p>syntax: \(X \sim D\).</p><p>Each distribution has three properties:</p><ul><li>variables (what is being modeled)</li><li>values (what values can they take on)</li><li>parameters (how many degrees of freedom do we have)</li></ul><h2 id=types-of-distribution>Types of Distribution</h2><h3 id=discrete-distribution--kbhdiscrete-distribution-dot-md><a href=/posts/kbhdiscrete_distribution/>discrete distribution</a></h3><ul><li>described by <a href=/posts/kbhprobability_mass_function/>PMF</a></li></ul><h3 id=continuous-distribution--kbhcontinuous-distribution-dot-md><a href=/posts/kbhcontinuous_distribution/>continuous distribution</a></h3><ul><li>described by <a href=/posts/kbhprobability_density_function/>PDF</a></li></ul><h2 id=parametrized-distribution>parametrized distribution</h2><p>We often represent probability distribution using a set of <a href=/posts/kbhparameter/>parameter</a>s \(\theta_{j}\). For instance, a <a href=/posts/kbhnormal_distribution/>normal distribution</a> is given by \(\mu\) and \(\sigma\), and a <a href=/posts/kbhprobability_mass_function/>PMF</a> is by the probability mass for each.</p><h2 id=methods-of-compressing-the-parameters-of-a-distribution>Methods of Compressing the Parameters of a Distribution</h2><p>So, for instance, for a binary distribution with \(n\) variables which we know nothing about, we have:</p><p>\begin{equation}
2^{n} - 1
\end{equation}</p><p>parameters (\(2^{n}\) different possibilities of combinations, and \(1\) non-free variables to ensure that the distribution add up)</p><h3 id=assuming-independence>assuming independence</h3><p>HOWEVER, if the variables were <a href=/posts/kbhprobability/#independence>independent</a>, this becomes much easier. Because the variables are independent, we can claim that:</p><p>\begin{equation}
p(x_{1\dots n}) = \prod_{i}^{} p(x_{i))
\end{equation}</p><h3 id=decision-tree>decision tree</h3><p>For instance, you can have a decision tree which you selectively ignore some combinations.</p><figure><img src=/ox-hugo/2023-09-28_10-13-07_screenshot.png></figure><p>In this case, we ignored \(z\) if both \(x\) and \(y\) are \(0\).</p><h3 id=baysian-networks>Baysian networks</h3><p>see <a href=/posts/kbhbaysian_network/>Baysian Network</a></p><h2 id=types-of-probability-distributions>types of probability distributions</h2><ul><li><a href=/posts/kbhdiscrete_distribution/>discrete distribution</a></li><li><a href=/posts/kbhcontinuous_distribution/>continuous distribution</a></li><li><a href=/posts/kbhjoint_probability_distribution/>joint probability distribution</a></li></ul><h2 id=distribution-of-note>distribution of note</h2><ul><li><a href=#uniform-distribution>uniform distribution</a></li><li>gaussian distributions<ul><li><a href=/posts/kbhgaussian_distribution/>Gaussian distribution</a></li><li><a href=#truncated-gaussian-distribution>Truncated Gaussian distribution</a></li><li></li></ul></li></ul><h3 id=uniform-distribution>uniform distribution</h3><p>\begin{equation}
X \sim Uni(\alpha, \beta)
\end{equation}</p><p>\begin{equation}
f(x) = \begin{cases}
\frac{1}{\beta -\alpha }, 0\leq x \leq 10 \\0
\end{cases}
\end{equation}</p><p>\begin{equation}
E[x] = \frac{1}{2}(\alpha +\beta)
\end{equation}</p><p>\begin{equation}
Var(X) = \frac{1}{12}(\beta -\alpha )^{2}
\end{equation}</p><h3 id=gaussian-things>Gaussian Things</h3><h4 id=truncated-gaussian-distribution>Truncated Gaussian distribution</h4><p>Sometimes, we don&rsquo;t want to use a <a href=/posts/kbhgaussian_distribution/>Gaussian distribution</a> for values above or below a threshold (say if they are physically impossible). In those cases, we have some:</p><p>\begin{equation}
X \sim N(\mu, \sigma^{2}, a, b)
\end{equation}</p><p>bounded within the interval of \((a,b)\). The <a href=/posts/kbhprobability_density_function/>PDF</a> of this function is given by:</p><p>\begin{equation}
N(\mu, \sigma^{2}, a, b) = \frac{\frac{1}{\sigma} \phi \qty(\frac{x-\mu }{\sigma })}{\Phi \qty(\frac{b-\mu }{\sigma }) - \Phi \qty(\frac{a-\mu}{\sigma})}
\end{equation}</p><p>where:</p><p>\begin{equation}
\Phi = \int_{-\infty}^{x} \phi (x&rsquo;) \dd{x&rsquo;}
\end{equation}</p><p>and where \(\phi\) is the <a href=/posts/kbhgaussian_distribution/#standard-normal-density-function>standard normal density function</a>.</p><h2 id=three-ways-of-analysis>three ways of analysis</h2><h3 id=cumulative-distribution-function>cumulative distribution function</h3><p>What is the probability that a <a href=/posts/kbhrandom_variables/>random variable</a> takes on value less tha</p><p>\begin{equation}
cdf_{x}(x) = P(X&lt;x) = \int_{-\infty}^{x} p(x&rsquo;) dx'
\end{equation}</p><p>sometimes written as:</p><p>\begin{equation}
F(x) = P(X &lt; x)
\end{equation}</p><p>Recall that, with</p><h3 id=quantile-function>quantile function</h3><p>\begin{equation}
\text{quantile}_{X}(\alpha)
\end{equation}</p><p>is the value \(x\) such that:</p><p>\begin{equation}
P(X \leq x) = \alpha
\end{equation}</p><p>That is, the <a href=#quantile-function>quantile function</a> returns the minimum value of \(x\) at which point a certain <a href=#cumulative-distribution-function>cumulative distribution</a> value desired is achieved.</p><h3 id=adding-uniform-distribution--org6d62aae>adding <a href=#uniform-distribution>uniform distribution</a></h3><p>for \(1 &lt; a &lt; 2\)</p><p>\begin{equation}
f(X+Y = a) =
\begin{cases}
a, 0 &lt; a &lt; 1, \\
2-a, 1 &lt; a &lt; 2, \\
0, otherwise
\end{cases}
\end{equation}</p></div></article></main><footer><p id=footer>&copy; 2019-2025 Houjun Liu. Licensed CC BY-NC-SA 4.0.</p></footer></div></body></html>