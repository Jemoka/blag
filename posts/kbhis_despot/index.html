<!doctype html><html lang=en-us><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Commissioner:wght@100;300;400;500;700&family=IBM+Plex+Sans:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css integrity="sha512-Evv84Mr4kqVGRNSgIGL/F/aIDqQb7xQ2vcrdIwxfjThSH8CSR7PBEakCr51Ck+w+/U6swU2Im1vVX0SVk9ABhg==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Jost:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>window.MathJax={loader:{load:["[tex]/physics"]},tex:{packages:{"[+]":["physics"]}}}</script><title>IS-DESPOT</title>
<meta name=description content="Motivation
Large crowd navigation with sudden changes: unlikely events are out of likely sample. So, we want to bring in another distribution based on importance and not likelyness.
Goals

retains DESPOT garantees
outperforms DESPOT and POMCP

DESPOT with Importance Sampling

take our initial belief
sample trajectories according to Importance Sampling distribution
calculate values of those states
obtain value estimate based on weighted average of the values

Importance Sampling of trajectories
We define an importance distribution of some trajectory \(\xi\):"><meta name=author content="Houjun Liu"><link rel=stylesheet href=/css/global.css><link rel=stylesheet href=/css/syntax.css></head><body><div class=center-clearfix><header><span id=header-name onclick='window.location.href="/"' style=cursor:pointer>Houjun Liu</span><div id=socialpanel><a href=https://www.jemoka.com/search/ class=header-social id=header-search><i class="ic fa-solid fa-magnifying-glass"></i></i></a>
<a href=https://github.com/Jemoka/ class=header-social id=header-github><i class="ic fa-brands fa-github"></i></a>
<a href=https://bsky.app/profile/jemoka.com class=header-social id=header-twitter><i class="ic fa-brands fa-bluesky"></i></a>
<a href=https://www.reddit.com/user/Jemoka/ class=header-social id=header-reddit><i class="ic fa-brands fa-reddit"></i></a></div></header><div id=title><h1>IS-DESPOT</h1><span class=tagbox></span></div><aside id=toc><h1 id=toc-title>table of contents</h1><nav id=TableOfContents><ul><li><a href=#motivation>Motivation</a></li><li><a href=#goals>Goals</a></li><li><a href=#despot--kbhdespot-dot-md--with-importance-sampling--org7062454><a href=HAHAHUGOSHORTCODE630s2HBHB>DESPOT</a> with <a href=#importance-sampling>Importance Sampling</a></a><ul><li><a href=#importance-sampling--org7062454--of-trajectories><a href=#importance-sampling>Importance Sampling</a> of trajectories</a></li></ul></li><li><a href=#background>Background</a><ul><li><a href=#importance-sampling>Importance Sampling</a></li></ul></li></ul></nav></aside><main><article><div><h2 id=motivation>Motivation</h2><p>Large crowd navigation with sudden changes: unlikely events are out of likely sample. So, we want to bring in another distribution based on <strong>importance</strong> and not <strong>likelyness</strong>.</p><h2 id=goals>Goals</h2><ul><li>retains DESPOT garantees</li><li>outperforms <a href=/posts/kbhdespot/>DESPOT</a> and <a href=/posts/kbhpomcp/>POMCP</a></li></ul><h2 id=despot--kbhdespot-dot-md--with-importance-sampling--org7062454><a href=/posts/kbhdespot/>DESPOT</a> with <a href=#importance-sampling>Importance Sampling</a></h2><ol><li>take our initial belief</li><li>sample trajectories according to <a href=#importance-sampling>Importance Sampling</a> distribution</li><li>calculate values of those states</li><li>obtain value estimate based on weighted average of the values</li></ol><h3 id=importance-sampling--org7062454--of-trajectories><a href=#importance-sampling>Importance Sampling</a> of trajectories</h3><p>We define an <a href=#importance-sampling>importance distribution</a> of some trajectory \(\xi\):</p><p>\begin{equation}
q(\xi | b,\pi) = q(s_0) \prod_{t=0}^{D} q(s_{t+1}, o_{t+1} | s_{t}, a_{t+1})
\end{equation}</p><h2 id=background>Background</h2><h3 id=importance-sampling>Importance Sampling</h3><p>Suppose you have a function \(f(s)\) which isn&rsquo;t super well integrate-able, yet you want:</p><p>\begin{equation}
\mu = \mathbb{E}(f(s)) = \int_{0}^{1} f(s)p(s) \dd{s}
\end{equation}</p><p>how would you sample various \(f(s)\) effectively such that you end up with \(\hat{\mu}\) that&rsquo;s close enough?</p><p>Well, what if you have an <a href=#importance-sampling>importance distribution</a> \(q(s): S \to \mathbb{R}^{[0,1]}\), which tells you how &ldquo;important&rdquo; to the expected value of the distribution a particular state is? Then, we can formulate a new, better normalization function called the &ldquo;<a href=#importance-sampling>importance weight</a>&rdquo;:</p><p>\begin{equation}
w(s) = \frac{p(s)}{q(s)}
\end{equation}</p><p>Therefore, this would make our estimator:</p><p>\begin{equation}
\hat{\mu} = \frac{\sum_{n} f(s_{n}) w(s_{n})}{\sum_{n} w(s_{n})}
\end{equation}</p><h4 id=theoretic-grantees>Theoretic grantees</h4><p>So, there&rsquo;s a distribution over \(f\):</p><p>\begin{equation}
q(s) = \frac{b(s)}{w_{\pi}(s)}
\end{equation}</p><p>where</p><p>\begin{equation}
w(s) = \frac{\mathbb{E}_{b} \qty( \sqrt{[\mathbb{E}(v|s, \pi )]^{2} + [Var(v|s, \pi )]})}{[\mathbb{E}(v|s, \pi )]^{2} + [Var(v|s, \pi )]}
\end{equation}</p><p>which measures how important a state is, where \(\pi\) is the total discounted reward.</p></div></article></main><footer><p id=footer>&copy; 2019-2025 Houjun Liu. Licensed CC BY-NC-SA 4.0.</p></footer></div></body></html>