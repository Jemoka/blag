<!doctype html><html lang=en-us><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Commissioner:wght@100;300;400;500;700&family=IBM+Plex+Sans:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css integrity="sha512-Evv84Mr4kqVGRNSgIGL/F/aIDqQb7xQ2vcrdIwxfjThSH8CSR7PBEakCr51Ck+w+/U6swU2Im1vVX0SVk9ABhg==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Jost:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>window.MathJax={loader:{load:["[tex]/physics"]},tex:{packages:{"[+]":["physics"]}}}</script><title>Basics of ML for 224n</title>
<meta name=description content="Random thoughts as I scan through the book:
Central framing: learning as a means to generalize + predict
Key Tasks

regression (predict a value)
binary classification (sort an example into a boolean class of Y/N)
multi-class classification (sort an example into multiple classes)
ranking (sorting an object into relevant order)

Optimality of Bayes Optimal Classifier
If you have the underlying data distribution, we can classify \(y\) from \(x\) by choosing:"><meta name=author content="Houjun Liu"><link rel=stylesheet href=/css/global.css><link rel=stylesheet href=/css/syntax.css></head><body><div class=center-clearfix><header><span id=header-name onclick='window.location.href="/"' style=cursor:pointer>Houjun Liu</span><div id=socialpanel><a href=https://www.jemoka.com/search/ class=header-social id=header-search><i class="ic fa-solid fa-magnifying-glass"></i></i></a>
<a href=https://github.com/Jemoka/ class=header-social id=header-github><i class="ic fa-brands fa-github"></i></a>
<a href=https://bsky.app/profile/jemoka.com class=header-social id=header-twitter><i class="ic fa-brands fa-bluesky"></i></a>
<a href=https://www.reddit.com/user/Jemoka/ class=header-social id=header-reddit><i class="ic fa-brands fa-reddit"></i></a></div></header><div id=title><h1>Basics of ML for 224n</h1><span class=tagbox></span></div><aside id=toc><h1 id=toc-title>table of contents</h1><nav id=TableOfContents><ul><li><a href=#key-tasks>Key Tasks</a></li><li><a href=#optimality-of-bayes-optimal-classifier>Optimality of Bayes Optimal Classifier</a></li><li><a href=#decision-tree>Decision Tree</a></li><li><a href=#bias>Bias</a><ul><li><a href=#inductive-bias>Inductive Bias</a></li><li><a href=#so-true>So true</a></li><li><a href=#sooo-true>Sooo true</a></li></ul></li><li><a href=#perception>Perception</a><ul><li><a href=#perception-convergence>Perception Convergence</a></li></ul></li></ul></nav></aside><main><article><div><p>Random thoughts as I scan through the book:</p><p>Central framing: learning as a means to <strong>generalize</strong> + <strong>predict</strong></p><h2 id=key-tasks>Key Tasks</h2><ul><li>regression (predict a value)</li><li>binary classification (sort an example into a boolean class of Y/N)</li><li>multi-class classification (sort an example into multiple classes)</li><li>ranking (sorting an object into relevant order)</li></ul><h2 id=optimality-of-bayes-optimal-classifier>Optimality of Bayes Optimal Classifier</h2><p>If you have the underlying data distribution, we can classify \(y\) from \(x\) by choosing:</p><p>\begin{equation}
f(x) = \arg\max_{y \in Y} P(x, y)
\end{equation}</p><p>where \(P(a,b)\) is the probability of \(a,b\) pain on the data \(D\); but like you don&rsquo;t have the probability distributed over \(D\), so sadge.</p><p>Optimality:</p><p>assume for contradiction \(\exists\) some \(g\) which works better than \(f\), meaning \(\exists x: g(x) \neq f(x)\). The error rate of \(f\) on \(x\) is \(1-P(x, f(x))\), of \(g\) is \(1-P(x, g(x))\). Yet, \(P(x,f(x))\) is maximized by definition of \(f\), so \(1-P(x, f(x)) \leq 1-P(x,g(x))\), meaning, \(P(x,g(x)) \leq P(x,f(x))\); recall \(P\) is the distribution on actual data so \(g\) is worse than \(f\), reaching contradiction. \(\blacksquare\)</p><h2 id=decision-tree>Decision Tree</h2><p>Its usually presented in terms of Gini impurity in a multi-class setting; as in the &ldquo;score&rdquo; is formalized as &ldquo;Gini Purity&rdquo;:</p><p>\begin{equation}
G_{f} = \sum_{j=1}^{N} p_{f}(j) \cdot p_{f}(\neg j)
\end{equation}</p><p>with \(N\) classes and \(f \in F\) features, and where \(p_{f}(j)\) means the probability that, for the subset of the data with condition \(f\), a random sample takes on class \(j\). Then, we select the feature:</p><p>\begin{equation}
f_{split} = \arg\min_{f}\qty( G_{f} + G_{\neg f})
\end{equation}</p><p>We want this because we want each feature split to be &ldquo;pure&rdquo;&mdash;we want there to be either high probability of each split containing one class, or absolutely not containing it, so either \(p_{f}(j)\) or \(p_{f}(\neg j)\) should be very low.</p><p>Yet, this textbook uses a goofy representation where their splitting score is, after splitting by some feature \(f\) the count in each group having the majority class of that group&mdash;which functionally measures the same thing (class &ldquo;purity&rdquo; of each group); ideally, we want this value to be high, so we take argmax of it.</p><p>also I&rsquo;m pretty sure we can recycle features instead of popping them out; check me on this.</p><h2 id=bias>Bias</h2><h3 id=inductive-bias>Inductive Bias</h3><p><a href=#inductive-bias>Inductive Bias</a> is defined here as the bias towards a particular choice of solution in a set of possible variations of valid solutions in absence of data which further narrows down the relevant concept.</p><p>Nice.</p><p>Confused about their treatment of parity, will come back later.</p><h3 id=so-true>So true</h3><figure><img src=/ox-hugo/2024-03-24_19-30-56_screenshot.png></figure><p>so true</p><h3 id=sooo-true>Sooo true</h3><figure><img src=/ox-hugo/2024-03-24_19-31-45_screenshot.png></figure><p>I officially have no opinions on their treatment of KNN/kmeans or single layer perceptrons</p><p>I wish there was a proof for why kmeans works</p><h2 id=perception>Perception</h2><p>See <a href=/posts/kbhlogistic_regression/>logistic regression</a> and <a href=/posts/kbhneural_networks/>Neural Networks</a></p><h3 id=perception-convergence>Perception Convergence</h3><p>Suppose \(D\) is linearly separable with margin \(\gamma >0\) (otherwise it wouldn&rsquo;t be very separable); assume \(\mid x \mid \leq 1\); then, 1-layer perceptrons converge in \(\frac{1}{\gamma^{2}}\) updates.</p><p>Sketch: take the fact that \(w^{(k)} = w^{(k-1)} + yx\). Compare it to \(w^{*}\) to obtain that \(w^{*} \cdot w^{(k)} \geq k \gamma\). Norm it and because \(x\) is within \(1\) so \(\mid w^{(k)}\mid^{2} \leq k\). Now do algebra.</p><p>We will obtain \(k \leq \frac{1}{\gamma^{2}}\).</p></div></article></main><footer><p id=footer>&copy; 2019-2024 Houjun Liu. Licensed CC BY-NC-SA 4.0.</p></footer></div></body></html>