<!doctype html><html lang=en-us><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Commissioner:wght@100;300;400;500;700&family=IBM+Plex+Sans:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css integrity="sha512-Evv84Mr4kqVGRNSgIGL/F/aIDqQb7xQ2vcrdIwxfjThSH8CSR7PBEakCr51Ck+w+/U6swU2Im1vVX0SVk9ABhg==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Jost:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>window.MathJax={loader:{load:["[tex]/physics"]},tex:{packages:{"[+]":["physics"]}}}</script><title>Language Agents with Karthik</title>
<meta name=description content="Transitions

Transition first from rule based learning to statistical learning
Rise of semantic parsing: statistical models of parsing
Then, moving from semantic parsing to large models&mdash;putting decision making and language modeling into the same bubble

Importance of LLMs

They are simply better at understanding language inputs
They can generate structured information (i.e. not just human language, JSONs, etc.)
They can perform natural language &ldquo;reasoning&rdquo;&mdash;not just generate

(and natural language generation, abv)"><meta name=author content="Houjun Liu"><link rel=stylesheet href=/css/global.css><link rel=stylesheet href=/css/syntax.css></head><body><div class=center-clearfix><header><span id=header-name onclick='window.location.href="/"' style=cursor:pointer>Houjun Liu</span><div id=socialpanel><a href=https://www.jemoka.com/search/ class=header-social id=header-search><i class="ic fa-solid fa-magnifying-glass"></i></i></a>
<a href=https://github.com/Jemoka/ class=header-social id=header-github><i class="ic fa-brands fa-github"></i></a>
<a href=https://bsky.app/profile/jemoka.com class=header-social id=header-twitter><i class="ic fa-brands fa-bluesky"></i></a>
<a href=https://www.reddit.com/user/Jemoka/ class=header-social id=header-reddit><i class="ic fa-brands fa-reddit"></i></a></div></header><div id=title><h1>Language Agents with Karthik</h1><span class=tagbox></span></div><aside id=toc><h1 id=toc-title>table of contents</h1><nav id=TableOfContents><ul><li><a href=#transitions>Transitions</a></li><li><a href=#importance-of-llms>Importance of LLMs</a></li><li><a href=#react>ReAct</a></li><li><a href=#problem-agents-are-not-robust-at-all>Problem: agents are not robust at all</a></li><li><a href=#key-challenges>Key Challenges</a></li></ul></nav></aside><main><article><div><h2 id=transitions>Transitions</h2><ol><li>Transition first from rule based learning to statistical learning</li><li>Rise of semantic parsing: statistical models of parsing</li><li>Then, moving from semantic parsing to large models&mdash;putting decision making and language modeling into the same bubble</li></ol><h2 id=importance-of-llms>Importance of LLMs</h2><ul><li>They are simply better at understanding language inputs</li><li>They can generate structured information (i.e. not just human language, JSONs, etc.)</li><li>They can perform natural language &ldquo;reasoning&rdquo;&mdash;not just generate</li></ul><p>(and natural language generation, abv)</p><ul><li>1+3 gives you chain of thought reasoning</li><li>1+2 gives CALM, SayCan, and other types of RL text parsing in order to do stuff with robotics</li><li>all three gives ReAct</li></ul><h2 id=react>ReAct</h2><p>See <a href>ReAct</a></p><h2 id=problem-agents-are-not-robust-at-all>Problem: agents are not robust at all</h2><p><a href=https://github.com/ryoungj/ToolEmu>https://github.com/ryoungj/ToolEmu</a></p><h2 id=key-challenges>Key Challenges</h2><p>See <a href=/posts/kbhinteractive_agent/#challenge-of-making-agents>History of Agents and Their Challenges</a></p></div></article></main><footer><p id=footer>&copy; 2019-2025 Houjun Liu. Licensed CC BY-NC-SA 4.0.</p></footer></div></body></html>