<!doctype html><html lang=en-us><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Commissioner:wght@100;300;400;500;700&family=IBM+Plex+Sans:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css integrity="sha512-Evv84Mr4kqVGRNSgIGL/F/aIDqQb7xQ2vcrdIwxfjThSH8CSR7PBEakCr51Ck+w+/U6swU2Im1vVX0SVk9ABhg==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Jost:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>window.MathJax={loader:{load:["[tex]/physics"]},tex:{packages:{"[+]":["physics"]}}}</script><title>Language Agents with Karthik</title>
<meta name=description content="Definitions: Language Agents
Agents that uses the language to act on behave of another person or group.
Transitions

Transition first from rule based learning to statistical learning
Rise of semantic parsing: statistical models of parsing
Then, moving from semantic parsing to large models&mdash;putting decision making and language modeling into the same bubble

Importance of LLMs

They are simply better at understanding language inputs
They can generate structured information (i.e. not just human language, JSONs, etc.)
They can perform natural language &ldquo;reasoning&rdquo;&mdash;not just generate

(and natural language generation, abv)"><meta name=author content="Houjun Liu"><link rel=stylesheet href=/css/global.css><link rel=stylesheet href=/css/syntax.css></head><body><div class=center-clearfix><header><span id=header-name onclick='window.location.href="/"' style=cursor:pointer>Houjun Liu</span><div id=socialpanel><a href=https://www.jemoka.com/search/ class=header-social id=header-search><i class="ic fa-solid fa-magnifying-glass"></i></i></a>
<a href=https://github.com/Jemoka/ class=header-social id=header-github><i class="ic fa-brands fa-github"></i></a>
<a href=https://bsky.app/profile/jemoka.com class=header-social id=header-twitter><i class="ic fa-brands fa-bluesky"></i></a>
<a href=https://www.reddit.com/user/Jemoka/ class=header-social id=header-reddit><i class="ic fa-brands fa-reddit"></i></a></div></header><div id=title><h1>Language Agents with Karthik</h1><span class=tagbox></span></div><aside id=toc><h1 id=toc-title>table of contents</h1><nav id=TableOfContents><ul><li><a href=#definitions-language-agents>Definitions: Language Agents</a></li><li><a href=#transitions>Transitions</a></li><li><a href=#importance-of-llms>Importance of LLMs</a></li><li><a href=#react>ReAct</a><ul><li><a href=#major-flaw>Major Flaw</a></li><li><a href=#tree-of-thoughts>Tree of Thoughts</a></li></ul></li><li><a href=#problem-agents-are-not-robust-at-all>Problem: agents are not robust at all</a></li><li><a href=#key-new-challenges-for-agents>Key New Challenges for Agents</a><ul><li><a href=#evaluation>Evaluation</a></li><li><a href=#agent-development>Agent Development</a></li><li><a href=#trust-and-safety>Trust and safety</a></li></ul></li></ul></nav></aside><main><article><div><h2 id=definitions-language-agents>Definitions: Language Agents</h2><p>Agents that uses the language to act on behave of another person or group.</p><h2 id=transitions>Transitions</h2><ol><li>Transition first from rule based learning to statistical learning</li><li>Rise of semantic parsing: statistical models of parsing</li><li>Then, moving from semantic parsing to large models&mdash;putting decision making and language modeling into the same bubble</li></ol><h2 id=importance-of-llms>Importance of LLMs</h2><ul><li>They are simply better at understanding language inputs</li><li>They can generate structured information (i.e. not just human language, JSONs, etc.)</li><li>They can perform natural language &ldquo;reasoning&rdquo;&mdash;not just generate</li></ul><p>(and natural language generation, abv)</p><ul><li>1+3 gives you chain of thought reasoning</li><li>1+2 gives CALM, SayCan, and other types of RL text parsing in order to do stuff with robotics</li><li>all three gives ReAct</li></ul><h2 id=react>ReAct</h2><ul><li>Recover from incorrect thought and incorrect tools</li><li>Allows human-in-the-loop alignment</li></ul><h3 id=major-flaw>Major Flaw</h3><ul><li>left-to-right one-pass decoding doesn&rsquo;t allow alternate solutions</li><li>bad properties regarding propagating hallucination</li><li>search and planning had been explored a lot</li></ul><h3 id=tree-of-thoughts>Tree of Thoughts</h3><p>Partial solution: <a href=#tree-of-thoughts>Tree of Thoughts</a></p><figure><img src=/ox-hugo/2024-01-11_11-22-35_screenshot.png></figure><p>evaluate sub-paths to determine most optimal paths: think A* but with more proper heuristic bounding.</p><p><strong>Big idea: merge classic algorithmic ideas with decision making against LLMs</strong></p><h2 id=problem-agents-are-not-robust-at-all>Problem: agents are not robust at all</h2><p><a href=https://github.com/ryoungj/ToolEmu>https://github.com/ryoungj/ToolEmu</a></p><h2 id=key-new-challenges-for-agents>Key New Challenges for Agents</h2><h3 id=evaluation>Evaluation</h3><ol><li>Different from how previous NLP benchmarks: we are <strong>not</strong> worried about language modeling</li><li>No longer boundaries between various fields</li></ol><p>Common goals:</p><ul><li>realistic agents&mdash;stop playing Atari games.</li><li>reproducible systems</li><li>measurability goals</li><li>scalable models</li><li>which are easy to use</li></ul><h4 id=web-as-an-interactive-environment>Web as an Interactive Environment</h4><ul><li>agents on the web is both practical and scalable</li><li><a href=https://webshop-pnlp.github.io/>https://webshop-pnlp.github.io/</a></li><li>WebShop can actually transfer with no work to training on Amazon</li><li>Mind2Web</li></ul><h4 id=intercode>InterCode</h4><p>Formulation of agent decisions as POMDP in order to fully benchmark Markovian decisions:</p><p><a href=https://arxiv.org/abs/2306.14898>https://arxiv.org/abs/2306.14898</a></p><h3 id=agent-development>Agent Development</h3><p>Agents development has no core framework</p><h4 id=production-systems>production systems</h4><ul><li>set of rules specificying a precondition + action</li><li>when preconditinons are met, perform an action</li></ul><p>Big kitchen sink proposal: <a href=https://arxiv.org/abs/2309.02427>https://arxiv.org/abs/2309.02427</a></p><h3 id=trust-and-safety>Trust and safety</h3><p>Agents are much more powerful and dynamic</p></div></article></main><footer><p id=footer>&copy; 2019-2024 Houjun Liu. Licensed CC BY-NC-SA 4.0.</p></footer></div></body></html>