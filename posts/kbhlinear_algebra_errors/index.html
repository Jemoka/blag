<!doctype html><html lang=en-us><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Commissioner:wght@100;300;400;500;700&family=IBM+Plex+Sans:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css integrity="sha512-KfkfwYDsLkIlwQp6LFnl8zNdLGxu9YAA1QvwINks4PhcElQSvqcyVLLD9aMhXd13uQjoXtEKNosOWaZqXgel0g==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Jost:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>window.MathJax={loader:{load:["[tex]/physics"]},tex:{packages:{"[+]":["physics"]}}}</script><title>Linear Algebra Errors</title><meta name=description content="Gaussian Elimination Quiz

Demonstrate that matrices&rsquo; multiplication are not commutative (error: didn&rsquo;t consider \(m\times m\))
Which \(2\times 2\) matrices under multiplication form a group? (error: closure need to proved on invertable matrices under multiplication, not just \(2\times 2\))
Deriving Rotation matrices (error: clockwise vs counter-clockwise)

Linear Independence Quiz

Connection between linear independence and systems equations (error: beated around the bush) &mdash; the matrix of an nxn system of equations has a solution if the matrix&rsquo;s column vectors is linearly independent

Basis and Dimension Quiz

put 0 into a basis AAAA not lin. indep; figure out what the basis for a polynomial with a certain root is: it is probably of dimension m (instead of m+1), because scalars doesn&rsquo;t work in the case of p(3)=0; so basis is just the scalars
missing some inequality about basis? &mdash; its just that lin.idp sets is shorter or equal to basis and spanning sets is longer or equal to basis

Final, part 1

definition of vector space: scalar multiplication is not an operation
straight forgot \(dim(U+V) = dim U + dim V - dim (U\cap V)\)
plane containing \((1,0,2)\) and \((3,-1,1)\): math mistake
proof: det A det B = det AB

Final, part 2

Counterproof: If \(v_1 \dots v_4\) is a basis of \(V\), and \(U\) is a subspace of \(V\) with \(v_1, v_2 \in U\) and \(v_3, v_4\) not in \(U\), \(v_1, v_2\) is a basis of \(U\)
Counterproof: if \(T \in \mathcal{L}(V,V)\) and \(T^{2}=0\), then \(T=0\)
Counterproof: if \(s,t \in \mathcal{L}(V,V)\), and \(ST=0\), then \(null\ s\) is contained in \(range\ T\)


Product Spaces Quiz

Need more specific description: explain why we use product and quotient to describe product and quotient spaces?
Prove that \(\mathcal{L}(V_1 \times V_2 \times \dots \times V_{m}, W)\) and \(\mathcal{L}(V_1, W) \times  \dots \times \mathcal{L}(V_{m}, W)\) are isomorphic. Error: didn&rsquo;t do it correctly for infinite dimensional

Quotient Spaces Quiz




Couldn&rsquo;t prove that the list in linearly independent: the linear combinations is some \(c_1v_1 + \dots c_{m}v_{m} + U\); as \(v_1 \dots v_{m}\) is a basis of \(V / U\), \(c_1 \dots c_{m} = 0\), now the second part is also a basis so they are \(0\) too.

The spanning proof: \(v + U =\) , rewrite as basis, etc.


she graded wrong: what&rsquo;s the importance of \(\widetilde{T}\)?
Give two statements equivalent to \(v+U = w+U\), prove equivalence betewen this statement and the others

didn&rsquo;t prove both directions!



Polynomials Quiz

state the fundamental theorem of algebra; error: \(\mathcal{P}_{m}(\mathbb{F})\) is a vector space of polynomials with degree at most \(m\), and yet the FtOA requires exactly \(m\)

Upper Triangular Quiz

upper-triangular representation is findable when the space is 1) under complexes and 2) for finite-dimensional vector spaces; need BOTH conditions

Upper Triangular Quiz

UNCLEAR: Geometric Multipliicty is bounded by Algebric Multiplicity; Algebraic multiplicity (&ldquo;real estate&rdquo; taken on the upper-triangular diagonal) v. geometric multiplicity (amount of linearly independent eigenvectors included with that eigenvalue); so if geometric multiplicity < algebraic multiplicity, the map is not diagonalizable because its not bringing enough linearly independent eigenvectors

Diagonalization Quiz

enough eigenvalues go in only one direction: it existing means its diagonalizable, but the opposite isn&rsquo;t true
the proof for \(T\) is diagonalizable IFF the matrix \(T\) is similar to a diagonal matrix: NUS-MATH530 Similar to Diagonal

Final, part 1

State the complex spectral theorem (error: the condition of normality is a PARALLEL result)

Final, Part 2

Said this was true, but its not; \(null\ T \bigoplus range\ T = V\), \(T\) is diagonalizable;
Said this was true, but its false \(T^{2}= 0\) IFF \(null\ T = range\ T\)
suppose \(T=0\), \(T^{2} = 0\). \(null\ T = V\), \(range\ T = 0\).
Spectral theorem doesn&rsquo;t define diagonalizability, it defines diagonalibility for ORTHONORMAL
missing derivation of the pseudoinverse
"><meta name=author content="Houjun Liu"><link rel=stylesheet href=/css/global.css><link rel=stylesheet href=/css/syntax.css></head><body><div class=center-clearfix><header><span id=header-name onclick='window.location.href="/"' style=cursor:pointer>Houjun Liu</span><div id=socialpanel><a href=https://www.jemoka.com/search/ class=header-social id=header-search><i class="ic fa-solid fa-magnifying-glass"></i></i></a>
<a href=https://github.com/Jemoka/ class=header-social id=header-github><i class="ic fa-brands fa-github"></i></a>
<a href=https://maly.io/@jemoka class=header-social id=header-twitter><i class="ic fa-brands fa-mastodon"></i></a>
<a href=https://www.reddit.com/user/Jemoka/ class=header-social id=header-reddit><i class="ic fa-brands fa-reddit"></i></a></div></header><div id=title><h1>Linear Algebra Errors</h1><span class=tagbox></span></div><aside id=toc><h1 id=toc-title>table of contents</h1><nav id=TableOfContents><ul><li><a href=#gaussian-elimination-quiz>Gaussian Elimination Quiz</a></li><li><a href=#linear-independence-quiz>Linear Independence Quiz</a></li><li><a href=#basis-and-dimension-quiz>Basis and Dimension Quiz</a></li><li><a href=#final-part-1>Final, part 1</a></li><li><a href=#final-part-2>Final, part 2</a></li><li><a href=#product-spaces-quiz>Product Spaces Quiz</a></li><li><a href=#quotient-spaces-quiz>Quotient Spaces Quiz</a></li><li><a href=#polynomials-quiz>Polynomials Quiz</a></li><li><a href=#upper-triangular-quiz>Upper Triangular Quiz</a></li><li><a href=#upper-triangular-quiz>Upper Triangular Quiz</a></li><li><a href=#diagonalization-quiz>Diagonalization Quiz</a></li><li><a href=#final-part-1>Final, part 1</a></li><li><a href=#final-part-2>Final, Part 2</a></li></ul></nav></aside><main><article><div><h2 id=gaussian-elimination-quiz>Gaussian Elimination Quiz</h2><ul><li>Demonstrate that matrices&rsquo; multiplication are not commutative (error: didn&rsquo;t consider \(m\times m\))</li><li>Which \(2\times 2\) matrices under multiplication form a group? (error: closure need to proved on <strong>invertable</strong> matrices under multiplication, not just \(2\times 2\))</li><li>Deriving Rotation matrices (error: clockwise vs counter-clockwise)</li></ul><h2 id=linear-independence-quiz>Linear Independence Quiz</h2><ul><li>Connection between linear independence and systems equations (error: beated around the bush) &mdash; the matrix of an nxn system of equations has a solution if the matrix&rsquo;s column vectors is linearly independent</li></ul><h2 id=basis-and-dimension-quiz>Basis and Dimension Quiz</h2><ul><li>put 0 into a basis AAAA not lin. indep; figure out what the basis for a polynomial with a certain root is: it is probably of dimension m (instead of m+1), because scalars doesn&rsquo;t work in the case of p(3)=0; so basis is just the scalars</li><li>missing some inequality about basis? &mdash; its just that lin.idp sets is shorter or equal to basis and spanning sets is longer or equal to basis</li></ul><h2 id=final-part-1>Final, part 1</h2><ul><li>definition of vector space: scalar multiplication is not an operation</li><li>straight forgot \(dim(U+V) = dim U + dim V - dim (U\cap V)\)</li><li>plane containing \((1,0,2)\) and \((3,-1,1)\): math mistake</li><li>proof: det A det B = det AB</li></ul><h2 id=final-part-2>Final, part 2</h2><ul><li>Counterproof: If \(v_1 \dots v_4\) is a basis of \(V\), and \(U\) is a subspace of \(V\) with \(v_1, v_2 \in U\) and \(v_3, v_4\) not in \(U\), \(v_1, v_2\) is a basis of \(U\)</li><li>Counterproof: if \(T \in \mathcal{L}(V,V)\) and \(T^{2}=0\), then \(T=0\)</li><li>Counterproof: if \(s,t \in \mathcal{L}(V,V)\), and \(ST=0\), then \(null\ s\) is contained in \(range\ T\)</li></ul><hr><h2 id=product-spaces-quiz>Product Spaces Quiz</h2><ul><li>Need more specific description: explain why we use product and quotient to describe product and quotient spaces?</li><li>Prove that \(\mathcal{L}(V_1 \times V_2 \times \dots \times V_{m}, W)\) and \(\mathcal{L}(V_1, W) \times \dots \times \mathcal{L}(V_{m}, W)\) are <a href=/posts/kbhisomorphism/>isomorphic</a>. Error: didn&rsquo;t do it correctly for infinite dimensional</li></ul><h2 id=quotient-spaces-quiz>Quotient Spaces Quiz</h2><figure><img src=/ox-hugo/2023-02-09_10-24-09_screenshot.png></figure><ul><li>Couldn&rsquo;t prove that the list in linearly independent: the linear combinations is some \(c_1v_1 + \dots c_{m}v_{m} + U\); as \(v_1 \dots v_{m}\) is a basis of \(V / U\), \(c_1 \dots c_{m} = 0\), now the second part is also a basis so they are \(0\) too.<ul><li>The spanning proof: \(v + U =\) , rewrite as basis, etc.</li></ul></li><li>she graded wrong: what&rsquo;s the importance of \(\widetilde{T}\)?</li><li>Give two statements equivalent to \(v+U = w+U\), prove equivalence betewen this statement and the others<ul><li>didn&rsquo;t prove both directions!</li></ul></li></ul><h2 id=polynomials-quiz>Polynomials Quiz</h2><ul><li>state the fundamental theorem of algebra; error: \(\mathcal{P}_{m}(\mathbb{F})\) is a <a href=/posts/kbhvector_space/>vector space</a> of <a href=/posts/kbhpolynomial/>polynomial</a>s with degree <em>at most \(m\)</em>, and yet the FtOA requires <em>exactly \(m\)</em></li></ul><h2 id=upper-triangular-quiz>Upper Triangular Quiz</h2><ul><li>upper-triangular representation is findable when the space is 1) under complexes and 2) for finite-dimensional vector spaces; need BOTH conditions</li></ul><h2 id=upper-triangular-quiz>Upper Triangular Quiz</h2><ul><li>UNCLEAR: Geometric Multipliicty is bounded by Algebric Multiplicity; Algebraic multiplicity (&ldquo;real estate&rdquo; taken on the upper-triangular diagonal) v. geometric multiplicity (amount of linearly independent eigenvectors included with that eigenvalue); so if geometric multiplicity &lt; algebraic multiplicity, the map is not diagonalizable because its not bringing enough linearly independent eigenvectors</li></ul><h2 id=diagonalization-quiz>Diagonalization Quiz</h2><ul><li>enough eigenvalues go in only one direction: it existing means its diagonalizable, but the opposite isn&rsquo;t true</li><li>the proof for \(T\) is diagonalizable IFF the matrix \(T\) is similar to a diagonal matrix: <a href=/posts/kbhnus_math530_similar_to_diagonal/>NUS-MATH530 Similar to Diagonal</a></li></ul><h2 id=final-part-1>Final, part 1</h2><ul><li>State the complex spectral theorem (error: the condition of normality is a PARALLEL result)</li></ul><h2 id=final-part-2>Final, Part 2</h2><ul><li>Said this was true, but its not; \(null\ T \bigoplus range\ T = V\), \(T\) is diagonalizable;</li><li>Said this was true, but its false \(T^{2}= 0\) IFF \(null\ T = range\ T\)
suppose \(T=0\), \(T^{2} = 0\). \(null\ T = V\), \(range\ T = 0\).</li><li>Spectral theorem doesn&rsquo;t define diagonalizability, it defines diagonalibility for ORTHONORMAL</li><li>missing derivation of the pseudoinverse</li></ul></div></article></main><footer><p id=footer>&copy; 2019-2024 Houjun Liu. Licensed CC BY-NC-SA 4.0.</p></footer></div></body></html>