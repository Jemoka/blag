<!doctype html><html lang=en-us><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Commissioner:wght@100;300;400;500;700&family=IBM+Plex+Sans:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css integrity="sha512-Evv84Mr4kqVGRNSgIGL/F/aIDqQb7xQ2vcrdIwxfjThSH8CSR7PBEakCr51Ck+w+/U6swU2Im1vVX0SVk9ABhg==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Jost:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>window.MathJax={loader:{load:["[tex]/physics"]},tex:{packages:{"[+]":["physics"]}}}</script><title>supervised learning</title>
<meta name=description content="Supervised learning (also known as behavioral cloning) if the agent is learning what to do in an observe-act cycle) is a type of decision making method.
constituents

input space: \(\mathcal{X}\)
output space: \(\mathcal{Y}\)
hypothesis/model/prediction: \(h : \mathcal{X} \to \mathcal{Y}\)

requirements
Our ultimate goal is to learn a good model \(h\) from the training set:

what &ldquo;good&rdquo; means is hard to define
we generally want to use the model on new data, not just the training set

continuous \(\mathcal{Y}\) is then called a regression problem; discrete \(\mathcal{Y}\) is called a classification problem."><meta name=author content="Houjun Liu"><link rel=stylesheet href=/css/global.css><link rel=stylesheet href=/css/syntax.css></head><body><div class=center-clearfix><header><span id=header-name onclick='window.location.href="/"' style=cursor:pointer>Houjun Liu</span><div id=socialpanel><a href=https://www.jemoka.com/search/ class=header-social id=header-search><i class="ic fa-solid fa-magnifying-glass"></i></i></a>
<a href=https://github.com/Jemoka/ class=header-social id=header-github><i class="ic fa-brands fa-github"></i></a>
<a href=https://bsky.app/profile/jemoka.com class=header-social id=header-twitter><i class="ic fa-brands fa-bluesky"></i></a>
<a href=https://www.reddit.com/user/Jemoka/ class=header-social id=header-reddit><i class="ic fa-brands fa-reddit"></i></a></div></header><div id=title><h1>supervised learning</h1><span class=tagbox></span></div><aside id=toc><h1 id=toc-title>table of contents</h1><nav id=TableOfContents><ul><li><a href=#constituents>constituents</a></li><li><a href=#requirements>requirements</a></li><li><a href=#additional-information>additional information</a><ul><li><a href=#training-set>training set</a></li><li><a href=#main-procedure>main procedure</a></li><li><a href=#disadvantages>Disadvantages</a></li><li><a href=#cost-function>cost function</a></li><li><a href=#evaluation>evaluation</a></li></ul></li></ul></nav></aside><main><article><div><p>Supervised learning (also known as <a href=/posts/kbhsupervised_learning/>behavioral cloning</a>) if the agent is learning what to do in an <a href=/posts/kbhobserve_act_cycle/>observe-act cycle</a>) is a type of <a href=/posts/kbhdecision_making/>decision making</a> method.</p><h2 id=constituents>constituents</h2><ul><li><strong>input space</strong>: \(\mathcal{X}\)</li><li><strong>output space</strong>: \(\mathcal{Y}\)</li><li><strong>hypothesis/model/prediction</strong>: \(h : \mathcal{X} \to \mathcal{Y}\)</li></ul><h2 id=requirements>requirements</h2><p>Our ultimate goal is to learn a good model \(h\) from the <a href=#training-set>training set</a>:</p><ul><li>what &ldquo;good&rdquo; means is hard to define</li><li>we generally want to use the model on <strong>new data</strong>, not just the <a href=#training-set>training set</a></li></ul><p>continuous \(\mathcal{Y}\) is then called a <a href=/posts/kbhsupervised_learning/>regression</a> problem; discrete \(\mathcal{Y}\) is called a <a href=/posts/kbhsupervised_learning/>classification</a> problem.</p><p>That is, we want our <a href=/posts/kbhsupervised_learning/>hypothesis</a> to behave as \(h_{\theta}\qty (x^{(i)}) \approx y^{(i)}\).</p><h2 id=additional-information>additional information</h2><h3 id=training-set>training set</h3><p>The training set is a set of pairs:</p><p>\begin{equation}
\qty {\qty(x^{(1)}, y^{(1)}) \dots \qty (x^{(n)}, y^{(n)})}
\end{equation}</p><p>such that \(x^{(j)} \in \mathcal{X}, y^{(j)} \in \mathcal{Y}\).</p><p>We call \(n\) the <a href=#training-set>training set</a> size.</p><h3 id=main-procedure>main procedure</h3><ol><li>provide the <a href=/posts/kbhagent/>agent</a> with some examples</li><li>use an automated learning algorithm to generalize from the example</li></ol><p>This is good for typically representative situations, but if you are throwing an <a href=/posts/kbhagent/>agent</a> into a completely unfamiliar situation, supervised learning cannot perform better.</p><h3 id=disadvantages>Disadvantages</h3><ul><li>the labeled data is finite</li><li>limited by the quality of performance in the training data</li><li>interpolation between states are finite</li></ul><h3 id=cost-function>cost function</h3><p>see <a href=/posts/kbhcost_function/>cost function</a></p><h3 id=evaluation>evaluation</h3><p>see <a href=/posts/kbhmachine_learning_evaluation/>machine learning evaluation</a></p></div></article></main><footer><p id=footer>&copy; 2019-2025 Houjun Liu. Licensed CC BY-NC-SA 4.0.</p></footer></div></body></html>