<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Commissioner:wght@100;300;400;500;700&family=IBM+Plex+Sans:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css integrity="sha512-KfkfwYDsLkIlwQp6LFnl8zNdLGxu9YAA1QvwINks4PhcElQSvqcyVLLD9aMhXd13uQjoXtEKNosOWaZqXgel0g==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script>
<link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Jost:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><title>DementiaBank Acoustics Project</title><meta name=description content="The DementiaBank Acoustics Project is a working title for an acoustic-only challenge for AD detection. This document serves as the lab notebook for this project.
This project will attempt to replicate some of the results of Wang 2019 and Martinc 2021, but focusing on minimizing human involvement; we will first work on raw transcript classification with ERNIE (cutting all CHAT annotations), then introduce pause-encoding in a manner similar to Yuan 2021 which is automated by MFA."><meta name=author content="Houjun Liu"><link rel=stylesheet href=/css/global.css><link rel=stylesheet href=/css/syntax.css></head><body><header><span id=header-name onclick='window.location.href="/"' style=cursor:pointer>Houjun Liu</span><div id=socialpanel><a href=https://www.jemoka.com/search/ class=header-social id=header-search><i class="ic fa-solid fa-magnifying-glass"></i></i></a>
<a href=https://github.com/Jemoka/ class=header-social id=header-github><i class="ic fa-brands fa-github"></i></a>
<a href=https://twitter.com/jemokajack class=header-social id=header-twitter><i class="ic fa-brands fa-twitter"></i></a>
<a href=https://www.reddit.com/user/Jemoka/ class=header-social id=header-reddit><i class="ic fa-brands fa-reddit"></i></a></div></header><div id=title><h1>DementiaBank Acoustics Project</h1></div><aside id=toc><h1 id=toc-title>table of contents</h1><nav id=TableOfContents><ul><li><a href=#background-reading>Background Reading</a></li><li><a href=#proposal>Proposal</a></li><li><a href=#brainstoming>Brainstoming</a></li><li><a href=#protocol-notes>Protocol Notes</a><ul><li><a href=#july-1st>July 1st</a></li><li><a href=#july-2nd>July 2nd</a></li><li><a href=#july-4th>July 4th</a></li><li><a href=#july-5th>July 5th</a></li><li><a href=#july-7th>July 7th</a></li><li><a href=#july-8th>July 8th</a></li><li><a href=#july-9th>July 9th</a></li></ul></li><li><a href=#concerns-and-questions>Concerns and Questions</a><ul><li><a href=#july-2nd>July 2nd</a></li><li><a href=#july-4th>July 4th</a></li></ul></li></ul></nav></aside><main><article><div><p>The <a href=/posts/kbhdementiabank_acoustics_project/>DementiaBank Acoustics Project</a> is a working title for an acoustic-only challenge for AD detection. This document serves as the lab notebook for this project.</p><p>This project will attempt to replicate some of the results of <a href=/posts/kbhwang_2019/>Wang 2019</a> and <a href=/posts/kbhmartinc_2021/>Martinc 2021</a>, but focusing on minimizing human involvement; we will first work on raw transcript classification with ERNIE (cutting all CHAT annotations), then introduce pause-encoding in a manner similar to <a href=/posts/kbhyuan_2021/>Yuan 2021</a> which is automated by MFA. Goal is to replicate the results of <a href=/posts/kbhyuan_2021/>Yuan 2021</a>/or even <a href=/posts/kbhmartinc_2021/>Martinc 2021</a> in a completely automated manner.</p><h2 id=background-reading>Background Reading</h2><p>I first began by doing a literature survey on the <a href=/posts/kbhadress_literature_survey/>ADReSS Challenge</a> results published in the Frontiers AD special interest group issue.</p><h2 id=proposal>Proposal</h2><p>And then, we wrote a proposal: <a href=/posts/kbhdementiabank_acoustics_project_proposal/>DementiaBank Acoustics Project Proposal</a></p><h2 id=brainstoming>Brainstoming</h2><p>More notes from the meeting: <a href=/posts/kbhdementiabank_acoustics_brainstoming/>DementiaBank Acoustics Brainstoming</a></p><h2 id=protocol-notes>Protocol Notes</h2><h3 id=july-1st>July 1st</h3><ul><li>Began by moving a subsample of <a href=https://dementia.talkbank.org/access/English/Pitt.html>Pitt</a>&rsquo;s <a href=/posts/kbhctp/>Cookie Theft</a> to <code>pitt-7-1</code> in the <code>raw</code> data folder</li><li>Ran <code>flo</code> on all collected samples. Arguments used are the same as that for <a href=/posts/kbhbatchalign/>batchalign</a>, except <em>we filter out the <code>INV</code> tier</em> as we are detecting AD on patient and not investigator: so <code>flo +d +ca +t* -tINV</code></li><li>Moved all collected samples (and changed extension to .txt) to the same sub-folder, but in <code>transcripts_nodisfluency</code></li></ul><h3 id=july-2nd>July 2nd</h3><ul><li>Created a dataprep script <code>dataprep.py</code> which dumps a pickled copy of cleaned data to <code>transcripts_nodisfluency/pitt-7-1.dat</code>.</li><li>Created sliding windows of 5 pieces of dialogue concatenated, stored it in <code>transcripts_nodisfluency/pitt-7-1-windowed.dat</code></li><li>Used tencent/HuYong&rsquo;s <code>nghuyong/ernie-2.0-en</code> Ernie 2.0 model, the continuous language model from Baidu (Layer:12, Hidden:768, Heads:12)</li></ul><h3 id=july-4th>July 4th</h3><ul><li>Finalized training code. Selected base hyperparameters {bs: 8, epochs: 2, lr: 3e-3, length: 60}. Again, we are using Baidu&rsquo;s <code>nghuyong/ernie-2.0-en</code>.</li><li>Started training fastcalculator on <code>24bc812</code></li></ul><h4 id=train-faithful-frog-3>train: faithful-frog-3</h4><p>{bs: 8, epochs: 2, lr: 3e-3, length: 60, pitt-7-1-windowed.dat }</p><figure><img src=/ox-hugo/2022-07-04_19-20-13_screenshot.png></figure><ul><li>Commentary: LR could be too high, looking at the divergent loss behavior.</li><li>Decision: dropping bs to <code>4</code> and lr to <code>1e-5</code>, similar to previous transformers. Also training for 3 epochs.</li></ul><h4 id=train-revived-disco-5>train: revived-disco-5</h4><p>{bs: 4, epochs: 3, lr: 1e-5, length: 60, pitt-7-1-windowed.dat }</p><figure><img src=/ox-hugo/2022-07-04_19-28-07_screenshot.png></figure><ul><li>Commentary: quintessential overfitting</li><li>Decision:<ul><li>Made the corpus bigger<ul><li>cleaned the entire <a href=https://dementia.talkbank.org/access/English/Pitt.html>Pitt</a> corpus (<code>pitt-7-4</code> in the <code>raw</code> folder) to become training data. Similar to <code>pitt-7-1</code>, ran <code>flo</code> on all collected samples; arguments used are the same as that for <a href=/posts/kbhbatchalign/>batchalign</a>, except <em>we filter out the <code>INV</code> tier</em> as we are detecting AD on patient and not investigator: so <code>flo +d +ca +t* -tINV</code>; the <code>flo</code>&rsquo;d results are in <code>transcripts_nodisfluency</code>.</li><li>the notable difference between the previous dataset <code>7-1</code> and the current one <code>7-4</code> is that the <code>7-4</code> are prepended numbered by the task (<code>cookie/100-01.cha</code> <code>> =cookie-100-01.txt</code>)</li><li>New (full) Pitt data as prepared above is ran though the dataprep script as of <code>b325514cfad79da82d7a519ed29ea19ed87b2be4</code> (difference is that empty/dummy files are ignored), and pickled at <code>transcripts_nodisfluency/pitt-7-4.dat</code> and <code>transcripts_nodisfluency/pitt-7-4-windowed.dat</code> respectively.</li><li>For new data, window size is still <code>5</code>, splitting <code>10</code> cases out for testing now instead of <code>5</code>.</li></ul></li></ul></li></ul><h4 id=train-vocal-oath-6>train: vocal-oath-6</h4><p>{bs: 4, epochs: 3, lr: 1e-5, length: 60, pitt-7-4-windowed.dat}</p><figure><img src=/ox-hugo/2022-07-04_20-20-01_screenshot.png></figure><figure><img src=/ox-hugo/2022-07-04_20-35-54_screenshot.png></figure><ul><li>Commentary: high recall, low precision. Perhaps classes aren&rsquo;t balanced?<ul><li>Spoiler alert: they are not.</li><li>An inspection of data reveals that there is 3211 rows of dementia, 2397 rows of control</li></ul></li><li>Decision:<ul><li>Created <code>pitt-7-4-bal</code> and <code>pitt-7-4-windowed-bal</code> series of data based on dataprep.py on <code>703f79248a20fd7a13a5033ca2bf7f691f42c941</code>. This version force-crops to make sure that the dementia and control indicies have the exact same length for each class.</li></ul></li></ul><h4 id=train-helpful-leaf-7>train: helpful-leaf-7</h4><p>{bs: 4, epochs: 3, lr: 1e-5, length: 60, pitt-7-4-windowed-bal.dat}</p><figure><img src=/ox-hugo/2022-07-04_21-31-19_screenshot.png></figure><figure><img src=/ox-hugo/2022-07-04_21-35-43_screenshot.png></figure><p>Beautiful. Question now is whether or not there is data leakage/external heuristics. It is a good time to do some <a href=/posts/kbhloo/>LOOCV</a>. Getting this result without any disfluency calculations seems unlikely.</p><p>But anyways, going to discuss these results as they seem to meet results we see in <a href=/posts/kbhyuan_2021/>Yuan 2021</a>, even without top-N ensemble; though this is one trial, <a href=/posts/kbhloo/>LOOCV</a> may still show that we actually need it.</p><h3 id=july-5th>July 5th</h3><ul><li>Began the day with creating the script k-fold validation; I originally hoped to exactly replicate the procedure of <a href=/posts/kbhyuan_2021/>Yuan 2021</a> for comparability, but, not sure how they got the actual result of a min/max range with <a href=/posts/kbhloo/>LOOCV</a> on binary; therefore, we will instead create a 95% <a href=/posts/kbhconfidence_interval/>confidence interval</a> analysis via a single-variable <a href=/posts/kbht_statistics/>t test</a> on standard k-fold validation. K=50</li><li>During one-off testing, another set of hyperparameters seems to work too: {bs: 72, epochs: 3, lr: 1e-5, length: 60, pitt-7-4-windowed-bal.dat}. As we have not begun tuning for hyperparameters, we are just going to use this set, K=50, for the first k-fold trial.</li></ul><h4 id=k-fold-f4zvbgfdbaqvtvxemwzczd>k-fold: F4ZVbGfdBAQvtvXemWZCZD</h4><p>code: 55f77ff1dea03c3ed66967864dc52fd2c0062f23</p><figure><img src=/ox-hugo/2022-07-05_13-22-24_screenshot.png></figure><p>{bs: 72, epochs: 3, lr: 1e-5, length: 60, pitt-7-4-windowed-bal.dat}
K = 50</p><figure><img src=/ox-hugo/2022-07-05_14-25-26_screenshot.png></figure><figure><img src=/ox-hugo/2022-07-05_14-26-00_screenshot.png></figure><p>It seems like the results we got is consistent and validates in a manner which we expect.</p><h3 id=july-7th>July 7th</h3><p>Yesterday was a day filled with working on <a href=/posts/kbhbatchalign/>batchalign</a>, but we are back now. Today, I aim to look into the heuristic that I identified yesterday by playing with the model, which is that it seems like the model prefers the use of long-focused sentences <em>about</em> cookies, so the heruistic its picking up is probably on-topicness.</p><p>I am going to first leverage the lovely <code>cdpierse/transformers-interpret</code> tool to help build some explainability by adding it to validate.py. Upon some human validation with random sampling, the model seem to do less well than I&rsquo;d hoped. Running a train cycle with the new results/params seen above to see if it does better.</p><h4 id=train-brisk-oath-10>train: brisk-oath-10</h4><p>{bs: 72, epochs: 3, lr: 1e-5, length: 60, pitt-7-4-windowed-bal.dat}</p><figure><img src=/ox-hugo/2022-07-07_11-39-18_screenshot.png></figure><figure><img src=/ox-hugo/2022-07-07_11-48-40_screenshot.png></figure><ul><li>Commentary: It seems like the model is doing overall worse from validation data, but it does fairly well during test data.</li><li>Decision:<ul><li>I can fairly confidently claim that the model is just fitting on topic. As in, if the topic is about cookies (theft/taking/cookie/mother/etc.), it will be classified as control.</li><li>One thing that we can do is to claim this task as directly task-controlled: that is, include <strong>no</strong> data except cookie and control for that difference</li><li>Then, the model would&rsquo;t be able to predict the result b/c the variation in topic won&rsquo;t have influence.</li><li>This is going to be prepared in the <code>cookiepitt-7-7-bal*</code> based on <code>dataprep.py</code> in commit <code>518dec82bb961c0a8ad02e3080289b56102aa1a2</code></li></ul></li></ul><h4 id=train-super-durian-11>train: super-durian-11</h4><p>{bs: 72, epochs: 3, lr: 1e-5, length: 60, cookiepitt-7-7-windowed-bal.dat}</p><figure><img src=/ox-hugo/2022-07-07_13-51-01_screenshot.png></figure><ul><li>Commentary: the model is <em>no where near convergence</em></li><li>Decision: multiplying the LR by 10</li></ul><h4 id=train-floral-sunset-12>train: floral-sunset-12</h4><p>{bs: 72, epochs: 3, lr: 1e-4, length: 60, cookiepitt-7-7-windowed-bal.dat}</p><figure><img src=/ox-hugo/2022-07-07_13-54-38_screenshot.png></figure><figure><img src=/ox-hugo/2022-07-07_14-02-47_screenshot.png></figure><ul><li>Commentary: There we go. This seem to be more in line with what we see in <a href=/posts/kbhyuan_2021/>Yuan 2021</a></li><li>Decision: ok, let&rsquo;s elongate the actual content. Perhaps we can try a 7-element search instead? This is written as <code>cookiepitt-7-7-*-long</code>. Code based on <code>9e31f4bc13c4bfe193dcc049059c3d9bda46c8d0</code></li></ul><h4 id=train-sweet-plasma-13>train: sweet-plasma-13</h4><p>{bs: 72, epochs: 3, lr: 1e-4, length: 60, cookiepitt-7-7-windowed-long-bal.dat}</p><figure><img src=/ox-hugo/2022-07-07_15-05-28_screenshot.png></figure><ul><li>Commentary: underfitting</li><li>Dropping batch size down to 64 to add more steps</li></ul><h4 id=train-smart-river-14>train: smart-river-14</h4><p>{bs: 64, epochs: 3, lr: 1e-4, length: 60, cookiepitt-7-7-windowed-long-bal.dat}</p><figure><img src=/ox-hugo/2022-07-07_15-13-21_screenshot.png></figure><figure><img src=/ox-hugo/2022-07-07_15-20-57_screenshot.png></figure><ul><li>Commentary: this finally fits to the specifications which <a href=/posts/kbhyuan_2021/>Yuan 2021</a> have revealed</li><li>Decision: running k-fold on this architecture</li></ul><h4 id=k-fold-xgsp4fvs6scfxczkfjovq5-dot>k-fold: XgsP4FVS6ScFxCZKFJoVQ5.</h4><p>Code: 3870651ba71da8ddb3f481a7c3e046397a09d8b2</p><figure><img src=/ox-hugo/2022-07-07_15-30-07_screenshot.png></figure><figure><img src=/ox-hugo/2022-07-07_16-18-44_screenshot.png></figure><figure><img src=/ox-hugo/2022-07-07_16-20-23_screenshot.png></figure><h3 id=july-8th>July 8th</h3><ul><li><p>Began the day with aligning the entirety of cookie for both control and dementia, named the dataset <code>alignedpitt-7-8</code> in the RAW folder</p></li><li><p>Per what we discussed, will add [pause] as a token to the model. Then, transcript the text such that it would contain normalized values to the pauses for pauses > 0.250 seconds. Therefore, the data would look like</p><p>&ldquo;hello my name is [pause] 262 [pause] bob&rdquo;</p></li></ul><h3 id=july-9th>July 9th</h3><ul><li>Created transcript.py, which coverts the data in <code>raw</code> to <code>transcripts_pauses</code>, which contains pause values > 250 msc and prepends them with [pause] tokens</li><li>The code from above is taken from <code>check.py</code> in <a href=/posts/kbhbatchalign/>batchalign</a>, used <code>transcript.py</code> from <code>7e19a4912cf0ad5d269c139da5ce018615495ebb</code> to clean out the dataset; placed it in similar txt format to <code>alignedpitt-7-8</code></li><li>Ran dataprep with window size of 5, created <code>alignedpitt-7-8.bat</code> and <code>alignedpitt-7-8-windowed.bat</code> as the dataprep file</li><li>starting a new training run, with <code>[pause]</code> added as a new token, code <code>06846c6c95e6b1ccf17f0660c5da76aa50231567</code></li></ul><h4 id=golden-tree-16>golden-tree-16</h4><p>{bs: 64, epochs: 3, lr: 1e-4, length: 60, alignedpitt-7-8-windowed.dat}</p><figure><img src=/ox-hugo/2022-07-09_11-48-01_screenshot.png></figure><figure><img src=/ox-hugo/2022-07-09_11-51-24_screenshot.png></figure><p>But interestingly, if I used the original (non-pause-aware) tokenizer, we have</p><figure><img src=/ox-hugo/2022-07-09_11-52-03_screenshot.png></figure><p>So realistically, we have the same F1 between the two, but pause encoding increased the accuracy of prediction yet dropped recall dramatically.</p><h2 id=concerns-and-questions>Concerns and Questions</h2><h3 id=july-2nd>July 2nd</h3><ul><li><code>pitt7-1/dementia/493-0</code> PAR tier &ldquo;tell me everything you see going on in that picture&rdquo; doesn&rsquo;t seem to be labeled correctly; I am guessing that&rsquo;s supposed to be INV?</li><li>Has anyone tried to include investigator/participant cross-dialogue?</li></ul><h3 id=july-4th>July 4th</h3><ul><li>Is the model overfitting on antiquated language?</li><li>Is the model overfitting on cooke-theft on-topic-ness?</li></ul></div></article></main><footer><p id=footer>&copy; 2019-2022 Houjun Liu. Licensed CC BY-NC-SA 4.0.</p></footer></body></html>