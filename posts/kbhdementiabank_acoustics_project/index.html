<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Commissioner:wght@100;300;400;500;700&family=IBM+Plex+Sans:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css integrity="sha512-KfkfwYDsLkIlwQp6LFnl8zNdLGxu9YAA1QvwINks4PhcElQSvqcyVLLD9aMhXd13uQjoXtEKNosOWaZqXgel0g==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script>
<link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Jost:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><title>DementiaBank Acoustics Project</title><meta name=description content="The DementiaBank Acoustics Project is a working title for an acoustic-only challenge for AD detection. This document serves as the lab notebook for this project.
This project will attempt to replicate some of the results of Wang 2019 and Martinc 2021, but focusing on minimizing human involvement; we will first work on raw transcript classification with ERNIE (cutting all CHAT annotations), then introduce pause-encoding in a manner similar to Yuan 2021 which is automated by MFA."><meta name=author content="Houjun Liu"><link rel=stylesheet href=/css/global.css><link rel=stylesheet href=/css/syntax.css></head><body><header><span id=header-name onclick='window.location.href="/"' style=cursor:pointer>Houjun Liu</span><div id=socialpanel><a href=https://www.jemoka.com/search/ class=header-social id=header-search><i class="ic fa-solid fa-magnifying-glass"></i></i></a>
<a href=https://github.com/Jemoka/ class=header-social id=header-github><i class="ic fa-brands fa-github"></i></a>
<a href=https://twitter.com/jemokajack class=header-social id=header-twitter><i class="ic fa-brands fa-twitter"></i></a>
<a href=https://www.reddit.com/user/Jemoka/ class=header-social id=header-reddit><i class="ic fa-brands fa-reddit"></i></a></div></header><div id=title><h1>DementiaBank Acoustics Project</h1></div><aside id=toc><h1 id=toc-title>table of contents</h1><nav id=TableOfContents><ul><li><a href=#background-reading>Background Reading</a></li><li><a href=#proposal>Proposal</a></li><li><a href=#brainstoming>Brainstoming</a></li><li><a href=#protocol-notes>Protocol Notes</a><ul><li><a href=#july-1st>July 1st</a></li><li><a href=#july-2nd>July 2nd</a></li><li><a href=#july-4th>July 4th</a></li></ul></li><li><a href=#concerns-and-questions>Concerns and Questions</a><ul><li><a href=#july-2nd>July 2nd</a></li></ul></li></ul></nav></aside><main><article><div><p>The <a href=/posts/kbhdementiabank_acoustics_project/>DementiaBank Acoustics Project</a> is a working title for an acoustic-only challenge for AD detection. This document serves as the lab notebook for this project.</p><p>This project will attempt to replicate some of the results of <a href=/posts/kbhwang_2019/>Wang 2019</a> and <a href=/posts/kbhmartinc_2021/>Martinc 2021</a>, but focusing on minimizing human involvement; we will first work on raw transcript classification with ERNIE (cutting all CHAT annotations), then introduce pause-encoding in a manner similar to <a href=/posts/kbhyuan_2021/>Yuan 2021</a> which is automated by MFA. Goal is to replicate the results of <a href=/posts/kbhyuan_2021/>Yuan 2021</a>/or even <a href=/posts/kbhmartinc_2021/>Martinc 2021</a> in a completely automated manner.</p><h2 id=background-reading>Background Reading</h2><p>I first began by doing a literature survey on the <a href=/posts/kbhadress_literature_survey/>ADReSS Challenge</a> results published in the Frontiers AD special interest group issue.</p><h2 id=proposal>Proposal</h2><p>And then, we wrote a proposal: <a href=/posts/kbhdementiabank_acoustics_project_proposal/>DementiaBank Acoustics Project Proposal</a></p><h2 id=brainstoming>Brainstoming</h2><p>More notes from the meeting: <a href=/posts/kbhdementiabank_acoustics_brainstoming/>DementiaBank Acoustics Brainstoming</a></p><h2 id=protocol-notes>Protocol Notes</h2><h3 id=july-1st>July 1st</h3><ul><li>Began by moving a subsample of <a href=https://dementia.talkbank.org/access/English/Pitt.html>Pitt</a>&rsquo;s <a href=/posts/kbhctp/>Cookie Theft</a> to <code>pitt-7-1</code> in the <code>raw</code> data folder</li><li>Ran <code>flo</code> on all collected samples. Arguments used are the same as that for <a href=/posts/kbhbatchalign/>batchalign</a>, except <em>we filter out the <code>INV</code> tier</em> as we are detecting AD on patient and not investigator: so <code>flo +d +ca +t* -tINV</code></li><li>Moved all collected samples (and changed extension to .txt) to the same sub-folder, but in <code>transcripts_nodisfluency</code></li></ul><h3 id=july-2nd>July 2nd</h3><ul><li>Created a dataprep script <code>dataprep.py</code> which dumps a pickled copy of cleaned data to <code>transcripts_nodisfluency/pitt-7-1.dat</code>.</li><li>Created sliding windows of 5 pieces of dialogue concatenated, stored it in <code>transcripts_nodisfluency/pitt-7-1-windowed.dat</code></li><li>Used tencent/HuYong&rsquo;s <code>nghuyong/ernie-2.0-en</code> Ernie 2.0 model, the continuous language model from Baidu (Layer:12, Hidden:768, Heads:12)</li></ul><h3 id=july-4th>July 4th</h3><ul><li>Finalized training code. Selected base hyperparameters {bs: 8, epochs: 2, lr: 3e-3, length: 60}. Again, we are using Baidu&rsquo;s <code>nghuyong/ernie-2.0-en</code>.</li><li>Started training fastcalculator on <code>24bc812</code></li></ul><h4 id=faithful-frog-3>faithful-frog-3</h4><p>{bs: 8, epochs: 2, lr: 3e-3, length: 60, pitt-7-1-windowed.dat }</p><figure><img src=/ox-hugo/2022-07-04_19-20-13_screenshot.png></figure><ul><li>Commentary: LR could be too high, looking at the divergent loss behavior.</li><li>Decision: dropping bs to <code>4</code> and lr to <code>1e-5</code>, similar to previous transformers. Also training for 3 epochs.</li></ul><h2 id=concerns-and-questions>Concerns and Questions</h2><h3 id=july-2nd>July 2nd</h3><ul><li><code>pitt7-1/dementia/493-0</code> PAR tier &ldquo;tell me everything you see going on in that picture&rdquo; doesn&rsquo;t seem to be labeled correctly; I am guessing that&rsquo;s supposed to be INV?</li><li>Has anyone tried to include investigator/participant cross-dialogue?</li></ul></div></article></main><footer><p id=footer>&copy; 2019-2022 Houjun Liu. Licensed CC BY-NC-SA 4.0.</p></footer></body></html>