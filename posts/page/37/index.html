<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Commissioner:wght@100;300;400;500;700&family=IBM+Plex+Sans:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css integrity="sha512-KfkfwYDsLkIlwQp6LFnl8zNdLGxu9YAA1QvwINks4PhcElQSvqcyVLLD9aMhXd13uQjoXtEKNosOWaZqXgel0g==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script>
<link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Jost:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script>
<script>window.MathJax={loader:{load:["[tex]/physics"]},tex:{packages:{"[+]":["physics"]}}}</script><title>Posts</title><meta name=author content="Houjun Liu"><link rel=stylesheet href=/css/global.css><link rel=stylesheet href=/css/syntax.css><link rel=alternate type=application/rss+xml href=/posts/index.xml title=jemoka.com></head><body><div class=center-clearfix><header><span id=header-name onclick='window.location.href="/"' style=cursor:pointer>Houjun Liu</span><div id=socialpanel><a href=https://www.jemoka.com/search/ class=header-social id=header-search><i class="ic fa-solid fa-magnifying-glass"></i></i></a>
<a href=https://github.com/Jemoka/ class=header-social id=header-github><i class="ic fa-brands fa-github"></i></a>
<a href=https://twitter.com/jemokajack class=header-social id=header-twitter><i class="ic fa-brands fa-twitter"></i></a>
<a href=https://www.reddit.com/user/Jemoka/ class=header-social id=header-reddit><i class="ic fa-brands fa-reddit"></i></a></div></header><main><div id=title><h1><span class=listhash>#</span>Posts</h1></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhaxler_2_b/"'><span class=top><h1><a class=noannot>Axler 2.B</a></h1><span class="modbox right">Last edited: <span class=moddate>October 10, 2022</span></span></span>
<span class=summary>Key Sequence we defined basis of a vector space&mdash;a linearly independent spanning list of that vector space&mdash;and shown that to be a basis one has to be able to write a write an unique spanning list we show that you can chop a spanning list of a space down to a basis or build a linearly independent list up to a basis because of this, you can make a spanning list of finite-dimensional vector spaces and chop it down to a basis: so every finite-dimensional vector space has a basis lastly, we can use the fact that you can grow list to basis to show that every subspace of \(V\) is a part of a direct sum equaling to \(V\) New Definitions basis and criteria for basis</span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhdirect_sum/"'><span class=top><h1><a class=noannot>direct sum</a></h1><span class="modbox right">Last edited: <span class=moddate>October 10, 2022</span></span></span>
<span class=summary>A direct sum is a sum of subspaces (not just subsets!!) where there&rsquo;s only one way to represent each element.
constituents subspaces of \(V\) named \(U_1, \dots, U_{m}\)
requirements The sum of subsets of \(U_1+\dots+U_{m}\) is called a direct sum IFF:
each element in \(U_1+\dots +U_{m}\) can only be written in one way as a sum \(u_1 +\dots +u_{m}\) (as in, they are linearly independent?)
We use \(\oplus\) to represent direct sum.</span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhbasis/"'><span class=top><h1><a class=noannot>basis</a></h1><span class="modbox right">Last edited: <span class=moddate>October 10, 2022</span></span></span>
<span class=summary>A basis is a list of vectors in \(V\) that spans \(V\) and is linearly independent
constituents a LIST! of vectors in vector space \(V\) requirements the list is&mldr; linear independent spans \(V\) additional information criteria for basis A list \(v_1, \dots v_{n}\) of vectors in \(V\) is a basis of \(V\) IFF every \(v \in V\) can be written uniquely as:
\begin{equation} v = a_1v_1+ \dots + a_{n}v_{n} \end{equation}</span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhlinear_independence/"'><span class=top><h1><a class=noannot>linear independence</a></h1><span class="modbox right">Last edited: <span class=moddate>October 10, 2022</span></span></span>
<span class=summary>A linearly independent list is a list of vectors such that there is one unique choice of scalars to be able to construct each member of their span.
Based on the same technique as in the proof that a sum of subsets is a direct sum IFF there is only one way to write \(0\), we can show that in a linearly independent list, there is (IFF) only one way to write the zero vector as a linear combination of that list of vectors &mdash;namely, the trivial representation of taking each vector to \(0\).</span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhnus_econ320_volatility_hedging/"'><span class=top><h1><a class=noannot>NUS-ECON320 Volatility Hedging</a></h1><span class="modbox right">Last edited: <span class=moddate>October 10, 2022</span></span></span>
<span class=summary>Let \(X\) denote price and \(Y\) denote volatility. The two objects obey the following process:
\begin{equation} \begin{cases} \dd{X} = \mu X \dd{t} + XY \dd{W} \\ \dd{Y} = \sigma Y \dd{B} \end{cases} \end{equation}
where, \(W\) and \(B\) are correlated Brownian motions with correlation \(\rho\) &mdash; \(E[(\dd{W})(\dd{B})] = \rho \dd{t}\).
Let&rsquo;s work with \(Y\) first. We understand that \(Y\) is some continuous variable \(e^{a}\). Therefore, \(\dv{Y}{t}=ae^{a}\). Therefore, \(dY = ae^{a}dt\). Finally, then \(\frac{\dd{Y}}{Y} = \frac{ae^{a}}{e^{a}}\dd{t} = a\).</span></div><ul class="pagination pagination-default"><li class=page-item><a href=/posts/ aria-label=First class=page-link role=button><span aria-hidden=true>⟸</span></a></li><li class=page-item><a href=/posts/page/36/ aria-label=Previous class=page-link role=button><span aria-hidden=true>⟵</span></a></li><li class=page-item><a href=/posts/page/35/ aria-label="Page 35" class=page-link role=button>35</a></li><li class=page-item><a href=/posts/page/36/ aria-label="Page 36" class=page-link role=button>36</a></li><li class="page-item active"><a aria-current=page aria-label="Page 37" class=page-link role=button>37</a></li><li class=page-item><a href=/posts/page/38/ aria-label="Page 38" class=page-link role=button>38</a></li><li class=page-item><a href=/posts/page/39/ aria-label="Page 39" class=page-link role=button>39</a></li><li class=page-item><a href=/posts/page/38/ aria-label=Next class=page-link role=button><span aria-hidden=true>⟶</span></a></li><li class=page-item><a href=/posts/page/126/ aria-label=Last class=page-link role=button><span aria-hidden=true>⟹</span></a></li></ul></main><footer><p id=footer>&copy; 2019-2023 Houjun Liu. Licensed CC BY-NC-SA 4.0.</p></footer></div></body></html>