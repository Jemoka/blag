<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Commissioner:wght@100;300;400;500;700&family=IBM+Plex+Sans:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css integrity="sha512-KfkfwYDsLkIlwQp6LFnl8zNdLGxu9YAA1QvwINks4PhcElQSvqcyVLLD9aMhXd13uQjoXtEKNosOWaZqXgel0g==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script>
<link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Jost:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script>
<script>window.MathJax={loader:{load:["[tex]/physics"]},tex:{packages:{"[+]":["physics"]}}}</script><title>Posts</title><meta name=author content="Houjun Liu"><link rel=stylesheet href=/css/global.css><link rel=stylesheet href=/css/syntax.css><link rel=alternate type=application/rss+xml href=/posts/index.xml title=jemoka.com></head><body><div class=center-clearfix><header><span id=header-name onclick='window.location.href="/"' style=cursor:pointer>Houjun Liu</span><div id=socialpanel><a href=https://www.jemoka.com/search/ class=header-social id=header-search><i class="ic fa-solid fa-magnifying-glass"></i></i></a>
<a href=https://github.com/Jemoka/ class=header-social id=header-github><i class="ic fa-brands fa-github"></i></a>
<a href=https://twitter.com/jemokajack class=header-social id=header-twitter><i class="ic fa-brands fa-twitter"></i></a>
<a href=https://www.reddit.com/user/Jemoka/ class=header-social id=header-reddit><i class="ic fa-brands fa-reddit"></i></a></div></header><main><div id=title><h1><span class=listhash>#</span>Posts</h1></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhlyu_2018/"'><span class=top><h1><a class=noannot>Lyu 2018</a></h1><span class="modbox right">Last edited: <span class=moddate>June 6, 2022</span></span></span>
<span class=summary>DOI: 10.1109/CISP-BMEI.2018.8633126
A dataset paper with which auditory info about people talking is collected.
Here are the state-of-the-art as of Laguarta 2021 on the dataset proposed.</span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhmartinc_2021/"'><span class=top><h1><a class=noannot>Martinc 2021</a></h1><span class="modbox right">Last edited: <span class=moddate>June 6, 2022</span></span></span>
<span class=summary>DOI: 10.3389/fnagi.2021.642647
One-Liner Combined bag-of-words on transcript + ADR on audio to various classifiers for AD; ablated BERT&rsquo;s decesion space for attention to make more easy models in the future.
Novelty Pre-processed each of the two modalities before fusing it (late fusion) Archieved \(93.75\%\) accuracy on AD detection The data being forced-aligned and fed with late fusion allows one to see what sounds/words the BERT model was focusing on by just focusing on the attention on the words Notable Methods Used classic cookie theft data bag of words to do ADR but for words multimodality but late fusion with one (hot-swappable) classifier Key Figs How they did it This is how the combined the forced aligned (:tada:) audio and transcript together.</span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhmeghanani_2021/"'><span class=top><h1><a class=noannot>Meghanani 2021</a></h1><span class="modbox right">Last edited: <span class=moddate>June 6, 2022</span></span></span>
<span class=summary>DOI: 10.3389/fcomp.2021.624558
One-Liner analyzed spontaneous speech transcripts (only!) from TD and AD patients with fastText and CNN; best was \(83.33\%\) acc.
Novelty threw the NLP kitchen sink to transcripts fastText CNN (with vary n-gram kernel 2,3,4,5 sizes) Notable Methods embeddings seaded by GloVe fastText are much faster, but CNN won out Key Figs the qual results PAR (participant), INV (investigator)
Notes Hey look a review of the field:</span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhmmse/"'><span class=top><h1><a class=noannot>Mini-Mental State Examination</a></h1><span class="modbox right">Last edited: <span class=moddate>June 6, 2022</span></span></span>
<span class=summary>MMSE is not mean squared error! It is a short mental state test to measure one&rsquo;s neuralpsycological capabilities; frequently used as a first line by a psycologist.</span></div><div class=pageview onclick='window.location.href="https://www.jemoka.com/posts/kbhopen_voice_brain_model/"'><span class=top><h1><a class=noannot>Open Voice Brain Model</a></h1><span class="modbox right">Last edited: <span class=moddate>June 6, 2022</span></span></span>
<span class=summary>The Open Voice Brain Model is a audio processing architecture proposed by Laguarta 2021 for audio/biomarker correlation work.
Here&rsquo;s a fairly self-explanatory figure:
The model outputs an AD diagnoses as well as a longitudinal correlation with Memory, Mood, and Respiratory biomarkers.
This is then the embedding that they are proposing for use by other tasks.</span></div><ul class="pagination pagination-default"><li class=page-item><a href=/posts/ aria-label=First class=page-link role=button><span aria-hidden=true>⟸</span></a></li><li class=page-item><a href=/posts/page/80/ aria-label=Previous class=page-link role=button><span aria-hidden=true>⟵</span></a></li><li class=page-item><a href=/posts/page/79/ aria-label="Page 79" class=page-link role=button>79</a></li><li class=page-item><a href=/posts/page/80/ aria-label="Page 80" class=page-link role=button>80</a></li><li class="page-item active"><a aria-current=page aria-label="Page 81" class=page-link role=button>81</a></li><li class=page-item><a href=/posts/page/82/ aria-label="Page 82" class=page-link role=button>82</a></li><li class=page-item><a href=/posts/page/83/ aria-label="Page 83" class=page-link role=button>83</a></li><li class=page-item><a href=/posts/page/82/ aria-label=Next class=page-link role=button><span aria-hidden=true>⟶</span></a></li><li class=page-item><a href=/posts/page/130/ aria-label=Last class=page-link role=button><span aria-hidden=true>⟹</span></a></li></ul></main><footer><p id=footer>&copy; 2019-2023 Houjun Liu. Licensed CC BY-NC-SA 4.0.</p></footer></div></body></html>