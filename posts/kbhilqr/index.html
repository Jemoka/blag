<!doctype html><html lang=en-us><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Commissioner:wght@100;300;400;500;700&family=IBM+Plex+Sans:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css integrity="sha512-Evv84Mr4kqVGRNSgIGL/F/aIDqQb7xQ2vcrdIwxfjThSH8CSR7PBEakCr51Ck+w+/U6swU2Im1vVX0SVk9ABhg==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Jost:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>window.MathJax={loader:{load:["[tex]/physics"]},tex:{packages:{"[+]":["physics"]}}}</script><title>Belief iLQR</title>
<meta name=description content="Motivation

Imperfect sensors in robot control: partial observations
Manipulators face tradeoff between sensing + acting

curse of dimensionality and curse of history.
Belief-Space Planning
Perhaps we should plan over all possible distributions of state space, making a belief-state MDP.
But: this is a nonlinear, stochastic dynamic. In fact: there maybe stochastic events that affects dynamics.
Big problem:

dim(belief) >> dim(state)
dim(belief) >> dim(action)

Belief iLQR
&ldquo;determinize and replan&rdquo;: simplify the dynamics at each step, plan, take action, and replan"><meta name=author content="Houjun Liu"><link rel=stylesheet href=/css/global.css><link rel=stylesheet href=/css/syntax.css></head><body><div class=center-clearfix><header><span id=header-name onclick='window.location.href="/"' style=cursor:pointer>Houjun Liu</span><div id=socialpanel><a href=https://www.jemoka.com/search/ class=header-social id=header-search><i class="ic fa-solid fa-magnifying-glass"></i></i></a>
<a href=https://github.com/Jemoka/ class=header-social id=header-github><i class="ic fa-brands fa-github"></i></a>
<a href=https://bsky.app/profile/jemoka.com class=header-social id=header-twitter><i class="ic fa-brands fa-bluesky"></i></a>
<a href=https://www.reddit.com/user/Jemoka/ class=header-social id=header-reddit><i class="ic fa-brands fa-reddit"></i></a></div></header><div id=title><h1>Belief iLQR</h1><span class=tagbox></span></div><aside id=toc><h1 id=toc-title>table of contents</h1><nav id=TableOfContents><ul><li><a href=#motivation>Motivation</a></li><li><a href=#belief-space-planning>Belief-Space Planning</a></li><li><a href=#belief-ilqr--kbhilqr-dot-md><a href=HAHAHUGOSHORTCODE584s6HBHB>Belief iLQR</a></a><ul><li><a href=#previous-work>Previous Work</a></li><li><a href=#approach>Approach</a></li></ul></li></ul></nav></aside><main><article><div><h2 id=motivation>Motivation</h2><ul><li>Imperfect sensors in robot control: <strong>partial observations</strong></li><li>Manipulators face tradeoff between <strong>sensing</strong> + <strong>acting</strong></li></ul><p><a href=/posts/kbhcurse_of_dimensionality/>curse of dimensionality</a> and curse of history.</p><h2 id=belief-space-planning>Belief-Space Planning</h2><p>Perhaps we should plan over all possible distributions of state space, making a <a href=/posts/kbhbelief_state_mdp/>belief-state MDP</a>.</p><p>But: this is a <strong>nonlinear</strong>, <strong>stochastic</strong> dynamic. In fact: there maybe stochastic events that affects dynamics.</p><p>Big problem:</p><ul><li>dim(<a href=/posts/kbhbelief/>belief</a>) >> dim(<a href>state</a>)</li><li>dim(<a href=/posts/kbhbelief/>belief</a>) >> dim(<a href=/posts/kbhaction_value_function/>action</a>)</li></ul><h2 id=belief-ilqr--kbhilqr-dot-md><a href=/posts/kbhilqr/>Belief iLQR</a></h2><p>&ldquo;determinize and replan&rdquo;: simplify the dynamics at each step, plan, take action, and replan</p><ol><li>tracks belief via observations</li><li>simplifies belief state dynamics based on linear <a href=/posts/kbhmaximum_likelihood_parameter_learning/>MLE</a></li></ol><p>When the dynamics is linear, you can use <a href=/posts/kbhlinear_quadratic_regulator/>Linear-Quadratic Regulator</a> to solve. This results in a worse policy but will give you a policy.</p><h3 id=previous-work>Previous Work</h3><ul><li>&ldquo;just solve most-likely state&rdquo;: doesn&rsquo;t take action to explore and understand the state.</li><li>&ldquo;belief roadmap&rdquo;: not really planning in the belief space itself</li></ul><h3 id=approach>Approach</h3><h4 id=belief-update>Belief Update</h4><p>We use Baysian updates for the state probably updates:</p><p>\begin{equation}
P(s_{t+1}) = \eta P(o_{t+1}|s_{t+1}) \int_{x} p(_{t+1}|x, a_{t}) P(s)
\end{equation}</p><p>and then the actual beliefs are updated with <a href=/posts/kbhfilters/#extended>Extended Kalman Filter</a>.</p><p>Importantly, the <a href=/posts/kbhfilters/#extended>Extended Kalman Filter</a> usually requires us to take an expectation of each observation O over all O; instead, we assume that the future states are uniform linearly distributed.</p><h4 id=belief-update-cost>Belief Update Cost</h4><p>Ideally, we want to lower <a href=/posts/kbhcovariance/>covariance</a> of the <a href=/posts/kbhbelief/>belief</a> vectors in order to be more confident.</p><figure><img src=/ox-hugo/2024-02-20_09-32-34_screenshot.png></figure><ol><li>first term: reduce large trajectories (verify)</li><li>second: stabilization</li></ol><h4 id=replanning-strategy>Replanning Strategy</h4><figure><img src=/ox-hugo/2024-02-20_09-35-47_screenshot.png></figure><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#00a8c8>while</span> <span style=color:#111>b</span> <span style=color:#f92672>not</span> <span style=color:#111>at</span> <span style=color:#111>goal</span><span style=color:#111>:</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># replan at where we are at now</span>
</span></span><span style=display:flex><span>    <span style=color:#111>(</span><span style=color:#111>b</span><span style=color:#111>,</span> <span style=color:#111>a</span><span style=color:#111>,</span> <span style=color:#111>mean_b</span><span style=color:#111>)</span> <span style=color:#f92672>=</span> <span style=color:#111>create_initial_plan</span><span style=color:#111>(</span><span style=color:#111>b</span><span style=color:#111>);</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#00a8c8>for</span> <span style=color:#111>depth</span> <span style=color:#111>d</span><span style=color:#111>:</span>
</span></span><span style=display:flex><span>        <span style=color:#111>a_t</span> <span style=color:#f92672>=</span> <span style=color:#111>solve_lqr_for_plan_at_time</span><span style=color:#111>(</span><span style=color:#111>b</span><span style=color:#111>,</span> <span style=color:#111>a</span><span style=color:#111>,</span> <span style=color:#111>mean_b</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span>        <span style=color:#111>o</span> <span style=color:#f92672>=</span> <span style=color:#111>environment</span><span style=color:#f92672>.</span><span style=color:#111>step</span><span style=color:#111>(</span><span style=color:#111>a_t</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span>        <span style=color:#111>b</span> <span style=color:#f92672>=</span> <span style=color:#111>extended_kalman</span><span style=color:#111>(</span><span style=color:#111>b</span><span style=color:#111>,</span> <span style=color:#111>a</span><span style=color:#111>,</span> <span style=color:#111>o</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#00a8c8>if</span> <span style=color:#111>mean</span><span style=color:#111>(</span><span style=color:#111>b</span><span style=color:#111>)</span> <span style=color:#f92672>&gt;</span> <span style=color:#111>max_allowed_belief_uncertainty</span><span style=color:#111>:</span>
</span></span><span style=display:flex><span>            <span style=color:#00a8c8>break</span>
</span></span></code></pre></div></div></article></main><footer><p id=footer>&copy; 2019-2025 Houjun Liu. Licensed CC BY-NC-SA 4.0.</p></footer></div></body></html>