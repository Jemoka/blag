<!doctype html><html lang=en-us><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Commissioner:wght@100;300;400;500;700&family=IBM+Plex+Sans:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css integrity="sha512-KfkfwYDsLkIlwQp6LFnl8zNdLGxu9YAA1QvwINks4PhcElQSvqcyVLLD9aMhXd13uQjoXtEKNosOWaZqXgel0g==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Jost:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>window.MathJax={loader:{load:["[tex]/physics"]},tex:{packages:{"[+]":["physics"]}}}</script><title>belief</title>
<meta name=description content="belief is a probability distribution over your states.
\begin{equation} b \leftarrow update(b,a,o) \end{equation}
we want to create a Baysian Network to represent our situation. For instance, say for a speech recognition task:
if we have state certainty, the states &ldquo;lonely, Starbucks, lovers&rdquo; converges to:
This is a HMM! The only difference between something like this and a normal Markov Decision Process is that each state hangs an observation:
which for us is the sound waves."><meta name=author content="Houjun Liu"><link rel=stylesheet href=/css/global.css><link rel=stylesheet href=/css/syntax.css></head><body><div class=center-clearfix><header><span id=header-name onclick='window.location.href="/"' style=cursor:pointer>Houjun Liu</span><div id=socialpanel><a href=https://www.jemoka.com/search/ class=header-social id=header-search><i class="ic fa-solid fa-magnifying-glass"></i></i></a>
<a href=https://github.com/Jemoka/ class=header-social id=header-github><i class="ic fa-brands fa-github"></i></a>
<a href=https://maly.io/@jemoka class=header-social id=header-twitter><i class="ic fa-brands fa-mastodon"></i></a>
<a href=https://www.reddit.com/user/Jemoka/ class=header-social id=header-reddit><i class="ic fa-brands fa-reddit"></i></a></div></header><div id=title><h1>belief</h1><span class=tagbox></span></div><aside id=toc><h1 id=toc-title>table of contents</h1><nav id=TableOfContents><ul><li><a href=#observation-model>observation model</a><ul><li><a href=#error-model>error model</a></li><li><a href=#filters--kbhfilters-dot-md><a href=HAHAHUGOSHORTCODE137s10HBHB>filters</a></a></li></ul></li></ul></nav></aside><main><article><div><p><a href=/posts/kbhbelief/>belief</a> is a <a href=/posts/kbhprobability_distributions/>probability distribution</a> over your states.</p><p>\begin{equation}
b \leftarrow update(b,a,o)
\end{equation}</p><p>we want to create a <a href=/posts/kbhbaysian_network/>Baysian Network</a> to represent our situation. For instance, say for a speech recognition task:</p><p>if we have state certainty, the states &ldquo;lonely, Starbucks, lovers&rdquo; converges to:</p><figure><img src=/ox-hugo/2023-11-09_09-50-38_screenshot.png></figure><p>This is a <a href=/posts/kbhhidden_markov_model/>HMM</a>! The only difference between something like this and a normal <a href=/posts/kbhmarkov_decision_process/>Markov Decision Process</a> is that each state hangs an observation:</p><figure><img src=/ox-hugo/2023-11-09_09-52-58_screenshot.png></figure><p>which for us is the sound waves. This means that we describe a <a href=/posts/kbhpartially_observable_markov_decision_process/>POMDP</a> with three expressions:</p><ul><li>\(T(s&rsquo;|s,a)\)</li><li>\(R(s,a)\)</li></ul><p>this is just one more expression than an <a href=/posts/kbhmarkov_decision_process/>MDP</a>; we take need the third expression because we may not know \(s\) directly, because we only get to observe \(O\) and not \(s\).</p><h2 id=observation-model>observation model</h2><p>\(O(o|a,s&rsquo;)\) is a model for what observations we may get if we are in a particular state/action.</p><h3 id=error-model>error model</h3><p>there is some model which is a probability distribution over the state given observation:</p><figure><img src=/ox-hugo/2023-11-09_10-01-10_screenshot.png></figure><p>let orange \(d\) be state, the green would be the <a href=#error-model>error model</a></p><h3 id=filters--kbhfilters-dot-md><a href=/posts/kbhfilters/>filters</a></h3><p><a href=/posts/kbhfilters/>filters</a> are how <a href=/posts/kbhbelief/>belief</a>s are updated from observation. &ldquo;we want to perform localization&rdquo;</p></div></article></main><footer><p id=footer>&copy; 2019-2023 Houjun Liu. Licensed CC BY-NC-SA 4.0.</p></footer></div></body></html>