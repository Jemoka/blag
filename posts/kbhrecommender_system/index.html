<!doctype html><html lang=en-us><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Commissioner:wght@100;300;400;500;700&family=IBM+Plex+Sans:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css integrity="sha512-KfkfwYDsLkIlwQp6LFnl8zNdLGxu9YAA1QvwINks4PhcElQSvqcyVLLD9aMhXd13uQjoXtEKNosOWaZqXgel0g==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Jost:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>window.MathJax={loader:{load:["[tex]/physics"]},tex:{packages:{"[+]":["physics"]}}}</script><title>Recommender System</title>
<meta name=description content="Recommender System is a system that provide recommendations due to search; it combines Information Retrival with another goal:

Editorial/Hand-Curated lists: &ldquo;list of favorites&rdquo;, &ldquo;essential items&rdquo;, etc.
Aggregates: top 10 lists, most popular, recent uploads
(hardest) Individual tailors: user-based recommendation

Formal Model

\(X\) the set of users
\(S\) the set of things to recommend
\(R\) the set of distinct and totally ordered ratings  (stars 1-5, real number 0-1, etc.)
Utility function: \(U:X \times S \to R\) (&ldquo;how much

Three key problems:"><meta name=author content="Houjun Liu"><link rel=stylesheet href=/css/global.css><link rel=stylesheet href=/css/syntax.css></head><body><div class=center-clearfix><header><span id=header-name onclick='window.location.href="/"' style=cursor:pointer>Houjun Liu</span><div id=socialpanel><a href=https://www.jemoka.com/search/ class=header-social id=header-search><i class="ic fa-solid fa-magnifying-glass"></i></i></a>
<a href=https://github.com/Jemoka/ class=header-social id=header-github><i class="ic fa-brands fa-github"></i></a>
<a href=https://maly.io/@jemoka class=header-social id=header-twitter><i class="ic fa-brands fa-mastodon"></i></a>
<a href=https://www.reddit.com/user/Jemoka/ class=header-social id=header-reddit><i class="ic fa-brands fa-reddit"></i></a></div></header><div id=title><h1>Recommender System</h1><span class=tagbox></span></div><aside id=toc><h1 id=toc-title>table of contents</h1><nav id=TableOfContents><ul><li><a href=#formal-model>Formal Model</a></li><li><a href=#obtaining-u>obtaining \(U\)</a></li><li><a href=#extrapolating-u>extrapolating \(U\)</a><ul><li><a href=#content-based-filtering>content based filtering</a></li><li><a href=#collaborative-filtering>collaborative filtering</a></li><li><a href=#latent-factor--neural--systems>latent factor (neural) systems</a></li></ul></li><li><a href=#evaluation>evaluation</a></li></ul></nav></aside><main><article><div><p><a href=/posts/kbhrecommender_system/>Recommender System</a> is a system that provide recommendations due to search; it combines <a href=/posts/kbhinformation_retrival/>Information Retrival</a> with another goal:</p><ul><li><strong>Editorial/Hand-Curated lists</strong>: &ldquo;list of favorites&rdquo;, &ldquo;essential items&rdquo;, etc.</li><li><strong>Aggregates</strong>: top 10 lists, most popular, recent uploads</li><li>(hardest) <strong>Individual tailors</strong>: user-based recommendation</li></ul><h2 id=formal-model>Formal Model</h2><ul><li>\(X\) the set of users</li><li>\(S\) the set of things to recommend</li><li>\(R\) the set of distinct and totally ordered ratings (stars 1-5, real number 0-1, etc.)</li><li>Utility function: \(U:X \times S \to R\) (&ldquo;how much</li></ul><p>Three key problems:</p><ul><li><strong>obtain</strong> \(U\) as much as possible, leaving something blank</li><li><strong>extrapolate</strong> blank entries in \(U\) which maybe high (&ldquo;recommend something&rdquo;)</li><li><strong>evaluate</strong> our recommendation method</li></ul><h2 id=obtaining-u>obtaining \(U\)</h2><ul><li>ask people (rate!)</li><li>implicit signals (buying book, picking song, watching video, etc.)&mdash;this will create a binary matrix</li></ul><h2 id=extrapolating-u>extrapolating \(U\)</h2><p>\(U\) is sparse (people can&rsquo;t rate everything).</p><p><strong>Cold Start problem</strong>:</p><ul><li>new items have no ratings</li><li>new users have no history</li></ul><p><strong>Three Main Approaches</strong>:</p><h3 id=content-based-filtering>content based filtering</h3><p><strong>Recommend \(s\) to \(x\) if \(s \sim s&rsquo;\) based on content where \(s&rsquo;\) is already rated highly by \(x\)</strong></p><p>(&ldquo;if the user likes Jazz, given them more Jazz&rdquo;)</p><ol><li>create profile of each item (movie: genre, actor, years; lexicon: important words by <a href=/posts/kbhranked_information_retrieval/#tf-idf>TF-IDF</a>; etc)</li><li>create profile of user, say by averaging ratings of the things the user marked as high</li><li>cosine similarity</li></ol><hr><p>Advantages:</p><ul><li>no need for data on other users (no user sparsity)</li><li>able to tailor to unique tastes</li><li>able to recommend new and unpopular things</li><li>transparent</li></ul><p>Disadvantages:</p><ul><li>need to build a profile for user</li><li>overspecialization (never recommend outside of user&rsquo;s preferences)</li><li>unable to exploit other users&rsquo; judgments</li><li>finding good features is hard</li></ul><h3 id=collaborative-filtering>collaborative filtering</h3><p>Instead of using content features of items to recommend, we find user instead.</p><h4 id=user-user-collaborative-filtering--orga6897ce>user-user <a href=#collaborative-filtering>collaborative filtering</a></h4><p>Consider a user \(x\), and some set of unrated items \(i\).</p><p>Let&rsquo;s find \(N\) other users with similar ratings: 1) find similar users and 2) recommend items they like.</p><p>Then, we estimate \(x\)&rsquo;s ratings for \(i\) based on the similar users&rsquo; ratings for \(i\).</p><ul><li><p>problem</p><p>because the sparsity of the user vectors which we treat as \(0\), cosine gets confused. Cosine doesn&rsquo;t really capture the &ldquo;oppositeness&rdquo; of a 5 star vs a 1 star rating.</p><p>solution: <strong>mean center</strong> each user&mdash;subtracting each user&rsquo;s score from their mean rating (ignoring missing values, and do not subtract anything to the missing values). This allows opposite opinions to have opposite signs as well.</p></li></ul><ul><li><p>sparsity</p><p>we prevent computing values for which one user does not rate; as in, we chop the vectors such that the comparison between \(x\) and \(x_{n} \in X\) are both dense (i.e. if one of the two users don&rsquo;t rate something, we do not include that in the vector).</p><p>after this, we can compute our normal cosine similarity; remember to normalise.</p></li></ul><ul><li><p>prediction</p><p>finally, after we got our \(N\), we can return our prediction for \(I\) either based on an average score of the similar users retrieved in \(N\) or average weighted of scores in \(N\) weighted by similarity to our target user \(x\).</p><p>\begin{equation}
r_{xi} = \frac{1}{N} \sum_{}^{} r_{yi}
\end{equation}</p><p>or</p><p>\begin{equation}
r_{xi} = \sum_{}^{} \frac{sim(x,y) r_{yi}}{sim(x,y)}
\end{equation}</p></li></ul><h4 id=item-item-collaborative-filtering--orga6897ce>item-item <a href=#collaborative-filtering>collaborative filtering</a></h4><p>For item \(i\), we want to find other similar <strong>items</strong> to our item \(i\), and average the user&rsquo;s own ratings on those similar items onto \(i\).</p><p>this tends to work better because items are easier to classify than users.</p><ul><li><p>problem</p><ul><li>cold start (we need initial data to seed the rating)</li><li>sparsity (user ratings are sparse)</li><li>popularity bias&mdash;creates filter bubbles and hard to generalize over unique tastes</li></ul></li></ul><h3 id=latent-factor--neural--systems>latent factor (neural) systems</h3><ol><li>represent each video and user as an embedding</li><li><a href=#collaborative-filtering>collaborative filtering</a>.</li></ol><p>YouTube obtains this embedding by predicting what video user is going to watch</p><h2 id=evaluation>evaluation</h2><p>RMSE between held out ratings:</p><p>\begin{equation}
\sqrt{\frac{\sum_{xi}^{}(r_{xi} - r^{*}_{xi})^{2}}{N}}
\end{equation}</p></div></article></main><footer><p id=footer>&copy; 2019-2024 Houjun Liu. Licensed CC BY-NC-SA 4.0.</p></footer></div></body></html>