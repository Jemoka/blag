<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Commissioner:wght@100;300;400;500;700&family=IBM+Plex+Sans:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css integrity="sha512-KfkfwYDsLkIlwQp6LFnl8zNdLGxu9YAA1QvwINks4PhcElQSvqcyVLLD9aMhXd13uQjoXtEKNosOWaZqXgel0g==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script>
<link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Jost:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script>
<script>window.MathJax={loader:{load:["[tex]/physics"]},tex:{packages:{"[+]":["physics"]}}}</script><title>NUS-ECON320 Currency Arbitrage</title><meta name=description content="Let&rsquo;s import some tools.
import pandas as pd from scipy.optimize import minimize import numpy as np from datetime import datetime from tqdm import tqdm import torch tqdm.pandas() And load our data:
df = pd.read_csv(&#34;./currency_signal.csv&#34;, index_col=0, header=None, parse_dates=[0]) df 1 0 2006-03-01 0.000050 2006-03-02 0.001778 2006-03-03 0.000116 2006-03-06 -0.001038 2006-03-07 -0.001197 ... ... 2020-05-18 0.000264 2020-05-19 0.001434 2020-05-20 0.000995 2020-05-21 0.000120 2020-05-22 0.000424 [3713 rows x 1 columns] Let&rsquo;s rename the headers"><meta name=author content="Houjun Liu"><link rel=stylesheet href=/css/global.css><link rel=stylesheet href=/css/syntax.css></head><body><div class=center-clearfix><header><span id=header-name onclick='window.location.href="/"' style=cursor:pointer>Houjun Liu</span><div id=socialpanel><a href=https://www.jemoka.com/search/ class=header-social id=header-search><i class="ic fa-solid fa-magnifying-glass"></i></i></a>
<a href=https://github.com/Jemoka/ class=header-social id=header-github><i class="ic fa-brands fa-github"></i></a>
<a href=https://twitter.com/jemokajack class=header-social id=header-twitter><i class="ic fa-brands fa-twitter"></i></a>
<a href=https://www.reddit.com/user/Jemoka/ class=header-social id=header-reddit><i class="ic fa-brands fa-reddit"></i></a></div></header><div id=title><h1>NUS-ECON320 Currency Arbitrage</h1><span class=tagbox></span></div><main><article><div><p>Let&rsquo;s import some tools.</p><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> <span style=color:#111>pandas</span> <span style=color:#00a8c8>as</span> <span style=color:#111>pd</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> <span style=color:#111>scipy.optimize</span> <span style=color:#f92672>import</span> <span style=color:#111>minimize</span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> <span style=color:#111>numpy</span> <span style=color:#00a8c8>as</span> <span style=color:#111>np</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> <span style=color:#111>datetime</span> <span style=color:#f92672>import</span> <span style=color:#111>datetime</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> <span style=color:#111>tqdm</span> <span style=color:#f92672>import</span> <span style=color:#111>tqdm</span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> <span style=color:#111>torch</span>
</span></span><span style=display:flex><span><span style=color:#111>tqdm</span><span style=color:#f92672>.</span><span style=color:#111>pandas</span><span style=color:#111>()</span>
</span></span></code></pre></div><p>And load our data:</p><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#111>df</span> <span style=color:#f92672>=</span> <span style=color:#111>pd</span><span style=color:#f92672>.</span><span style=color:#111>read_csv</span><span style=color:#111>(</span><span style=color:#d88200>&#34;./currency_signal.csv&#34;</span><span style=color:#111>,</span> <span style=color:#111>index_col</span><span style=color:#f92672>=</span><span style=color:#ae81ff>0</span><span style=color:#111>,</span> <span style=color:#111>header</span><span style=color:#f92672>=</span><span style=color:#00a8c8>None</span><span style=color:#111>,</span> <span style=color:#111>parse_dates</span><span style=color:#f92672>=</span><span style=color:#111>[</span><span style=color:#ae81ff>0</span><span style=color:#111>])</span>
</span></span><span style=display:flex><span><span style=color:#111>df</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>                   1
</span></span><span style=display:flex><span>0
</span></span><span style=display:flex><span>2006-03-01  0.000050
</span></span><span style=display:flex><span>2006-03-02  0.001778
</span></span><span style=display:flex><span>2006-03-03  0.000116
</span></span><span style=display:flex><span>2006-03-06 -0.001038
</span></span><span style=display:flex><span>2006-03-07 -0.001197
</span></span><span style=display:flex><span>...              ...
</span></span><span style=display:flex><span>2020-05-18  0.000264
</span></span><span style=display:flex><span>2020-05-19  0.001434
</span></span><span style=display:flex><span>2020-05-20  0.000995
</span></span><span style=display:flex><span>2020-05-21  0.000120
</span></span><span style=display:flex><span>2020-05-22  0.000424
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>[3713 rows x 1 columns]
</span></span></code></pre></div><p>Let&rsquo;s rename the headers</p><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#111>df</span><span style=color:#f92672>.</span><span style=color:#111>index</span><span style=color:#f92672>.</span><span style=color:#111>rename</span><span style=color:#111>(</span><span style=color:#d88200>&#34;date&#34;</span><span style=color:#111>,</span> <span style=color:#00a8c8>True</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span><span style=color:#111>df</span><span style=color:#f92672>.</span><span style=color:#111>columns</span> <span style=color:#f92672>=</span> <span style=color:#111>[</span><span style=color:#d88200>&#34;value&#34;</span><span style=color:#111>]</span>
</span></span></code></pre></div><p>Awesome. For the rest of the calculations, we will hide the 2020 data from the model:</p><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#111>data</span> <span style=color:#f92672>=</span> <span style=color:#111>df</span><span style=color:#111>[</span><span style=color:#111>df</span><span style=color:#f92672>.</span><span style=color:#111>index</span> <span style=color:#f92672>&lt;</span> <span style=color:#111>datetime</span><span style=color:#111>(</span><span style=color:#ae81ff>2020</span><span style=color:#111>,</span> <span style=color:#ae81ff>1</span><span style=color:#111>,</span><span style=color:#ae81ff>1</span><span style=color:#111>)]</span>
</span></span><span style=display:flex><span><span style=color:#111>data</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>               value
</span></span><span style=display:flex><span>date
</span></span><span style=display:flex><span>2006-03-01  0.000050
</span></span><span style=display:flex><span>2006-03-02  0.001778
</span></span><span style=display:flex><span>2006-03-03  0.000116
</span></span><span style=display:flex><span>2006-03-06 -0.001038
</span></span><span style=display:flex><span>2006-03-07 -0.001197
</span></span><span style=display:flex><span>...              ...
</span></span><span style=display:flex><span>2019-12-25 -0.010659
</span></span><span style=display:flex><span>2019-12-26 -0.000869
</span></span><span style=display:flex><span>2019-12-27  0.000075
</span></span><span style=display:flex><span>2019-12-30  0.000033
</span></span><span style=display:flex><span>2019-12-31  0.000944
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>[3610 rows x 1 columns]
</span></span></code></pre></div><p>we will add a column of randomness to this, to serve as the seed of our epsilon:</p><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#111>data</span><span style=color:#111>[</span><span style=color:#d88200>&#34;epsilon&#34;</span><span style=color:#111>]</span> <span style=color:#f92672>=</span> <span style=color:#111>np</span><span style=color:#f92672>.</span><span style=color:#111>random</span><span style=color:#f92672>.</span><span style=color:#111>normal</span><span style=color:#111>(</span><span style=color:#ae81ff>0</span><span style=color:#111>,</span><span style=color:#ae81ff>1</span><span style=color:#111>,</span> <span style=color:#111>data</span><span style=color:#f92672>.</span><span style=color:#111>shape</span><span style=color:#111>[</span><span style=color:#ae81ff>0</span><span style=color:#111>])</span>
</span></span><span style=display:flex><span><span style=color:#111>data</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>               value   epsilon
</span></span><span style=display:flex><span>date
</span></span><span style=display:flex><span>2006-03-01  0.000050  0.907060
</span></span><span style=display:flex><span>2006-03-02  0.001778 -0.679389
</span></span><span style=display:flex><span>2006-03-03  0.000116  0.930653
</span></span><span style=display:flex><span>2006-03-06 -0.001038 -0.357563
</span></span><span style=display:flex><span>2006-03-07 -0.001197 -2.583978
</span></span><span style=display:flex><span>...              ...       ...
</span></span><span style=display:flex><span>2019-12-25 -0.010659 -0.967139
</span></span><span style=display:flex><span>2019-12-26 -0.000869 -2.435896
</span></span><span style=display:flex><span>2019-12-27  0.000075  2.511539
</span></span><span style=display:flex><span>2019-12-30  0.000033 -0.434153
</span></span><span style=display:flex><span>2019-12-31  0.000944 -0.990262
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>[3610 rows x 2 columns]
</span></span></code></pre></div><p>Awesome, we will now seed three parameter variables. Recall that the GARCH model we are dealing with is:</p><p>\begin{equation}
\begin{cases}
n_t = \sigma_{t}\epsilon_{t} \\
{\sigma_{t}}^{2} = \alpha {n_{t}}^{2} + \beta {\sigma_{t-1}}^{2} + \gamma
\end{cases}
\end{equation}</p><p>Solving for explicit solutions of \(n_t\) and \(\sigma_t\), in terms of the others using computer algebra, we have:</p><p>\begin{equation}
\sigma_{t} = \sqrt{-\frac{\beta \mathit{\sigma_{t-1}}^{2} + y}{\alpha \epsilon^{2} - 1}}
\end{equation}</p><p>The value of \(n_t\) is naturally \(\sigma_t \epsilon_t\).</p><p>Now, we can now compute a column of these, based on the data we have. To be able to optimize this symbolically, we will leverage PyTorch.</p><p>Let&rsquo;s seed these constants all at \(1\), to be optimized later:</p><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#111>a</span> <span style=color:#f92672>=</span> <span style=color:#111>torch</span><span style=color:#f92672>.</span><span style=color:#111>tensor</span><span style=color:#111>(</span><span style=color:#ae81ff>0.001</span><span style=color:#111>,</span> <span style=color:#111>requires_grad</span><span style=color:#f92672>=</span><span style=color:#00a8c8>True</span><span style=color:#111>,</span> <span style=color:#111>dtype</span><span style=color:#f92672>=</span><span style=color:#111>torch</span><span style=color:#f92672>.</span><span style=color:#111>cfloat</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span><span style=color:#111>b</span> <span style=color:#f92672>=</span> <span style=color:#111>torch</span><span style=color:#f92672>.</span><span style=color:#111>tensor</span><span style=color:#111>(</span><span style=color:#ae81ff>0.001</span><span style=color:#111>,</span> <span style=color:#111>requires_grad</span><span style=color:#f92672>=</span><span style=color:#00a8c8>True</span><span style=color:#111>,</span> <span style=color:#111>dtype</span><span style=color:#f92672>=</span><span style=color:#111>torch</span><span style=color:#f92672>.</span><span style=color:#111>cfloat</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span><span style=color:#111>y</span> <span style=color:#f92672>=</span> <span style=color:#111>torch</span><span style=color:#f92672>.</span><span style=color:#111>tensor</span><span style=color:#111>(</span><span style=color:#ae81ff>0.001</span><span style=color:#111>,</span> <span style=color:#111>requires_grad</span><span style=color:#f92672>=</span><span style=color:#00a8c8>True</span><span style=color:#111>,</span> <span style=color:#111>dtype</span><span style=color:#f92672>=</span><span style=color:#111>torch</span><span style=color:#f92672>.</span><span style=color:#111>cfloat</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#111>(</span><span style=color:#111>a</span><span style=color:#111>,</span><span style=color:#111>b</span><span style=color:#111>,</span><span style=color:#111>y</span><span style=color:#111>)</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>(tensor(0.0010+0.j, requires_grad=True), tensor(0.0010+0.j, requires_grad=True), tensor(0.0010+0.j, requires_grad=True))
</span></span></code></pre></div><p>We use the complex data type here to make the subtract operation work. We will eventually project it down to real space without much trouble.</p><p>Awesome, let us compute this series of \(\sigma\), and optimize for the loss.</p><p>Here is a gradient descent optimizer:</p><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># we will use the gradient descent scheme</span>
</span></span><span style=display:flex><span><span style=color:#111>optimizer</span> <span style=color:#f92672>=</span> <span style=color:#111>torch</span><span style=color:#f92672>.</span><span style=color:#111>optim</span><span style=color:#f92672>.</span><span style=color:#111>SGD</span><span style=color:#111>([</span><span style=color:#111>a</span><span style=color:#111>,</span><span style=color:#111>b</span><span style=color:#111>,</span><span style=color:#111>y</span><span style=color:#111>],</span> <span style=color:#111>lr</span><span style=color:#f92672>=</span><span style=color:#ae81ff>0.1</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#111>optimizer</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>SGD (
</span></span><span style=display:flex><span>Parameter Group 0
</span></span><span style=display:flex><span>    dampening: 0
</span></span><span style=display:flex><span>    differentiable: False
</span></span><span style=display:flex><span>    foreach: None
</span></span><span style=display:flex><span>    lr: 0.1
</span></span><span style=display:flex><span>    maximize: False
</span></span><span style=display:flex><span>    momentum: 0
</span></span><span style=display:flex><span>    nesterov: False
</span></span><span style=display:flex><span>    weight_decay: 0
</span></span><span style=display:flex><span>)
</span></span></code></pre></div><p>And now, for 1000 steps, we will minimize the difference between the computed \(n\) and actual value against \(\alpha, \beta, \gamma\). We will run the scheme for 50 steps.</p><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#00a8c8>for</span> <span style=color:#111>_</span> <span style=color:#f92672>in</span> <span style=color:#111>tqdm</span><span style=color:#111>(</span><span style=color:#111>range</span><span style=color:#111>(</span><span style=color:#ae81ff>50</span><span style=color:#111>)):</span>
</span></span><span style=display:flex><span>    <span style=color:#111>loss</span> <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>    <span style=color:#111>prev_sigma</span> <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># # for each row</span>
</span></span><span style=display:flex><span>    <span style=color:#00a8c8>for</span> <span style=color:#111>i</span> <span style=color:#f92672>in</span> <span style=color:#111>range</span><span style=color:#111>(</span><span style=color:#111>len</span><span style=color:#111>(</span><span style=color:#111>data</span><span style=color:#111>)):</span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># get previous value, or seed at 0</span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># if it doesn&#39;t exist</span>
</span></span><span style=display:flex><span>        <span style=color:#111>prev_sigma</span> <span style=color:#f92672>=</span> <span style=color:#111>((</span><span style=color:#f92672>-</span><span style=color:#111>(</span><span style=color:#111>b</span><span style=color:#f92672>*</span><span style=color:#111>prev_sigma</span><span style=color:#f92672>**</span><span style=color:#ae81ff>2</span><span style=color:#f92672>+</span><span style=color:#111>y</span><span style=color:#111>)</span><span style=color:#f92672>/</span><span style=color:#111>(</span><span style=color:#111>a</span><span style=color:#f92672>*</span><span style=color:#111>data</span><span style=color:#111>[</span><span style=color:#d88200>&#34;epsilon&#34;</span><span style=color:#111>]</span><span style=color:#f92672>.</span><span style=color:#111>iloc</span><span style=color:#111>[</span><span style=color:#111>i</span><span style=color:#111>]</span><span style=color:#f92672>**</span><span style=color:#ae81ff>2</span><span style=color:#f92672>-</span><span style=color:#ae81ff>1</span><span style=color:#111>))</span><span style=color:#f92672>**</span><span style=color:#ae81ff>0.5</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span>        <span style=color:#111>n</span> <span style=color:#f92672>=</span> <span style=color:#111>prev_sigma</span><span style=color:#f92672>*</span><span style=color:#111>data</span><span style=color:#111>[</span><span style=color:#d88200>&#34;epsilon&#34;</span><span style=color:#111>]</span><span style=color:#f92672>.</span><span style=color:#111>iloc</span><span style=color:#111>[</span><span style=color:#111>i</span><span style=color:#111>]</span>
</span></span><span style=display:flex><span>        <span style=color:#111>loss</span> <span style=color:#f92672>+=</span> <span style=color:#111>(</span><span style=color:#111>n</span><span style=color:#f92672>-</span><span style=color:#111>data</span><span style=color:#111>[</span><span style=color:#d88200>&#34;value&#34;</span><span style=color:#111>]</span><span style=color:#f92672>.</span><span style=color:#111>iloc</span><span style=color:#111>[</span><span style=color:#111>i</span><span style=color:#111>])</span><span style=color:#f92672>**</span><span style=color:#ae81ff>2</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># print the loss</span>
</span></span><span style=display:flex><span>    <span style=color:#111>print</span><span style=color:#111>(</span><span style=color:#111>loss</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># backpropegate the loss</span>
</span></span><span style=display:flex><span>    <span style=color:#111>loss</span><span style=color:#f92672>.</span><span style=color:#111>backward</span><span style=color:#111>()</span>
</span></span><span style=display:flex><span>    <span style=color:#111>optimizer</span><span style=color:#f92672>.</span><span style=color:#111>step</span><span style=color:#111>()</span>
</span></span><span style=display:flex><span>    <span style=color:#111>optimizer</span><span style=color:#f92672>.</span><span style=color:#111>zero_grad</span><span style=color:#111>()</span>
</span></span></code></pre></div><p>These values continue to be imaginary, which we will discuss next time.</p></div></article></main><footer><p id=footer>&copy; 2019-2022 Houjun Liu. Licensed CC BY-NC-SA 4.0.</p></footer></div></body></html>