<!doctype html><html lang=en-us><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Commissioner:wght@100;300;400;500;700&family=IBM+Plex+Sans:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css integrity="sha512-Evv84Mr4kqVGRNSgIGL/F/aIDqQb7xQ2vcrdIwxfjThSH8CSR7PBEakCr51Ck+w+/U6swU2Im1vVX0SVk9ABhg==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Jost:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>window.MathJax={loader:{load:["[tex]/physics"]},tex:{packages:{"[+]":["physics"]}}}</script><title>Direct Sampling</title>
<meta name=description content="Direct Sampling is the act in probability to sample what you want from the distribution. This is often used when actual inference impossible. It involves. well. sampling from the distribution to compute a conditional probability that you want.
It basically involves invoking the Frequentist Definition of Probability without letting \(n \to \infty\), instead just sampling some \(n < \infty\) and dividing the event space by your sample space.
So, for instance, to compute inference on \(b^{1}\) given observations \(d^{1}c^{1}\), we can write:"><meta name=author content="Houjun Liu"><link rel=stylesheet href=/css/global.css><link rel=stylesheet href=/css/syntax.css></head><body><div class=center-clearfix><header><span id=header-name onclick='window.location.href="/"' style=cursor:pointer>Houjun Liu</span><div id=socialpanel><a href=https://www.jemoka.com/search/ class=header-social id=header-search><i class="ic fa-solid fa-magnifying-glass"></i></i></a>
<a href=https://github.com/Jemoka/ class=header-social id=header-github><i class="ic fa-brands fa-github"></i></a>
<a href=https://bsky.app/profile/jemoka.com class=header-social id=header-twitter><i class="ic fa-brands fa-bluesky"></i></a>
<a href=https://www.reddit.com/user/Jemoka/ class=header-social id=header-reddit><i class="ic fa-brands fa-reddit"></i></a></div></header><div id=title><h1>Direct Sampling</h1><span class=tagbox></span></div><aside id=toc><h1 id=toc-title>table of contents</h1><nav id=TableOfContents><ul><li><a href=#direct-sampling-a-baysian-network--kbhbaysian-network-dot-md>Direct Sampling a <a href=HAHAHUGOSHORTCODE367s7HBHB>Baysian Network</a></a></li><li><a href=#likelihood-weighted-sampling>Likelihood Weighted Sampling</a></li></ul></nav></aside><main><article><div><p><a href=/posts/kbhdirect_sampling/>Direct Sampling</a> is the act in <a href=/posts/kbhprobability/>probability</a> to sample what you want from the distribution. This is often used when actual <a href=/posts/kbhinference/>inference</a> impossible. It involves. well. sampling from the distribution to compute a <a href=/posts/kbhprobability/#conditional-probability>conditional probability</a> that you want.</p><p>It basically involves invoking the <a href=/posts/kbhprobability/#frequentist-definition-of-probability>Frequentist Definition of Probability</a> without letting \(n \to \infty\), instead just sampling some \(n &lt; \infty\) and dividing the event space by your <a href=/posts/kbhsample_space/>sample space</a>.</p><p>So, for instance, to compute <a href=/posts/kbhinference/>inference</a> on \(b^{1}\) given observations \(d^{1}c^{1}\), we can write:</p><p>\begin{equation}
P(b^{1} | d^{1}, c^{1}) = \frac{P(b^{1}, d^{1}, c^{1})}{P(d^{1})P(c^{1})} \approx \frac{\sum_{i}^{} b^{i} = 1 \land d^{i} = i \land c^{i} = 1}{\sum_{i}^{} d^{i} =1 \land c^{i} = 1}
\end{equation}</p><p>where \(a^{i}\) is the \(i\) th sample.</p><h2 id=direct-sampling-a-baysian-network--kbhbaysian-network-dot-md>Direct Sampling a <a href=/posts/kbhbaysian_network/>Baysian Network</a></h2><p>We first obtain a <a href=/posts/kbhtopological_sort/>topological sort</a> of the system. For a graph with \(n\) nodes, we then obtain a list \(X_{1:n}\).</p><p>We can then obtain a <a href=/posts/kbhdirect_sampling/>Direct Sampling</a> via simply sampling from this list. Whenever we need to sample some kind of <a href=/posts/kbhprobability/#conditional-probability>conditional probability</a>, we know that for every \(k_{i}\) we need to sample from, its parent conditions would have already been sampled because we are sampling in order of a <a href=/posts/kbhtopological_sort/>topological sort</a> so we can just sample the values from a subset of the conditioned set.</p><h2 id=likelihood-weighted-sampling>Likelihood Weighted Sampling</h2><p><a href=#likelihood-weighted-sampling>Likelihood Weighted Sampling</a> is a change to the <a href=/posts/kbhdirect_sampling/>Direct Sampling</a> approach which deals with the fact that <a href=/posts/kbhdirect_sampling/>Direct Sampling</a> may oversample <a href=/posts/kbhprobability/#conditional-probability>conditional probabilities</a> as it is sampling sub-nodes an equal amount.</p><p>It is particularly useful when our priors are unlikely.</p><p>To do this, we first perform <a href=/posts/kbhdirect_sampling/>Direct Sampling</a> as how you would normally. Now, say we get \(D=1\), \(C=1\), \(E=1\) for the <a href=/posts/kbhbaysian_network/>Baysian Network</a> presented below, the actual value we return would be whatever \(P(D|E) P(C|E)\).</p><figure><img src=/ox-hugo/2023-09-28_10-20-23_screenshot.png></figure><p>See <a href=/posts/kbhapproximate_inference/#example>an example here</a>.</p></div></article></main><footer><p id=footer>&copy; 2019-2025 Houjun Liu. Licensed CC BY-NC-SA 4.0.</p></footer></div></body></html>