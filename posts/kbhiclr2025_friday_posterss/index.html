<!doctype html><html lang=en-us><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Commissioner:wght@100;300;400;500;700&family=IBM+Plex+Sans:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css integrity="sha512-Evv84Mr4kqVGRNSgIGL/F/aIDqQb7xQ2vcrdIwxfjThSH8CSR7PBEakCr51Ck+w+/U6swU2Im1vVX0SVk9ABhg==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Jost:ital,wght@0,100;0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>window.MathJax={loader:{load:["[tex]/physics"]},tex:{packages:{"[+]":["physics"]}}}</script><title>ICLR2025 Friday Posters</title>
<meta name=description content="ICLR2025 Morris: contextual document embeddings
Take a bunch of sentence embeddings as input to produce a new sentence embedding that is now contextual
ICLR2025 Noukhovich: asynchronous reinforcement learning for language models
Rollout and tune concurrently
ICLR2025 Yao: CR-CTC CONSISTENCY REGULATION
CTC LOSS CAN BE MADE MORE ROBUST IF YOU REGULARIZE TO HAVE MINIMAL DIFFERENCE BETWEEN TWO AUGMENTED VIEWS OF THE SAME MEL SPECTRUM
ICLR2025 Sun: ReDeEP detecting hallucination using mechanistic interpretability
Find layers most prone to insert information, measure the information insertion using logit lens before and after passing through FFN, strong change after hallucination prone FFN means hallucination"><meta name=author content="Houjun Liu"><link rel=stylesheet href=/css/global.css><link rel=stylesheet href=/css/syntax.css></head><body><div class=center-clearfix><header><span id=header-name onclick='window.location.href="/"' style=cursor:pointer>Houjun Liu</span><div id=socialpanel><a href=https://www.jemoka.com/search/ class=header-social id=header-search><i class="ic fa-solid fa-magnifying-glass"></i></i></a>
<a href=https://github.com/Jemoka/ class=header-social id=header-github><i class="ic fa-brands fa-github"></i></a>
<a href=https://bsky.app/profile/jemoka.com class=header-social id=header-twitter><i class="ic fa-brands fa-bluesky"></i></a>
<a href=https://www.reddit.com/user/Jemoka/ class=header-social id=header-reddit><i class="ic fa-brands fa-reddit"></i></a></div></header><div id=title><h1>ICLR2025 Friday Posters</h1><span class=tagbox></span></div><aside id=toc><h1 id=toc-title>table of contents</h1><nav id=TableOfContents><ul><li><a href=#iclr2025-morris-contextual-document-embeddings>ICLR2025 Morris: contextual document embeddings</a></li><li><a href=#iclr2025-noukhovich-asynchronous-reinforcement-learning-for-language-models>ICLR2025 Noukhovich: asynchronous reinforcement learning for language models</a></li><li><a href=#iclr2025-yao-cr-ctc-consistency-regulation>ICLR2025 Yao: CR-CTC CONSISTENCY REGULATION</a></li><li><a href=#iclr2025-sun-redeep-detecting-hallucination-using-mechanistic-interpretability>ICLR2025 Sun: ReDeEP detecting hallucination using mechanistic interpretability</a></li><li><a href=#iclr2025-fu-chip>ICLR2025 Fu: CHiP</a></li><li><a href=#iclr2025-faysse-colpali>ICLR2025 Faysse: ColPali</a></li><li><a href=#iclr2025-liu-dellma>ICLR2025 Liu: DeLLMa</a></li><li><a href=#iclr2025-wijmans-cut-your-losses-in-large-vocabulary-language-model>ICLR2025 Wijmans: cut your losses in large vocabulary language model</a></li><li><a href=#iclr2025-gao-progressing-the-relative-future>ICLR2025 Gao: progressing the relative future</a></li><li><a href=#iclr2025-jin-moe-plus-plus-zero-computation-experts>ICLR2025 Jin: MOE++ zero computation experts</a></li><li><a href=#iclr2025-xiao-simper-preference-alignment-by-removing-hyper-parameters>ICLR2025 Xiao: SimPER preference alignment by removing hyper parameters</a></li><li><a href=#iclr2025-xiong-from-tokens-to-lattices>ICLR2025 Xiong: from tokens to lattices</a></li><li><a href=#iclr2025-pagliardini-ademamix>ICLR2025 Pagliardini: AdEMAMix</a></li><li><a href=#iclr2025-fan-loop-transformers-for-length-generalization>ICLR2025 Fan: loop transformers for length generalization</a></li><li><a href=#iclr2025-lee-multiple-non-asymptotic-rates-for-value-iteration>ICLR2025 Lee: multiple non-asymptotic rates for value iteration</a></li><li><a href=#iclr2025-liu-linear-combination-of-saves-checkpoints-makes-diffusion-and-consistency-models-better>ICLR2025 Liu: linear combination of saves checkpoints makes diffusion and consistency models better</a></li><li><a href=#iclr2025-ramapuram-theory-analysis-and-best-practices-for-sigmoid-self-attention>ICLR2025 Ramapuram: theory analysis and best practices for sigmoid self attention</a></li><li><a href=#iclr2025-sun-block-verification-accelerate-speculative-decoding>ICLR2025 Sun: block verification accelerate speculative decoding</a></li><li><a href=#iclr2025-chang-skiable-influence-a-fact-tracing>ICLR2025 Chang: skiable influence a fact tracing</a></li><li><a href=#iclr2025-hu-how-to-visualize-training-dynamics>ICLR2025 Hu: how to visualize training dynamics</a></li><li><a href=#iclr2025-addepali-safety-training-of-lm-s-generalized-to-semantically-related-prompts>ICLR2025 Addepali: safety training of LM&rsquo;s generalized to semantically related prompts</a></li><li><a href=#iclr2025-georgiev-attribute-to-delete>ICLR2025 Georgiev: attribute to delete</a></li></ul></nav></aside><main><article><div><h2 id=iclr2025-morris-contextual-document-embeddings>ICLR2025 Morris: contextual document embeddings</h2><p>Take a bunch of sentence embeddings as input to produce a new sentence embedding that is now contextual</p><h2 id=iclr2025-noukhovich-asynchronous-reinforcement-learning-for-language-models>ICLR2025 Noukhovich: asynchronous reinforcement learning for language models</h2><p>Rollout and tune concurrently</p><h2 id=iclr2025-yao-cr-ctc-consistency-regulation>ICLR2025 Yao: CR-CTC CONSISTENCY REGULATION</h2><p>CTC LOSS CAN BE MADE MORE ROBUST IF YOU REGULARIZE TO HAVE MINIMAL DIFFERENCE BETWEEN TWO AUGMENTED VIEWS OF THE SAME MEL SPECTRUM</p><h2 id=iclr2025-sun-redeep-detecting-hallucination-using-mechanistic-interpretability>ICLR2025 Sun: ReDeEP detecting hallucination using mechanistic interpretability</h2><p>Find layers most prone to insert information, measure the information insertion using logit lens before and after passing through FFN, strong change after hallucination prone FFN means hallucination</p><h2 id=iclr2025-fu-chip>ICLR2025 Fu: CHiP</h2><p>For multi model preference optimization, combine four different loss terms together a varying types of preference loss to get best results</p><h2 id=iclr2025-faysse-colpali>ICLR2025 Faysse: ColPali</h2><p>Embed images of text instead of text itself during rag</p><h2 id=iclr2025-liu-dellma>ICLR2025 Liu: DeLLMa</h2><p>Key insight; make a language model of POMDP by asking the language model to produce value judgments and normalizing them and doing standard value iteration</p><h2 id=iclr2025-wijmans-cut-your-losses-in-large-vocabulary-language-model>ICLR2025 Wijmans: cut your losses in large vocabulary language model</h2><p>Instead of decoding directly into logits, which is memory intensive, there is a trick to allow us to not have to store the entire out projection in memory</p><h2 id=iclr2025-gao-progressing-the-relative-future>ICLR2025 Gao: progressing the relative future</h2><p>Solve multiturn RLHF by writing the policy Q value and optimizing it over discounted features</p><h2 id=iclr2025-jin-moe-plus-plus-zero-computation-experts>ICLR2025 Jin: MOE++ zero computation experts</h2><p>Instead of doing MLP in experts, instead make each expert discarding input, duplicate input, or replacing input with trainable vector</p><p>Learn forwarding for adaptive computation</p><h2 id=iclr2025-xiao-simper-preference-alignment-by-removing-hyper-parameters>ICLR2025 Xiao: SimPER preference alignment by removing hyper parameters</h2><p>Remove the log term of DPO and remove thereby the hyper parameter beta that is needed</p><h2 id=iclr2025-xiong-from-tokens-to-lattices>ICLR2025 Xiong: from tokens to lattices</h2><p>Mask language models learn conditional relationships between tokens of the same entity thereby implicitly creating a graph</p><h2 id=iclr2025-pagliardini-ademamix>ICLR2025 Pagliardini: AdEMAMix</h2><p>Key insight: Adam with two different betas and also use gradient information from multiple steps for stabler and faster convergence</p><h2 id=iclr2025-fan-loop-transformers-for-length-generalization>ICLR2025 Fan: loop transformers for length generalization</h2><p>Key insight: UT like approaches with loops generalize better for tasks of a specific kind</p><h2 id=iclr2025-lee-multiple-non-asymptotic-rates-for-value-iteration>ICLR2025 Lee: multiple non-asymptotic rates for value iteration</h2><p>Key insight: anchoring using the original policy speed up average value value iteration</p><p>That is: Vt = a*V0 + b*T*Vt-1</p><h2 id=iclr2025-liu-linear-combination-of-saves-checkpoints-makes-diffusion-and-consistency-models-better>ICLR2025 Liu: linear combination of saves checkpoints makes diffusion and consistency models better</h2><p>Key insight: as titled, use evolutionary research to figure out the best mixture of weights to select</p><h2 id=iclr2025-ramapuram-theory-analysis-and-best-practices-for-sigmoid-self-attention>ICLR2025 Ramapuram: theory analysis and best practices for sigmoid self attention</h2><p>Key insight: sigmoid self attention reduces all gather costs and they have a bunch of tricks to make it work</p><h2 id=iclr2025-sun-block-verification-accelerate-speculative-decoding>ICLR2025 Sun: block verification accelerate speculative decoding</h2><p>Key insight: when using a small language model to speculatively decode a large language model, evaluate likelihood blocks at a time</p><h2 id=iclr2025-chang-skiable-influence-a-fact-tracing>ICLR2025 Chang: skiable influence a fact tracing</h2><p>Key insight: using a normalized gradient dot product between training examples and outputs, do attribution</p><h2 id=iclr2025-hu-how-to-visualize-training-dynamics>ICLR2025 Hu: how to visualize training dynamics</h2><p>Key insight: take whatever summary statistics you have for each checkpoint, run classical low dimensional work on it such as PCA</p><h2 id=iclr2025-addepali-safety-training-of-lm-s-generalized-to-semantically-related-prompts>ICLR2025 Addepali: safety training of LM&rsquo;s generalized to semantically related prompts</h2><p>Key insight: take some jailbreak that doesn&rsquo;t work anymore, make semantic pururbation o it, check if it still works. Often, it does.</p><h2 id=iclr2025-georgiev-attribute-to-delete>ICLR2025 Georgiev: attribute to delete</h2><p>Key; learn a data model which then allows you to perturb what pieces of input pre-training data is relevant to the actual output, using this,, with counterfactual for what the correct unlearned outcome is, and then tune against that.</p></div></article></main><footer><p id=footer>&copy; 2019-2025 Houjun Liu. Licensed CC BY-NC-SA 4.0.</p></footer></div></body></html>